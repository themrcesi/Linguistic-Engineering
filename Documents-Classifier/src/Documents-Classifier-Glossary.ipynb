{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Índice<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Carga-de-documentos\" data-toc-modified-id=\"Carga-de-documentos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Carga de documentos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocesado\" data-toc-modified-id=\"Preprocesado-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preprocesado</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bigramas\" data-toc-modified-id=\"Bigramas-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Bigramas</a></span></li></ul></li></ul></li><li><span><a href=\"#Glosario\" data-toc-modified-id=\"Glosario-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Glosario</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extracción-de-keywords\" data-toc-modified-id=\"Extracción-de-keywords-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Extracción de keywords</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extracción-propia\" data-toc-modified-id=\"Extracción-propia-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Extracción propia</a></span></li><li><span><a href=\"#Gensim\" data-toc-modified-id=\"Gensim-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Gensim</a></span></li><li><span><a href=\"#Kmeans\" data-toc-modified-id=\"Kmeans-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Kmeans</a></span></li></ul></li><li><span><a href=\"#Formación-del-glosario\" data-toc-modified-id=\"Formación-del-glosario-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Formación del glosario</a></span><ul class=\"toc-item\"><li><span><a href=\"#Automatizado\" data-toc-modified-id=\"Automatizado-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Automatizado</a></span></li></ul></li></ul></li><li><span><a href=\"#Clasificador\" data-toc-modified-id=\"Clasificador-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Clasificador</a></span><ul class=\"toc-item\"><li><span><a href=\"#Carga-de-glosarios\" data-toc-modified-id=\"Carga-de-glosarios-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Carga de glosarios</a></span></li><li><span><a href=\"#Bigramas-de-test-data\" data-toc-modified-id=\"Bigramas-de-test-data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Bigramas de test data</a></span></li><li><span><a href=\"#Modelos\" data-toc-modified-id=\"Modelos-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Modelos</a></span><ul class=\"toc-item\"><li><span><a href=\"#TFIDF\" data-toc-modified-id=\"TFIDF-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>TFIDF</a></span></li><li><span><a href=\"#Word2Vec\" data-toc-modified-id=\"Word2Vec-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Word2Vec</a></span></li><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Naive Bayes</a></span><ul class=\"toc-item\"><li><span><a href=\"#TFIDF\" data-toc-modified-id=\"TFIDF-3.3.3.1\"><span class=\"toc-item-num\">3.3.3.1&nbsp;&nbsp;</span>TFIDF</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Clasificación-de-documentos\" data-toc-modified-id=\"Clasificación-de-documentos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Clasificación de documentos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Funciones-auxiliares\" data-toc-modified-id=\"Funciones-auxiliares-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Funciones auxiliares</a></span></li><li><span><a href=\"#Clasificación\" data-toc-modified-id=\"Clasificación-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Clasificación</a></span></li></ul></li><li><span><a href=\"#Evaluación-de-modelos\" data-toc-modified-id=\"Evaluación-de-modelos-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluación de modelos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Funciones-auxiliares\" data-toc-modified-id=\"Funciones-auxiliares-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Funciones auxiliares</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:26.415896Z",
     "start_time": "2020-12-14T16:21:25.265897Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# NLTK\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import pos_tag\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.summarization import keywords\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.similarities import Similarity\n",
    "\n",
    "# Operatos\n",
    "from operator import itemgetter\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "from spacy_spanish_lemmatizer import SpacyCustomLemmatizer\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# statistics\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# utils\n",
    "from time import sleep\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:26.419897Z",
     "start_time": "2020-12-14T16:21:26.416899Z"
    }
   },
   "outputs": [],
   "source": [
    "path_health = \"../documents/health\"\n",
    "path_politics = \"../documents/politics\"\n",
    "path_sports = \"../documents/sports\"\n",
    "path_documents = \"../documents\"\n",
    "path_stopwords = \"../documents/stopwords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:26.483897Z",
     "start_time": "2020-12-14T16:21:26.420898Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_document(path):\n",
    "    return path.split(\"\\\\\")[-1], open(path,encoding='utf-8').read(), path.split(\"\\\\\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:26.970896Z",
     "start_time": "2020-12-14T16:21:26.484897Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = Parallel(n_jobs = -1)(delayed(load_document)(path) for path in glob.glob(path_documents+\"/*/*.txt\"))\n",
    "documents = pd.DataFrame(documents, columns=[\"doc_name\", \"text\", \"class\"])\n",
    "documents['text'] = documents['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:26.982897Z",
     "start_time": "2020-12-14T16:21:26.971897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>health_1.txt</td>\n",
       "      <td>Aceptémoslo de una vez: perder peso de manera ...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>health_10.txt</td>\n",
       "      <td>Sin tiempo para hacer recuento de daños, irrum...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health_11.txt</td>\n",
       "      <td>Mucha gente intenta mostrar en las redes socia...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health_12.txt</td>\n",
       "      <td>Una faceta clave en la frenética lucha global ...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>health_13.txt</td>\n",
       "      <td>La curva de contagios de coronavirus se mantie...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc_name                                               text   class\n",
       "0   health_1.txt  Aceptémoslo de una vez: perder peso de manera ...  health\n",
       "1  health_10.txt  Sin tiempo para hacer recuento de daños, irrum...  health\n",
       "2  health_11.txt  Mucha gente intenta mostrar en las redes socia...  health\n",
       "3  health_12.txt  Una faceta clave en la frenética lucha global ...  health\n",
       "4  health_13.txt  La curva de contagios de coronavirus se mantie...  health"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:27.883898Z",
     "start_time": "2020-12-14T16:21:26.983899Z"
    }
   },
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"(\\&)|(\\%)|(\\$)|(\\€)|(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)|(\\⁰)|(\\•)|(\\\\')\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "    \n",
    "nlp = spacy.load(\"es\")\n",
    "lemmatizer = SpacyCustomLemmatizer()\n",
    "\n",
    "def load_stopwords(path):\n",
    "    return [line.strip() for line in open(path_stopwords, encoding = \"utf-8\").readlines()]\n",
    "\n",
    "STOP_WORDS = set(load_stopwords(path_stopwords))\n",
    "\n",
    "def delete_stop_words(doc):\n",
    "    tokens = wordpunct_tokenize(doc)\n",
    "    clean = [token for token in tokens if token not in STOP_WORDS and len(token) > 2]\n",
    "    return clean\n",
    "\n",
    "def preprocess_document(document):\n",
    "    document = REPLACE_NO_SPACE.sub(NO_SPACE, document.lower())\n",
    "    document = REPLACE_WITH_SPACE.sub(SPACE, document)\n",
    "    # tokens = wordpunct_tokenize(document)\n",
    "    # tokens = delete_proper_nouns(tokens)\n",
    "    return document\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    tokens = nlp(\" \".join(tokens))\n",
    "    return [token.lemma_ for token in tokens]\n",
    "\n",
    "\n",
    "# TODO: REVISAR ESTO\n",
    "\n",
    "def delete_proper_nouns(tokens):\n",
    "    # Tag the tokens with their type - ie are they nouns or not\n",
    "    lTokens = pos_tag(tokens)\n",
    "    # find all the proper nouns and print them out\n",
    "    lTagDict = findtags('NNP', lTokens)\n",
    "    return [token.lower() for token in tokens if token not in lTagDict]\n",
    "    \n",
    "def findtags(tag_prefix, tagged_text):\n",
    "    \"\"\"\n",
    "    Find tokens matching the specified tag_prefix\n",
    "    \"\"\"\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
    "                                  if tag.startswith(tag_prefix))\n",
    "    print(cfd.conditions())\n",
    "    return [list(cfd[tag].keys()) for tag in cfd.conditions()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:28.389900Z",
     "start_time": "2020-12-14T16:21:27.884900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>preprocesado</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>health_1.txt</td>\n",
       "      <td>Aceptémoslo de una vez: perder peso de manera ...</td>\n",
       "      <td>health</td>\n",
       "      <td>aceptémoslo de una vez perder peso de manera r...</td>\n",
       "      <td>[aceptémoslo, perder, peso, rápida, indolora, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>health_10.txt</td>\n",
       "      <td>Sin tiempo para hacer recuento de daños, irrum...</td>\n",
       "      <td>health</td>\n",
       "      <td>sin tiempo para hacer recuento de daños irrump...</td>\n",
       "      <td>[recuento, daños, irrumpe, ola, virus, golpear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health_11.txt</td>\n",
       "      <td>Mucha gente intenta mostrar en las redes socia...</td>\n",
       "      <td>health</td>\n",
       "      <td>mucha gente intenta mostrar en las redes socia...</td>\n",
       "      <td>[gente, mostrar, redes, sociales, versión, fot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health_12.txt</td>\n",
       "      <td>Una faceta clave en la frenética lucha global ...</td>\n",
       "      <td>health</td>\n",
       "      <td>una faceta clave en la frenética lucha global ...</td>\n",
       "      <td>[faceta, clave, frenética, lucha, global, pfiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>health_13.txt</td>\n",
       "      <td>La curva de contagios de coronavirus se mantie...</td>\n",
       "      <td>health</td>\n",
       "      <td>la curva de contagios de coronavirus se mantie...</td>\n",
       "      <td>[curva, contagios, coronavirus, mantiene, espa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc_name                                               text   class  \\\n",
       "0   health_1.txt  Aceptémoslo de una vez: perder peso de manera ...  health   \n",
       "1  health_10.txt  Sin tiempo para hacer recuento de daños, irrum...  health   \n",
       "2  health_11.txt  Mucha gente intenta mostrar en las redes socia...  health   \n",
       "3  health_12.txt  Una faceta clave en la frenética lucha global ...  health   \n",
       "4  health_13.txt  La curva de contagios de coronavirus se mantie...  health   \n",
       "\n",
       "                                        preprocesado  \\\n",
       "0  aceptémoslo de una vez perder peso de manera r...   \n",
       "1  sin tiempo para hacer recuento de daños irrump...   \n",
       "2  mucha gente intenta mostrar en las redes socia...   \n",
       "3  una faceta clave en la frenética lucha global ...   \n",
       "4  la curva de contagios de coronavirus se mantie...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [aceptémoslo, perder, peso, rápida, indolora, ...  \n",
       "1  [recuento, daños, irrumpe, ola, virus, golpear...  \n",
       "2  [gente, mostrar, redes, sociales, versión, fot...  \n",
       "3  [faceta, clave, frenética, lucha, global, pfiz...  \n",
       "4  [curva, contagios, coronavirus, mantiene, espa...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[\"preprocesado\"] = documents[\"text\"].apply(lambda x: preprocess_document(x))\n",
    "documents[\"tokens\"] = documents[\"preprocesado\"].apply(lambda x: delete_stop_words(x))\n",
    "# documents[\"lematizado\"] = documents[\"preprocesado\"].apply(lambda x: lemmatize(x))\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:28.397897Z",
     "start_time": "2020-12-14T16:21:28.390897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data ==> 45 documents\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_health = documents[documents[\"class\"] == \"health\"].iloc[:15]\n",
    "train_politics = documents[documents[\"class\"] == \"politics\"].iloc[:15]\n",
    "train_sports = documents[documents[\"class\"] == \"sports\"].iloc[:15]\n",
    "\n",
    "train_data = pd.concat([train_health, train_politics, train_sports])\n",
    "print(f\"Training data ==> {len(train_data)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:28.404897Z",
     "start_time": "2020-12-14T16:21:28.398899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data ==> 105 documents\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_health = documents[documents[\"class\"] == \"health\"].iloc[15:]\n",
    "test_politics = documents[documents[\"class\"] == \"politics\"].iloc[15:]\n",
    "test_sports = documents[documents[\"class\"] == \"sports\"].iloc[15:]\n",
    "\n",
    "test_data = pd.concat([test_health, test_politics, test_sports])\n",
    "test_data.reset_index(inplace = True)\n",
    "print(f\"Testing data ==> {len(test_data)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:28.410896Z",
     "start_time": "2020-12-14T16:21:28.405897Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bigrams(documents, threshold):\n",
    "    token_ = [doc.split(\" \") for doc in documents]\n",
    "    bigram = Phrases(token_, min_count=1, threshold=threshold, delimiter=b' ')\n",
    "    bigram_phraser = Phraser(bigram)\n",
    "    bigram_token = []\n",
    "    for sent in token_:\n",
    "        for bigram in bigram_phraser[sent]:\n",
    "            if len(bigram.split(\" \")) > 1: # comprobamos que realmente es un bigrama\n",
    "                bigram_token.append(bigram) \n",
    "    return bigram_token\n",
    "           \n",
    "def check_bigram(x, bigrams):\n",
    "    if x.find(\"jamón serrano\") != -1 or x.find(\"jamón\") != -1:\n",
    "        print(x)\n",
    "    return [bigram for bigram in bigrams if x.find(bigram) != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:29.289896Z",
     "start_time": "2020-12-14T16:21:28.411899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sobre todo',\n",
       " 'están sus',\n",
       " 'equipo rojiblanco',\n",
       " 'como obligación',\n",
       " 'ha sido',\n",
       " 'tercer puesto',\n",
       " 'estamos hablando',\n",
       " 'como obligación',\n",
       " 'estamos hablando',\n",
       " 'sí mismo',\n",
       " 'lo dicen',\n",
       " 'tiene nada',\n",
       " 'han hecho',\n",
       " 'sergi roberto',\n",
       " 'sobre todo',\n",
       " 'ha ido',\n",
       " 'único teclado',\n",
       " 'respecto al',\n",
       " 'único teclado',\n",
       " 'buena parte',\n",
       " 'equipo rojiblanco',\n",
       " 'por ejemplo',\n",
       " 'sergi roberto',\n",
       " 'respecto al',\n",
       " 'se circula',\n",
       " 'ahora mismo',\n",
       " 'se circula',\n",
       " 'una campaña',\n",
       " 'por delante',\n",
       " 'real madrid',\n",
       " 'champions porque',\n",
       " 'las cosas',\n",
       " 'tercer puesto',\n",
       " 'se juega',\n",
       " 'por encima',\n",
       " 'por debajo',\n",
       " 'al timón',\n",
       " 'ni siquiera',\n",
       " 'sea necesario',\n",
       " 'sonny vaccaro',\n",
       " 'michael jordan',\n",
       " 'michael jordan',\n",
       " 'recién llegado',\n",
       " 'por culpa',\n",
       " 'the last',\n",
       " 'ha decidido',\n",
       " 'jordan vi',\n",
       " 'le regaló',\n",
       " 'propio jugador',\n",
       " 'para demostrar',\n",
       " 'the last',\n",
       " 'sonny vaccaro',\n",
       " 'tiene nada',\n",
       " 'michael jordan',\n",
       " 'jordan vi',\n",
       " 'propio jugador',\n",
       " 'le regaló',\n",
       " 'para demostrar',\n",
       " 'ha decidido',\n",
       " 'primera jornada',\n",
       " 'todas las',\n",
       " 'serbio jugará',\n",
       " 'próxima temporada',\n",
       " 'ha informado',\n",
       " 'adrian wojnarowski',\n",
       " 'agente libre',\n",
       " 'serbio jugará',\n",
       " 'próxima temporada',\n",
       " 'ha informado',\n",
       " 'adrian wojnarowski',\n",
       " 'esta manera',\n",
       " 'nueva orleans',\n",
       " 'ha promediado',\n",
       " 'han llegado',\n",
       " 'detroit pistons',\n",
       " 'por ciento',\n",
       " 'por ciento',\n",
       " 'por culpa',\n",
       " 'unos días',\n",
       " 'ed davis',\n",
       " 'adrian wojnarowski',\n",
       " 'ed davis',\n",
       " 'segunda ronda',\n",
       " 'ha promediado',\n",
       " 'ha conseguido',\n",
       " 'ha informado',\n",
       " 'adrian wojnarowski',\n",
       " 'detroit pistons',\n",
       " 'han llegado',\n",
       " 'esta manera',\n",
       " 'una campaña',\n",
       " 'nueva orleans',\n",
       " 'nueva orleans',\n",
       " 'alero estrella',\n",
       " 'cinco años',\n",
       " 'esta manera',\n",
       " 'pasada temporada',\n",
       " 'all star',\n",
       " 'primera vez',\n",
       " 'cinco años',\n",
       " 'pasada temporada',\n",
       " 'all star',\n",
       " 'bla bla',\n",
       " 'andrew wiggins',\n",
       " 'las cosas',\n",
       " 'han hecho',\n",
       " 'he quedado',\n",
       " 'he tenido',\n",
       " 'tres años',\n",
       " 'marc gasol',\n",
       " 'actuales campeones',\n",
       " 'agente libre',\n",
       " 'pasada temporada',\n",
       " 'primera vez',\n",
       " 'segunda ronda',\n",
       " 'aunque luego',\n",
       " 'pasada temporada',\n",
       " 'agente libre',\n",
       " 'ala pívot',\n",
       " 'marc gasol',\n",
       " 'actuales campeones',\n",
       " 'alero estrella',\n",
       " 'ala pívot',\n",
       " 'por ciento',\n",
       " 'sucede algo',\n",
       " 'sucede algo',\n",
       " 'mucho tiempo',\n",
       " 'all star',\n",
       " 'ha promediado',\n",
       " 'sea necesario',\n",
       " 'él mismo',\n",
       " 'son difíciles',\n",
       " 'han llegado',\n",
       " 'andrew wiggins',\n",
       " 'real madrid',\n",
       " 'ha ido',\n",
       " 'ahora mismo',\n",
       " 'entrenador madridista',\n",
       " 'son difíciles',\n",
       " 'al timón',\n",
       " 'he echado',\n",
       " 'por ejemplo',\n",
       " 'ha estado',\n",
       " 'aunque luego',\n",
       " 'real madrid',\n",
       " 'me gustaría',\n",
       " 'me siento',\n",
       " 'me jode',\n",
       " 'me jode',\n",
       " 'me gustaría',\n",
       " 'me jode',\n",
       " 'me siento',\n",
       " 'entrenador madridista',\n",
       " 'jornet atacará',\n",
       " 'pista este',\n",
       " 'noviembre arrancará',\n",
       " 'kilómetros establecido',\n",
       " 'yiannis kouros',\n",
       " 'nuevo reto',\n",
       " 'ha estado',\n",
       " 'buen tiempo',\n",
       " 'noruega aunque',\n",
       " 'primera intención',\n",
       " 'era lanzarse',\n",
       " 'las nevadas',\n",
       " 'tierras noruegas',\n",
       " 'intento hasta',\n",
       " 'se desarrollará',\n",
       " 'måndalen noruega',\n",
       " 'sin público',\n",
       " 'esperan temperaturas',\n",
       " 'grados por',\n",
       " 'díajornet cambiará',\n",
       " 'dirección cada',\n",
       " 'cuatro horas',\n",
       " 'ha entrenado',\n",
       " 'durante varios',\n",
       " 'carrera sea',\n",
       " 'oficial también',\n",
       " 'competirán varios',\n",
       " 'atletas noruegos',\n",
       " 'larga distancia',\n",
       " 'intento jornet',\n",
       " 'nueva s',\n",
       " 'lab phantasm',\n",
       " 'récord actual',\n",
       " 'del griego',\n",
       " 'yiannis kouros',\n",
       " 'hour run',\n",
       " 'km hla',\n",
       " 'ha sido',\n",
       " 'al principio',\n",
       " 'temporada supe',\n",
       " 'quería probar',\n",
       " 'diferentes entrenamientos',\n",
       " 'llano sin',\n",
       " 'ningún objetivo',\n",
       " 'específico así',\n",
       " 'estuve probando',\n",
       " 'diferentes series',\n",
       " 'permitían las',\n",
       " 'lesiones hasta',\n",
       " 'me fijé',\n",
       " 'horas explicó',\n",
       " 'hace días',\n",
       " 'jornet\\n\\nel corredor',\n",
       " 'salomon explicó',\n",
       " 'ha sido',\n",
       " 'para buscar',\n",
       " 'este récord',\n",
       " 'primero corrió',\n",
       " 'seis horas',\n",
       " 'probar diferentes',\n",
       " 'nutrición luego',\n",
       " 'algunas semanas',\n",
       " 'llegó hasta',\n",
       " 'tiradas cercanas',\n",
       " 'para trarar',\n",
       " 'equilibrio entre',\n",
       " 'conseguir adaptaciones',\n",
       " 'no sufrir',\n",
       " 'heridasa principios',\n",
       " 'verano completó',\n",
       " 'algunos días',\n",
       " 'casi enteros',\n",
       " 'montaña así',\n",
       " 'metabolismo está',\n",
       " 'gran pregunta',\n",
       " 'me hago',\n",
       " 'las adaptaciones',\n",
       " 'musculares son',\n",
       " 'entrenamiento nutricional',\n",
       " 'ha dado',\n",
       " 'resultados apuntó',\n",
       " 'hace unos',\n",
       " 'sus redes',\n",
       " 'socialestambién jornet',\n",
       " 'sus redes',\n",
       " 'mejores registros',\n",
       " 'distintas distancias',\n",
       " 'especialidades tanto',\n",
       " 'montañaultra distancias',\n",
       " 'escalada eso',\n",
       " 'me permite',\n",
       " 'pensar diferentes',\n",
       " 'es interesante',\n",
       " 'hasta dónde',\n",
       " 'podemos llegar',\n",
       " 'cada esfuerzo',\n",
       " 'entrenamiento específico',\n",
       " 'esta tabla',\n",
       " 'publicó su',\n",
       " 'mejores registros',\n",
       " 'las pruebas',\n",
       " 'es interesante',\n",
       " 'jornet atacará',\n",
       " 'pista este',\n",
       " 'noviembre arrancará',\n",
       " 'kilómetros establecido',\n",
       " 'yiannis kouros',\n",
       " 'nuevo reto',\n",
       " 'ha estado',\n",
       " 'buen tiempo',\n",
       " 'noruega aunque',\n",
       " 'primera intención',\n",
       " 'era lanzarse',\n",
       " 'las nevadas',\n",
       " 'tierras noruegas',\n",
       " 'intento hasta',\n",
       " 'se desarrollará',\n",
       " 'måndalen noruega',\n",
       " 'sin público',\n",
       " 'esperan temperaturas',\n",
       " 'grados por',\n",
       " 'díajornet cambiará',\n",
       " 'dirección cada',\n",
       " 'cuatro horas',\n",
       " 'ha entrenado',\n",
       " 'durante varios',\n",
       " 'carrera sea',\n",
       " 'oficial también',\n",
       " 'competirán varios',\n",
       " 'atletas noruegos',\n",
       " 'larga distancia',\n",
       " 'intento jornet',\n",
       " 'nueva s',\n",
       " 'lab phantasm',\n",
       " 'récord actual',\n",
       " 'del griego',\n",
       " 'yiannis kouros',\n",
       " 'hour run',\n",
       " 'km hla',\n",
       " 'ha sido',\n",
       " 'al principio',\n",
       " 'temporada supe',\n",
       " 'quería probar',\n",
       " 'diferentes entrenamientos',\n",
       " 'llano sin',\n",
       " 'ningún objetivo',\n",
       " 'específico así',\n",
       " 'estuve probando',\n",
       " 'diferentes series',\n",
       " 'permitían las',\n",
       " 'lesiones hasta',\n",
       " 'me fijé',\n",
       " 'horas explicó',\n",
       " 'hace días',\n",
       " 'metabolismo está',\n",
       " 'gran pregunta',\n",
       " 'me hago',\n",
       " 'las adaptaciones',\n",
       " 'musculares son',\n",
       " 'entrenamiento nutricional',\n",
       " 'ha dado',\n",
       " 'jornet\\n\\nel corredor',\n",
       " 'salomon explicó',\n",
       " 'ha sido',\n",
       " 'para buscar',\n",
       " 'este récord',\n",
       " 'primero corrió',\n",
       " 'seis horas',\n",
       " 'probar diferentes',\n",
       " 'nutrición luego',\n",
       " 'algunas semanas',\n",
       " 'llegó hasta',\n",
       " 'tiradas cercanas',\n",
       " 'para trarar',\n",
       " 'equilibrio entre',\n",
       " 'conseguir adaptaciones',\n",
       " 'no sufrir',\n",
       " 'heridasa principios',\n",
       " 'verano completó',\n",
       " 'algunos días',\n",
       " 'casi enteros',\n",
       " 'montaña así',\n",
       " 'metabolismo está',\n",
       " 'gran pregunta',\n",
       " 'me hago',\n",
       " 'las adaptaciones',\n",
       " 'musculares son',\n",
       " 'entrenamiento nutricional',\n",
       " 'ha dado',\n",
       " 'resultados apuntó',\n",
       " 'hace unos',\n",
       " 'sus redes',\n",
       " 'socialestambién jornet',\n",
       " 'sus redes',\n",
       " 'mejores registros',\n",
       " 'distintas distancias',\n",
       " 'especialidades tanto',\n",
       " 'montañaultra distancias',\n",
       " 'escalada eso',\n",
       " 'me permite',\n",
       " 'pensar diferentes',\n",
       " 'es interesante',\n",
       " 'hasta dónde',\n",
       " 'podemos llegar',\n",
       " 'cada esfuerzo',\n",
       " 'entrenamiento específico',\n",
       " 'esta tabla',\n",
       " 'publicó su',\n",
       " 'mejores registros',\n",
       " 'las pruebas',\n",
       " 'están sus',\n",
       " 'di stéfano',\n",
       " 'se enfundó',\n",
       " 'se enfundó',\n",
       " 'di stéfano',\n",
       " 'santiago bernabéu',\n",
       " 'don alfredo',\n",
       " 'real madrid',\n",
       " 'santiago bernabéu',\n",
       " 'di stéfano',\n",
       " 'di stéfano',\n",
       " 'real madrid',\n",
       " 'di stéfano',\n",
       " 'don alfredo',\n",
       " 'del deporte',\n",
       " 'di stéfano',\n",
       " 'marca española',\n",
       " 'dos segundos',\n",
       " 'récord nacional',\n",
       " 'todas las',\n",
       " 'jesús españa',\n",
       " 'yago rojo',\n",
       " 'récord nacional',\n",
       " 'segunda parte',\n",
       " 'yago rojo',\n",
       " 'sí mismo',\n",
       " 'por debajo',\n",
       " 'dos segundos',\n",
       " 'por debajo',\n",
       " 'récord nacional',\n",
       " 'he quedado',\n",
       " 'he tenido',\n",
       " 'he echado',\n",
       " 'jesús españa',\n",
       " 'marta garcía',\n",
       " 'marta garcía',\n",
       " 'marca española',\n",
       " 'estamos hablando',\n",
       " 'cierto es',\n",
       " 'goles esperados',\n",
       " 'participa más',\n",
       " 'participa más',\n",
       " 'las acciones',\n",
       " 'cierto es',\n",
       " 'champions porque',\n",
       " 'goles esperados',\n",
       " 'por encima',\n",
       " 'lo dicen',\n",
       " 'por delante',\n",
       " 'gran pregunta',\n",
       " 'esta ocasión',\n",
       " 'primera jornada',\n",
       " 'tres años',\n",
       " 'del mundo',\n",
       " 'mucho tiempo',\n",
       " 'ni siquiera',\n",
       " 'del mundo',\n",
       " 'del mundo',\n",
       " 'del deporte',\n",
       " 'por culpa',\n",
       " 'él mismo',\n",
       " 'habría sido',\n",
       " 'muy difícil',\n",
       " 'habría sido',\n",
       " 'muy difícil',\n",
       " 'ni siquiera',\n",
       " 'ha conseguido',\n",
       " 'límite está',\n",
       " 'límite está',\n",
       " 'esta ocasión',\n",
       " 'esta ocasión',\n",
       " 'cuatro goles',\n",
       " 'argelino abdi',\n",
       " 'buena parte',\n",
       " 'las penas',\n",
       " 'jaime fernández',\n",
       " 'gonzalo pérez',\n",
       " 'argelino abdi',\n",
       " 'las penas',\n",
       " 'segunda parte',\n",
       " 'recién llegado',\n",
       " 'gonzalo pérez',\n",
       " 'todas las',\n",
       " 'cuatro goles',\n",
       " 'por debajo',\n",
       " 'jaime fernández',\n",
       " 'se juega',\n",
       " 'segunda sede',\n",
       " 'ronda principal',\n",
       " 'semana pasada',\n",
       " 'semana pasada',\n",
       " 'ha sido',\n",
       " 'per bertelsen',\n",
       " 'segunda sede',\n",
       " 'todas las',\n",
       " 'per bertelsen',\n",
       " 'ronda principal',\n",
       " 'ronda principal']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_sports = get_bigrams(train_sports[\"preprocesado\"].values, 50)\n",
    "bigrams_health = get_bigrams(train_health[\"preprocesado\"].values, 50)\n",
    "bigrams_politics = get_bigrams(train_politics[\"preprocesado\"].values, 50)\n",
    "bigrams = get_bigrams(train_data[\"preprocesado\"].values, 50)\n",
    "\n",
    "\n",
    "train_sports[\"bigrams\"] = train_sports[\"preprocesado\"].apply(lambda x: check_bigram(x, bigrams_sports))\n",
    "train_health[\"bigrams\"] = train_health[\"preprocesado\"].apply(lambda x: check_bigram(x, bigrams_health))\n",
    "train_politics[\"bigrams\"] = train_politics[\"preprocesado\"].apply(lambda x: check_bigram(x, bigrams_politics))\n",
    "\n",
    "train_sports[\"tokens + bigrams\"] = train_sports[\"tokens\"] + train_sports[\"bigrams\"]\n",
    "train_health[\"tokens + bigrams\"] = train_health[\"tokens\"] + train_health[\"bigrams\"]\n",
    "train_politics[\"tokens + bigrams\"] = train_politics[\"tokens\"] + train_politics[\"bigrams\"]\n",
    "\n",
    "train_data[\"bigrams\"] = train_data[\"preprocesado\"].apply(lambda x: check_bigram(x, bigrams))\n",
    "train_data[\"tokens + bigrams\"] = train_data[\"tokens\"] + train_data[\"bigrams\"]\n",
    "\n",
    "bigrams_sports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glosario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción propia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:29.293898Z",
     "start_time": "2020-12-14T16:21:29.290896Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_dir = \"../documents/stopwords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:29.302898Z",
     "start_time": "2020-12-14T16:21:29.293898Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_k_tfidf_keywords(df, k):\n",
    "    tokens = df[\"tokens + bigrams\"].values\n",
    "    dictionary = corpora.Dictionary(tokens)\n",
    "    bow = [dictionary.doc2bow(doc) for doc in tokens]\n",
    "    tfidf = models.TfidfModel(bow)\n",
    "    bow_tfidf = tfidf[bow]\n",
    "    tfidf_dic = {dictionary.get(id): value for doc in bow_tfidf for id, value in doc}\n",
    "    tfidf_list = [k for k, v in sorted(tfidf_dic.items(), key=lambda item: item[1], reverse = True)]\n",
    "    return tfidf_list[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:29.404898Z",
     "start_time": "2020-12-14T16:21:29.303898Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_tfidf_health = get_k_tfidf_keywords(train_health, 100)\n",
    "keywords_tfidf_politics = get_k_tfidf_keywords(train_politics, 100)\n",
    "keywords_tfidf_sports = get_k_tfidf_keywords(train_sports, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:29.409899Z",
     "start_time": "2020-12-14T16:21:29.405899Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(d1, d2, d3):\n",
    "\n",
    "    i1 = set(d1) & set(d2)\n",
    "    i2 = set(d1) & set(d3)\n",
    "    i3 = set(d2) & set(d3)\n",
    "    \n",
    "    deleted = set(list(i1.union(i2).union(i3)))\n",
    "    \n",
    "    for key in deleted:\n",
    "        try:\n",
    "            d1.remove(key)\n",
    "        except:\n",
    "            print(f\"D1 no tiene {key}\")\n",
    "        try:\n",
    "            d2.remove(key)\n",
    "        except:\n",
    "            print(f\"D2 no tiene {key}\")\n",
    "        try:\n",
    "            d3.remove(key)\n",
    "        except:\n",
    "            print(f\"D3 no tiene {key}\")\n",
    "            \n",
    "    return d1, d2, d3   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:29.415898Z",
     "start_time": "2020-12-14T16:21:29.410899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 no tiene récord\n",
      "D1 no tiene defensa\n"
     ]
    }
   ],
   "source": [
    "keywords_tfidf_health, keywords_tfidf_politics, keywords_tfidf_sports = remove_duplicates(keywords_tfidf_health, keywords_tfidf_politics, keywords_tfidf_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:29.418898Z",
     "start_time": "2020-12-14T16:21:29.416898Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_table_keywords(health, sports, politics):\n",
    "    aa = pd.DataFrame(health, columns=[\"health\"])\n",
    "    aa[\"sports\"] = pd.Series(sports)\n",
    "    aa[\"politics\"] = pd.Series(politics)\n",
    "    print(aa.to_latex(bold_rows = True, column_format = \"lll\", index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:29.427899Z",
     "start_time": "2020-12-14T16:21:29.419898Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "               health &              sports &                politics \\\\\n",
      "\\midrule\n",
      "         tuberculosis &               gasol &                   marín \\\\\n",
      "            teléfonos &             vaccaro &            ayuntamiento \\\\\n",
      "               plasma &             stéfano &                vivienda \\\\\n",
      "              móviles &             haaland &                 supremo \\\\\n",
      "          metabolismo &           balonmano &                sociedad \\\\\n",
      "            miocardio &             alfredo &                     dsn \\\\\n",
      "    teléfonos móviles &          di stéfano &                informes \\\\\n",
      "              moderna &           candidato &         manifestaciones \\\\\n",
      "              infarto &            favorito &                   notas \\\\\n",
      "             facebook &              jornet &      seguridad nacional \\\\\n",
      "                pecho &               pista &                ministro \\\\\n",
      "            contagios &               curry &               desahucio \\\\\n",
      "          anticuerpos &            thompson &         felipe gonzález \\\\\n",
      "            las redes &            warriors &              territorio \\\\\n",
      "                redes &              lakers &     armonización fiscal \\\\\n",
      "              alergia &                nike &                     mal \\\\\n",
      "                magra &                 bla &              feministas \\\\\n",
      "                 masa &            campazzo &     las manifestaciones \\\\\n",
      "           masa magra &               carro &             este jueves \\\\\n",
      "          hiperinmune &            nacional &                  utrera \\\\\n",
      "               al día &           campeones &               propuesto \\\\\n",
      "               angina &                marc &                gonzález \\\\\n",
      "                plato &            bernabéu &               eutanasia \\\\\n",
      "          voluntarios &            atlético &            interés para \\\\\n",
      "         personalidad &            dortmund &               navidades \\\\\n",
      "             castilla &             ha sido &             información \\\\\n",
      "           fallecidos &               barça &                     pnv \\\\\n",
      "                  mes &               grupo &                  europa \\\\\n",
      "              senegal &      rehabilitación &                exterior \\\\\n",
      "                quizá &                tipo &               azurmendi \\\\\n",
      "                donar &      michael jordan &                becerril \\\\\n",
      "             suicidio &                bolt &        jiménez becerril \\\\\n",
      "            suicidios &           del mundo &                  callar \\\\\n",
      "           metabólica &            competir &                   iceta \\\\\n",
      "         salud mental &                duro &                don juan \\\\\n",
      "             sociales &               ricky &                   elena \\\\\n",
      "           algún tipo &                facu &                rey juan \\\\\n",
      "                 tasa &                jode &              los hechos \\\\\n",
      "              sistema &                laso &               rodríguez \\\\\n",
      "          por ejemplo &             me jode &            convocatoria \\\\\n",
      "                 león &              abadía &        gobierno central \\\\\n",
      "            enfermera &               jesús &             isabel díaz \\\\\n",
      "               ensayo &        obstaculista &                 armadas \\\\\n",
      "            inyección &                rojo &        defensa nacional \\\\\n",
      "              placebo &     récord nacional &         fuerzas armadas \\\\\n",
      "           se produce &           kilómetro &                  loyola \\\\\n",
      "             desayuno &                abdi &               militares \\\\\n",
      "              apostar &              ademar &                 antúnez \\\\\n",
      "          apostar por &              leonés &               municipal \\\\\n",
      "               hambre &            marcador &         estas navidades \\\\\n",
      "             cardíaca &              adrian &                  planes \\\\\n",
      "               fritas &  adrian wojnarowski &           profesionales \\\\\n",
      "                fruta &             orleans &                  verano \\\\\n",
      "             donación &         wojnarowski &                  código \\\\\n",
      "             donantes &           dinamarca &            código penal \\\\\n",
      "              belleza &          federación &                injurias \\\\\n",
      "              tinción &              grupos &            ha explicado \\\\\n",
      "          utilización &             herning &              madrileños \\\\\n",
      "              escuela &             kolding &                atención \\\\\n",
      "           idealizada &           principal &               casa real \\\\\n",
      "             usuarios &     ronda principal &            ha advertido \\\\\n",
      "            comenzado &                sede &            armonización \\\\\n",
      "                dakar &             equipos &              regulación \\\\\n",
      "          desconocida &               mcgee &                   texto \\\\\n",
      "      las autoridades &    pasada temporada &           pedro sánchez \\\\\n",
      "            ocho días &              huella &                 interés \\\\\n",
      "          inmunitario &             leyenda &            acuerdos con \\\\\n",
      "  sistema inmunitario &         real madrid &                eh bildu \\\\\n",
      "                sueño &            saunders &          pablo iglesias \\\\\n",
      "           tu sistema &         situaciones &                 alberto \\\\\n",
      "            microbios &              wolves &                   ascen \\\\\n",
      "            patógenos &                 gol &  presupuestos generales \\\\\n",
      "        se encuentran &       gran pregunta &               enfrentar \\\\\n",
      "       sistema inmune &          distancias &                    haga \\\\\n",
      "          sin embargo &                reto &              haga falta \\\\\n",
      "          aumento del &              lesión &                ir mejor \\\\\n",
      "               padres &              hablar &                 mejorar \\\\\n",
      "            preguntas &          entrenador &         puede enfrentar \\\\\n",
      "              energía &            all star &               recordado \\\\\n",
      "              tu tasa &       ha promediado &                  fiesta \\\\\n",
      "            tu cuerpo &         han llegado &         fiesta nacional \\\\\n",
      "             alergias &         ni siquiera &                 tensión \\\\\n",
      "          alimentaria &          por debajo &         decisiones pesc \\\\\n",
      "          científicos &     como obligación &                   delcy \\\\\n",
      "            acumulada &          obligación &         delcy rodríguez \\\\\n",
      "             asturias &            pelearla &        las obligaciones \\\\\n",
      "             baleares &          sobre todo &            obligaciones \\\\\n",
      "             canarias &                tiro &                    pesc \\\\\n",
      " incidencia acumulada &         dellavedova &       política exterior \\\\\n",
      "          notificados &             detroit &               querellas \\\\\n",
      "              sanidad &                espn &      territorio español \\\\\n",
      "        última semana &         esta manera &        tribunal supremo \\\\\n",
      "             clínicos &        ha informado &                   penal \\\\\n",
      "                dosis &                heat &                tribunal \\\\\n",
      "                miami &           informado &              decisiones \\\\\n",
      "                padre &       nueva orleans &                  activó \\\\\n",
      "           participar &            pelicans &                   arcas \\\\\n",
      "               pfizer &             pistons &              financiero \\\\\n",
      "             expertos &                 NaN &                     NaN \\\\\n",
      "            parte del &                 NaN &                     NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_table_keywords(keywords_tfidf_health, keywords_tfidf_sports, keywords_tfidf_politics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:29.431897Z",
     "start_time": "2020-12-14T16:21:29.428899Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_k_gensim_keywords(data, k):\n",
    "    data = data.copy()\n",
    "    data[\"joined\"] = data[\"tokens + bigrams\"].apply(lambda x: \" \".join(x))\n",
    "    data['joined'] = data.joined.astype(str)\n",
    "    data = \" \".join(data[\"joined\"].values)\n",
    "    return [key[0] for key in keywords(data, scores=True, words=k, pos_filter=('NNP', 'JJ', \"NNPS\", \"VB\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:30.655895Z",
     "start_time": "2020-12-14T16:21:29.432900Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D3 no tiene pandemia\n",
      "D2 no tiene punto\n",
      "D3 no tiene personas\n",
      "D2 no tiene grupo\n",
      "D1 no tiene espana\n",
      "D1 no tiene partido\n",
      "D1 no tiene partidos\n",
      "D3 no tiene dia\n",
      "D2 no tiene horas\n",
      "D3 no tiene trata\n",
      "D1 no tiene presidente\n",
      "D3 no tiene persona\n",
      "D1 no tiene real\n",
      "D3 no tiene casos\n",
      "D1 no tiene situacion\n",
      "D2 no tiene puntos\n",
      "D3 no tiene sin\n"
     ]
    }
   ],
   "source": [
    "keywords_gensim_health = get_k_gensim_keywords(train_health, 100)\n",
    "keywords_gensim_politics = get_k_gensim_keywords(train_politics, 100)\n",
    "keywords_gensim_sports = get_k_gensim_keywords(train_sports, 100)\n",
    "\n",
    "keywords_gensim_health, keywords_k_gensim_politics, keywords_k_gensim_sports = remove_duplicates(keywords_gensim_health, keywords_gensim_politics, keywords_gensim_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:30.664896Z",
     "start_time": "2020-12-14T16:21:30.656895Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "              health &                     sports &                       politics \\\\\n",
      "\\midrule\n",
      "          enfermedad &                     equipo &                       gobierno \\\\\n",
      "        enfermedades &                    equipos &                        sanchez \\\\\n",
      "                caso &                    jugador &               socialista pedro \\\\\n",
      "             estudio &                  jugadores &                   presupuestos \\\\\n",
      "            estudios &                     madrid &                    presupuesto \\\\\n",
      "             comidas &                  temporada &                      comunidad \\\\\n",
      "              comida &                 temporadas &                    comunidades \\\\\n",
      "               forma &                     grupos &                       nacional \\\\\n",
      "              formas &                        por &                         nacion \\\\\n",
      "               salud &                      marca &                        familia \\\\\n",
      "           saludable &                     marcas &                       familias \\\\\n",
      "          saludables &                       base &             coronavirus madrid \\\\\n",
      "              cuerpo &                       liga &                           psoe \\\\\n",
      "            telefono &                   atletico &                            erc \\\\\n",
      "           telefonos &                      goles &                       politica \\\\\n",
      "              frente &                    carrera &                      politicas \\\\\n",
      "             infarto &                   carreras &                    euros horas \\\\\n",
      "            infartos &                    dificil &                            vox \\\\\n",
      "              sangre &                  dificiles &                            ley \\\\\n",
      "              muerte &                llegado nba &                        acuerdo \\\\\n",
      "             muertes &                      juego &                       acuerdos \\\\\n",
      "             efectos &                     record &                    socialistas \\\\\n",
      "              efecto &                    records &                     rey felipe \\\\\n",
      "               covid &                      pivot &                   ayuntamiento \\\\\n",
      "              puedes &                     pivots &                       vivienda \\\\\n",
      "               puede &                     pivote &                       congreso \\\\\n",
      "             sistema &                   historia &                   cuentas caso \\\\\n",
      "            sistemas &                      final &                      diputados \\\\\n",
      "               virus &                     jordan &                       diputado \\\\\n",
      "              vacuna &                    stefano &  vicepresidente pablo iglesias \\\\\n",
      " importantes vacunas &                     futbol &                       politico \\\\\n",
      "          importante &          contrato millones &                      politicos \\\\\n",
      "           alimentos &                    mercado &                           este \\\\\n",
      "            alimento &                     lesion &                        espanol \\\\\n",
      "           pandemias &                   lesiones &                      espanoles \\\\\n",
      "        tuberculosis &                    escolta &                          vidas \\\\\n",
      "              riesgo &                   escoltas &                     sanitarias \\\\\n",
      "           por sobre &          finales champions &                      sanitaria \\\\\n",
      "               datos &                    noruega &                       comision \\\\\n",
      "                dato &                   noruegas &                          hijos \\\\\n",
      "         anticuerpos &                    haaland &                           hijo \\\\\n",
      "             medicos &                 kilometros &               independentistas \\\\\n",
      "              medico &                  kilometro &                independentista \\\\\n",
      "                vida &           gol minuto jugar &                         reales \\\\\n",
      "              plasma &                     jornet &                      ejecutivo \\\\\n",
      "             corazon &                   registro &                            pnv \\\\\n",
      "              grasas &                  registros &        pais vida institucional \\\\\n",
      "               grasa &                competicion &                       informes \\\\\n",
      "              partes &                   pregunta &                        informe \\\\\n",
      "               parte &                  preguntas &                          claro \\\\\n",
      "              numero &                    vaccaro &                      andalucia \\\\\n",
      "            sintomas &                  distancia &                         jueves \\\\\n",
      "             proceso &                     rondas &                 covid momentos \\\\\n",
      "            procesos &                    minutos &                      ministros \\\\\n",
      "         coronavirus &  entrenamientos distancias &                       ministro \\\\\n",
      "              unidos &                franquicias &                vicepresidentes \\\\\n",
      "               unido &                 franquicia &                      desahucio \\\\\n",
      "               fruta &                   estrella &                     desahucios \\\\\n",
      "              frutas &                  estrellas &                      impuestos \\\\\n",
      "                tipo &                 entrenador &                       impuesto \\\\\n",
      "               tipos &                      gasol &                  instituciones \\\\\n",
      "           pacientes &                bajas gente &                    institucion \\\\\n",
      "            paciente &                     debajo &                        derecho \\\\\n",
      "      moderna grupos &                situaciones &                       derechos \\\\\n",
      "               movil &                     volver &                         fiscal \\\\\n",
      "             moviles &                      mundo &                       fiscales \\\\\n",
      "           autentica &                      unico &                        militar \\\\\n",
      "          autenticas &                     unicos &                      militares \\\\\n",
      "               mucho &                   primeras &                       proyecto \\\\\n",
      "              muchos &                    primera &                          bildu \\\\\n",
      "             produce &                       club &                     madrilenos \\\\\n",
      "            expertos &                  balonmano &                      madrileno \\\\\n",
      "             experto &            seleccion ronda &                       noticias \\\\\n",
      "        mundo dietas &                       pasa &                        noticia \\\\\n",
      "             ejemplo &       pistas entrenamiento &                      generales \\\\\n",
      "            ejemplos &                     agente &                          notas \\\\\n",
      "             jovenes &                    agentes &                           nota \\\\\n",
      "               joven &                     lakers &                      seguridad \\\\\n",
      "         metabolismo &              recien salida &                          padre \\\\\n",
      "              paises &                    jornada &                         padres \\\\\n",
      "            contagio &                   jornadas &                        moncloa \\\\\n",
      "           contagios &                    montana &                         unidas \\\\\n",
      "         tratamiento &                     puesto &                         isabel \\\\\n",
      "        tratamientos &                       esta &                         social \\\\\n",
      "           bacterias &                     prueba &                       sociales \\\\\n",
      "            bacteria &                    pruebas &                        sanidad \\\\\n",
      "                pais &                     cambio &                         casado \\\\\n",
      "            probable &                    cambios &                           jose \\\\\n",
      "            cantidad &                     maxima &                     diaz ayuso \\\\\n",
      "          cantidades &                    maximas &                  informaciones \\\\\n",
      "            modernas &                    alfredo &                    informacion \\\\\n",
      "              centro &                    titulos &                  instalaciones \\\\\n",
      "             centros &                     titulo &                    instalacion \\\\\n",
      "               dieta &                   relacion &                            eta \\\\\n",
      "            realidad &                     hombre &                        delitos \\\\\n",
      "               plato &                      pista &                         delito \\\\\n",
      "              platos &                   hablando &                     presidenta \\\\\n",
      "               gente &                  realmente &                            dsn \\\\\n",
      "           problemas &                     firmar &                        momento \\\\\n",
      "            problema &                  convirtio &                         fuerza \\\\\n",
      "             general &                    segunda &                        fuerzas \\\\\n",
      "            arterias &                      ritmo &                        fuentes \\\\\n",
      "             arteria &                      todas &                         fuente \\\\\n",
      "               cifra &                      davis &              sentido asegurado \\\\\n",
      "              cifras &                selecciones &                        defensa \\\\\n",
      "             ensayos &                   fichajes &                      navidades \\\\\n",
      "              ensayo &                    fichaje &                        navidad \\\\\n",
      "       investigacion &                   esfuerzo &                     ciudadanos \\\\\n",
      "     investigaciones &                  esfuerzos &                        jimenez \\\\\n",
      "             revista &                     metros &                          zonas \\\\\n",
      "            revistas &                      queda &                           zona \\\\\n",
      "              opcion &                    noruego &                      sanitario \\\\\n",
      "            opciones &                    deporte &                     sanitarios \\\\\n",
      "             alergia &           atletas noruegos &                            muy \\\\\n",
      "            alergias &                       baja &                            NaN \\\\\n",
      "                 mas &                     atleta &                            NaN \\\\\n",
      "               tasas &                        NaN &                            NaN \\\\\n",
      "                tasa &                        NaN &                            NaN \\\\\n",
      "               manos &                        NaN &                            NaN \\\\\n",
      "                mano &                        NaN &                            NaN \\\\\n",
      "            cardiaco &                        NaN &                            NaN \\\\\n",
      "            suicidio &                        NaN &                            NaN \\\\\n",
      "           suicidios &                        NaN &                            NaN \\\\\n",
      "            facebook &                        NaN &                            NaN \\\\\n",
      "             musculo &                        NaN &                            NaN \\\\\n",
      "            musculos &                        NaN &                            NaN \\\\\n",
      "            hospital &                        NaN &                            NaN \\\\\n",
      "                 sal &                        NaN &                            NaN \\\\\n",
      "            estomago &                        NaN &                            NaN \\\\\n",
      "               malos &                        NaN &                            NaN \\\\\n",
      "                malo &                        NaN &                            NaN \\\\\n",
      "            vitamina &                        NaN &                            NaN \\\\\n",
      "           vitaminas &                        NaN &                            NaN \\\\\n",
      "      investigadores &                        NaN &                            NaN \\\\\n",
      "           demasiado &                        NaN &                            NaN \\\\\n",
      "           elementos &                        NaN &                            NaN \\\\\n",
      "            elemento &                        NaN &                            NaN \\\\\n",
      "             periodo &                        NaN &                            NaN \\\\\n",
      "              inmune &                        NaN &                            NaN \\\\\n",
      "          ejercicios &                        NaN &                            NaN \\\\\n",
      "           ejercicio &                        NaN &                            NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_table_keywords(keywords_gensim_health, keywords_k_gensim_sports, keywords_k_gensim_politics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:30.680897Z",
     "start_time": "2020-12-14T16:21:30.665895Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_k_kmeans_keywords(data, k):\n",
    "    data = data.copy()\n",
    "    data[\"joined\"] = data[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "    k_means_data = data[\"joined\"].values\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "    X = vectorizer.fit_transform(k_means_data)\n",
    "    \n",
    "    model = KMeans(n_clusters=3, init='k-means++', max_iter=1000, n_init=1, random_state = 5, algorithm=\"full\")\n",
    "    model.fit(X)\n",
    "    \n",
    "    order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    \n",
    "    keywords_kmeans_politics = [terms[ind] for ind in order_centroids[0, :k]]\n",
    "    keywords_kmeans_health = [terms[ind] for ind in order_centroids[1, :k]]\n",
    "    keywords_kmeans_sports = [terms[ind] for ind in order_centroids[2, :k]]\n",
    "    \n",
    "    return keywords_kmeans_politics, keywords_kmeans_health, keywords_kmeans_sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:30.788899Z",
     "start_time": "2020-12-14T16:21:30.683895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n",
      "D1 no tiene madrid\n",
      "D3 no tiene sánchez\n",
      "D1 no tiene mundo\n",
      "D3 no tiene españa\n",
      "D3 no tiene psoe\n",
      "D3 no tiene partido\n",
      "D3 no tiene presidente\n",
      "D3 no tiene gobierno\n",
      "D3 no tiene pedro sánchez\n",
      "D1 no tiene infarto\n",
      "D3 no tiene real\n",
      "D3 no tiene rey\n",
      "D1 no tiene forma\n",
      "D3 no tiene pedro\n",
      "D3 no tiene fiscal\n",
      "D1 no tiene estudio\n",
      "88 83 94\n"
     ]
    }
   ],
   "source": [
    "keywords_kmeans_politics, keywords_kmeans_health, keywords_kmeans_sports = get_k_kmeans_keywords(train_data, 100)\n",
    "print(len(keywords_kmeans_politics), len(keywords_kmeans_health), len(keywords_kmeans_sports))\n",
    "keywords_kmeans_politics, keywords_kmeans_health, keywords_kmeans_sports = remove_duplicates(keywords_kmeans_politics, keywords_kmeans_health, keywords_kmeans_sports)\n",
    "print(len(keywords_kmeans_politics), len(keywords_kmeans_health), len(keywords_kmeans_sports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:30.800896Z",
     "start_time": "2020-12-14T16:21:30.790898Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "             health &           sports &                politics \\\\\n",
      "\\midrule\n",
      "                día &           equipo &                     erc \\\\\n",
      "         enfermedad &          jugador &                   marín \\\\\n",
      "              covid &             liga &                     ley \\\\\n",
      "           nacional &           jordan &            presupuestos \\\\\n",
      "              horas &              nba &                  felipe \\\\\n",
      "           pandemia &        temporada &                   bildu \\\\\n",
      "           personas &            goles &                gonzález \\\\\n",
      "       tuberculosis &          vaccaro &                proyecto \\\\\n",
      "              grupo &            gasol &                 sistema \\\\\n",
      "               días &         contrato &                  jueves \\\\\n",
      "          teléfonos &             base &  presupuestos generales \\\\\n",
      "        coronavirus &         millones &               generales \\\\\n",
      "              casos &      metabolismo &         felipe gonzález \\\\\n",
      "              ayuso &            juego &               erc bildu \\\\\n",
      "          comunidad &           lakers &                acuerdos \\\\\n",
      "              virus &          haaland &               andalucía \\\\\n",
      "             récord &         facebook &                sociedad \\\\\n",
      "             plasma &           cuerpo &        independentistas \\\\\n",
      "             comida &          mercado &                congreso \\\\\n",
      "            móviles &        auténtica &          vicepresidente \\\\\n",
      "             sangre &              año &                   euros \\\\\n",
      "          contagios &       entrenador &                indicado \\\\\n",
      "         madrileños &            jugar &                   claro \\\\\n",
      "             número &           hombre &              socialista \\\\\n",
      "               tipo &          escolta &                iglesias \\\\\n",
      "             semana &         competir &             comunidades \\\\\n",
      "             vacuna &             duro &               españoles \\\\\n",
      "          seguridad &         atlético &                     vox \\\\\n",
      "            stéfano &           puntos &               eutanasia \\\\\n",
      "        anticuerpos &             masa &                     eta \\\\\n",
      "              salud &           volver &                   quizá \\\\\n",
      "                ola &            pívot &               diputados \\\\\n",
      "               país &      competición &               autónomas \\\\\n",
      "           vivienda &             nike &   comunidades autónomas \\\\\n",
      "       ayuntamiento &            magra &     armonización fiscal \\\\\n",
      "  teléfonos móviles &       masa magra &            armonización \\\\\n",
      "            defensa &            gente &     presidente gobierno \\\\\n",
      "               díaz &          raptors &                  callar \\\\\n",
      "            sanidad &           lesión &                   iceta \\\\\n",
      "              marca &   redes sociales &            financiación \\\\\n",
      "             europa &       temporadas &                   pablo \\\\\n",
      "          balonmano &            curry &              proetarras \\\\\n",
      "            familia &         warriors &               azurmendi \\\\\n",
      "             centro &         thompson &        jiménez becerril \\\\\n",
      "             riesgo &        jugadores &                becerril \\\\\n",
      "               caso &       franquicia &                     mal \\\\\n",
      "            alergia &              gol &          pablo iglesias \\\\\n",
      "         díaz ayuso &             suns &                     pge \\\\\n",
      "         importante &        realmente &                     pnv \\\\\n",
      "          situación &            redes &                 jiménez \\\\\n",
      "          miocardio &   investigadores &               izquierda \\\\\n",
      "            corazón &          energía &                    jefe \\\\\n",
      "           política &           recién &             inmunitario \\\\\n",
      "             frente &        champions &                   sueño \\\\\n",
      "            moderna &         campazzo &     sistema inmunitario \\\\\n",
      "          principal &            ricky &              ciudadanos \\\\\n",
      "            supremo &              the &                  código \\\\\n",
      "            muertes &             marc &                injurias \\\\\n",
      "            jóvenes &        campeones &            código penal \\\\\n",
      "               juan &          llegado &                   ascen \\\\\n",
      "        juan carlos &        convirtió &              regulación \\\\\n",
      "           estudios &             tasa &                    malo \\\\\n",
      "           comisión &          dólares &                atención \\\\\n",
      "              media &             vida &                   junta \\\\\n",
      "            alfredo &              bla &            separatistas \\\\\n",
      "          impuestos &       metabólica &            manda callar \\\\\n",
      "              pecho &  tasa metabólica &                  afecta \\\\\n",
      "          alimentos &         sociales &           generales pge \\\\\n",
      "           síntomas &           tantos &                    casa \\\\\n",
      "        tratamiento &            pasar &                esquerra \\\\\n",
      "           ministro &     personalidad &             republicana \\\\\n",
      "             jornet &         dortmund &    esquerra republicana \\\\\n",
      "              pista &         hablando &               ocasiones \\\\\n",
      "           decisión &          difícil &                  lengua \\\\\n",
      "            medidas &           fútbol &                   penal \\\\\n",
      "          noviembre &              sal &                banderas \\\\\n",
      " seguridad nacional &   michael jordan &               casa real \\\\\n",
      "                dsn &             pasa &                obligado \\\\\n",
      "           informes &            draft &                    cosa \\\\\n",
      "           expertos &           firmar &            medicamentos \\\\\n",
      "         fallecidos &         partidos &                 alberto \\\\\n",
      "          ejecutivo &         historia &                 barrios \\\\\n",
      "             países &          acuerdo &                   líder \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_table_keywords(keywords_kmeans_health, keywords_kmeans_sports, keywords_kmeans_politics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formación del glosario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:30.814895Z",
     "start_time": "2020-12-14T16:21:30.801896Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_relevant_keywords(d1, d2, d3):\n",
    "    i1 = set(d1) & set(d2)\n",
    "    i2 = set(d1) & set(d3)\n",
    "    i3 = set(d2) & set(d3)\n",
    "    \n",
    "    deleted = set(list(i1.union(i2).union(i3)))\n",
    "    return deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:30.847895Z",
     "start_time": "2020-12-14T16:21:30.815895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politics ==>  ['erc', 'presupuestos generales', 'instituciones', 'eutanasia', 'jiménez becerril', 'navidades', 'ley', 'generales', 'congreso', 'claro', 'comunidades', 'penal', 'código penal', 'diputados', 'becerril', 'jueves', 'mal', 'texto', 'ayuntamiento', 'dsn', 'pablo iglesias', 'eta', 'vox', 'notas', 'callar', 'casa real', 'informes', 'injurias', 'regulación', 'sociedad', 'ascen', 'acuerdos', 'marín', 'desahucio', 'ciudadanos', 'iceta', 'presupuestos', 'militares', 'vivienda', 'armonización fiscal', 'proyecto', 'felipe gonzález', 'ministro', 'gonzález', 'código', 'armonización', 'azurmendi', 'pnv', 'bildu', 'independentistas', 'atención', 'alberto']\n",
      "Sports ==>  ['jugador', 'mercado', 'volver', 'escolta', 'hombre', 'juego', 'competir', 'jornet', 'realmente', 'bla', 'balonmano', 'liga', 'atlético', 'firmar', 'gasol', 'michael jordan', 'alfredo', 'thompson', 'bolt', 'lakers', 'warriors', 'nike', 'equipo', 'haaland', 'curry', 'campeones', 'dortmund', 'pasa', 'vaccaro', 'situaciones', 'jugadores', 'equipos', 'goles', 'entrenador', 'ricky', 'temporadas', 'rehabilitación', 'hablando', 'lesión', 'gol', 'campazzo', 'jordan', 'temporada', 'duro', 'historia', 'franquicia', 'marc', 'pista', 'estrella', 'grupos', 'barça', 'base']\n",
      "Health ==>  ['facebook', 'suicidio', 'riesgo', 'teléfonos móviles', 'comida', 'covid', 'tuberculosis', 'anticuerpos', 'vacuna', 'caso', 'estudios', 'fallecidos', 'teléfonos', 'alimentos', 'tipo', 'frente', 'suicidios', 'móviles', 'sangre', 'alergia', 'pecho', 'plasma', 'metabolismo', 'tratamiento', 'fruta', 'sistema', 'salud', 'infarto', 'alergias', 'ensayo', 'centro', 'virus', 'sanidad', 'enfermedad', 'expertos', 'coronavirus', 'tasa', 'contagios', 'importante', 'plato', 'miocardio', 'muertes', 'moderna']\n"
     ]
    }
   ],
   "source": [
    "relevant_keywords_politics = list(check_relevant_keywords(keywords_kmeans_politics, keywords_gensim_politics, keywords_tfidf_politics))\n",
    "relevant_keywords_health = list(check_relevant_keywords(keywords_kmeans_health, keywords_gensim_health, keywords_tfidf_health))\n",
    "relevant_keywords_sports = list(check_relevant_keywords(keywords_kmeans_sports, keywords_gensim_sports, keywords_tfidf_sports))\n",
    "\n",
    "print(\"Politics ==> \", relevant_keywords_politics)\n",
    "print(\"Sports ==> \", relevant_keywords_sports)\n",
    "print(\"Health ==> \", relevant_keywords_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:30.859898Z",
     "start_time": "2020-12-14T16:21:30.848895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "            health &          sports &                politics \\\\\n",
      "\\midrule\n",
      "          facebook &         jugador &                     erc \\\\\n",
      "          suicidio &         mercado &  presupuestos generales \\\\\n",
      "            riesgo &          volver &           instituciones \\\\\n",
      " teléfonos móviles &         escolta &               eutanasia \\\\\n",
      "            comida &          hombre &        jiménez becerril \\\\\n",
      "             covid &           juego &               navidades \\\\\n",
      "      tuberculosis &        competir &                     ley \\\\\n",
      "       anticuerpos &          jornet &               generales \\\\\n",
      "            vacuna &       realmente &                congreso \\\\\n",
      "              caso &             bla &                   claro \\\\\n",
      "          estudios &       balonmano &             comunidades \\\\\n",
      "        fallecidos &            liga &                   penal \\\\\n",
      "         teléfonos &        atlético &            código penal \\\\\n",
      "         alimentos &          firmar &               diputados \\\\\n",
      "              tipo &           gasol &                becerril \\\\\n",
      "            frente &  michael jordan &                  jueves \\\\\n",
      "         suicidios &         alfredo &                     mal \\\\\n",
      "           móviles &        thompson &                   texto \\\\\n",
      "            sangre &            bolt &            ayuntamiento \\\\\n",
      "           alergia &          lakers &                     dsn \\\\\n",
      "             pecho &        warriors &          pablo iglesias \\\\\n",
      "            plasma &            nike &                     eta \\\\\n",
      "       metabolismo &          equipo &                     vox \\\\\n",
      "       tratamiento &         haaland &                   notas \\\\\n",
      "             fruta &           curry &                  callar \\\\\n",
      "           sistema &       campeones &               casa real \\\\\n",
      "             salud &        dortmund &                informes \\\\\n",
      "           infarto &            pasa &                injurias \\\\\n",
      "          alergias &         vaccaro &              regulación \\\\\n",
      "            ensayo &     situaciones &                sociedad \\\\\n",
      "            centro &       jugadores &                   ascen \\\\\n",
      "             virus &         equipos &                acuerdos \\\\\n",
      "           sanidad &           goles &                   marín \\\\\n",
      "        enfermedad &      entrenador &               desahucio \\\\\n",
      "          expertos &           ricky &              ciudadanos \\\\\n",
      "       coronavirus &      temporadas &                   iceta \\\\\n",
      "              tasa &  rehabilitación &            presupuestos \\\\\n",
      "         contagios &        hablando &               militares \\\\\n",
      "        importante &          lesión &                vivienda \\\\\n",
      "             plato &             gol &     armonización fiscal \\\\\n",
      "         miocardio &        campazzo &                proyecto \\\\\n",
      "           muertes &          jordan &         felipe gonzález \\\\\n",
      "           moderna &       temporada &                ministro \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_table_keywords(relevant_keywords_health, relevant_keywords_sports, relevant_keywords_politics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de glosarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:30.897897Z",
     "start_time": "2020-12-14T16:21:30.860898Z"
    }
   },
   "outputs": [],
   "source": [
    "path_keys_health = \"../keywords/keys_health.txt\"\n",
    "path_keys_sports = \"../keywords/keys_sports.txt\"\n",
    "path_keys_politics = \"../keywords/keys_politics.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:30.902898Z",
     "start_time": "2020-12-14T16:21:30.898898Z"
    }
   },
   "outputs": [],
   "source": [
    "keys_health = [key.strip() for key in open(path_keys_health, encoding=\"utf-8\").readlines()]\n",
    "keys_sports = [key.strip() for key in open(path_keys_sports, encoding=\"utf-8\").readlines()]\n",
    "keys_politics = [key.strip() for key in open(path_keys_politics, encoding=\"utf-8\").readlines()]\n",
    "\n",
    "keys_dic = {-1: \"unknown\", 0: \"health\", 1: \"sports\", 2: \"politics\"}\n",
    "inverted_keys_dic = {\"unknown\": -1, \"health\": 0, \"sports\": 1, \"politics\": 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigramas de test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.473900Z",
     "start_time": "2020-12-14T16:21:30.903896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>preprocesado</th>\n",
       "      <th>tokens</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>tokens + bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>health_23.txt</td>\n",
       "      <td>Hace unos días Alejandro Díez, madrileño de 24...</td>\n",
       "      <td>health</td>\n",
       "      <td>hace unos días alejandro díez madrileño de  añ...</td>\n",
       "      <td>[días, alejandro, díez, madrileño, años, levan...</td>\n",
       "      <td>[se trata, este tipo, se trata, ha sido, es de...</td>\n",
       "      <td>[días, alejandro, díez, madrileño, años, levan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>health_24.txt</td>\n",
       "      <td>Casi todos los planes contra el coronavirus un...</td>\n",
       "      <td>health</td>\n",
       "      <td>casi todos los planes contra el coronavirus un...</td>\n",
       "      <td>[planes, coronavirus, pase, peor, basan, inmun...</td>\n",
       "      <td>[sobre todo, se trata, frente al, segunda ola,...</td>\n",
       "      <td>[planes, coronavirus, pase, peor, basan, inmun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>health_25.txt</td>\n",
       "      <td>Un correcto descanso nocturno no sólo es impor...</td>\n",
       "      <td>health</td>\n",
       "      <td>un correcto descanso nocturno no sólo es impor...</td>\n",
       "      <td>[correcto, descanso, nocturno, importante, sen...</td>\n",
       "      <td>[frente al, frente al, cada vez, new york, más...</td>\n",
       "      <td>[correcto, descanso, nocturno, importante, sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>health_26.txt</td>\n",
       "      <td>Los problemas de sueño son cada vez más frecue...</td>\n",
       "      <td>health</td>\n",
       "      <td>los problemas de sueño son cada vez más frecue...</td>\n",
       "      <td>[problemas, sueño, frecuentes, sociedad, llega...</td>\n",
       "      <td>[muy probable, se trata, sino también, sin emb...</td>\n",
       "      <td>[problemas, sueño, frecuentes, sociedad, llega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>health_27.txt</td>\n",
       "      <td>El estrés de la rutina diaria, las preocupacio...</td>\n",
       "      <td>health</td>\n",
       "      <td>el estrés de la rutina diaria las preocupacion...</td>\n",
       "      <td>[estrés, rutina, diaria, preocupaciones, labor...</td>\n",
       "      <td>[sin embargo, más allá, sin embargo, muchas pe...</td>\n",
       "      <td>[estrés, rutina, diaria, preocupaciones, labor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>145</td>\n",
       "      <td>sports_50.txt</td>\n",
       "      <td>La cuarentena que cumplen algunas gimnastas, l...</td>\n",
       "      <td>sports</td>\n",
       "      <td>la cuarentena que cumplen algunas gimnastas la...</td>\n",
       "      <td>[cuarentena, cumplen, gimnastas, dificultades,...</td>\n",
       "      <td>[muchos casos, muchos casos, las autoridades, ...</td>\n",
       "      <td>[cuarentena, cumplen, gimnastas, dificultades,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>146</td>\n",
       "      <td>sports_6.txt</td>\n",
       "      <td>El Sevilla obtuvo en Krasnodar su billete para...</td>\n",
       "      <td>sports</td>\n",
       "      <td>el sevilla obtuvo en krasnodar su billete para...</td>\n",
       "      <td>[sevilla, obtuvo, krasnodar, billete, octavos,...</td>\n",
       "      <td>[todas las, todas las, todas las, todas las, t...</td>\n",
       "      <td>[sevilla, obtuvo, krasnodar, billete, octavos,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>147</td>\n",
       "      <td>sports_7.txt</td>\n",
       "      <td>Ronald Koeman decidió dar una oportunidad a Ca...</td>\n",
       "      <td>sports</td>\n",
       "      <td>ronald koeman decidió dar una oportunidad a ca...</td>\n",
       "      <td>[ronald, koeman, decidió, oportunidad, carles,...</td>\n",
       "      <td>[apostar por, apostar por, apostar por, frente...</td>\n",
       "      <td>[ronald, koeman, decidió, oportunidad, carles,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>148</td>\n",
       "      <td>sports_8.txt</td>\n",
       "      <td>\\nChiellini, Bonucci, Barzagli, Zambrotta...la...</td>\n",
       "      <td>sports</td>\n",
       "      <td>\\nchiellini bonucci barzagli zambrottala lista...</td>\n",
       "      <td>[chiellini, bonucci, barzagli, zambrottala, li...</td>\n",
       "      <td>[frente al, sin embargo, frente al, sin embarg...</td>\n",
       "      <td>[chiellini, bonucci, barzagli, zambrottala, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>149</td>\n",
       "      <td>sports_9.txt</td>\n",
       "      <td>Darko Brasanac es la principal novedad en la c...</td>\n",
       "      <td>sports</td>\n",
       "      <td>darko brasanac es la principal novedad en la c...</td>\n",
       "      <td>[darko, brasanac, principal, novedad, convocat...</td>\n",
       "      <td>[frente al, sin embargo, frente al, sin embarg...</td>\n",
       "      <td>[darko, brasanac, principal, novedad, convocat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       doc_name                                               text  \\\n",
       "0       15  health_23.txt  Hace unos días Alejandro Díez, madrileño de 24...   \n",
       "1       16  health_24.txt  Casi todos los planes contra el coronavirus un...   \n",
       "2       17  health_25.txt  Un correcto descanso nocturno no sólo es impor...   \n",
       "3       18  health_26.txt  Los problemas de sueño son cada vez más frecue...   \n",
       "4       19  health_27.txt  El estrés de la rutina diaria, las preocupacio...   \n",
       "..     ...            ...                                                ...   \n",
       "100    145  sports_50.txt  La cuarentena que cumplen algunas gimnastas, l...   \n",
       "101    146   sports_6.txt  El Sevilla obtuvo en Krasnodar su billete para...   \n",
       "102    147   sports_7.txt  Ronald Koeman decidió dar una oportunidad a Ca...   \n",
       "103    148   sports_8.txt  \\nChiellini, Bonucci, Barzagli, Zambrotta...la...   \n",
       "104    149   sports_9.txt  Darko Brasanac es la principal novedad en la c...   \n",
       "\n",
       "      class                                       preprocesado  \\\n",
       "0    health  hace unos días alejandro díez madrileño de  añ...   \n",
       "1    health  casi todos los planes contra el coronavirus un...   \n",
       "2    health  un correcto descanso nocturno no sólo es impor...   \n",
       "3    health  los problemas de sueño son cada vez más frecue...   \n",
       "4    health  el estrés de la rutina diaria las preocupacion...   \n",
       "..      ...                                                ...   \n",
       "100  sports  la cuarentena que cumplen algunas gimnastas la...   \n",
       "101  sports  el sevilla obtuvo en krasnodar su billete para...   \n",
       "102  sports  ronald koeman decidió dar una oportunidad a ca...   \n",
       "103  sports  \\nchiellini bonucci barzagli zambrottala lista...   \n",
       "104  sports  darko brasanac es la principal novedad en la c...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [días, alejandro, díez, madrileño, años, levan...   \n",
       "1    [planes, coronavirus, pase, peor, basan, inmun...   \n",
       "2    [correcto, descanso, nocturno, importante, sen...   \n",
       "3    [problemas, sueño, frecuentes, sociedad, llega...   \n",
       "4    [estrés, rutina, diaria, preocupaciones, labor...   \n",
       "..                                                 ...   \n",
       "100  [cuarentena, cumplen, gimnastas, dificultades,...   \n",
       "101  [sevilla, obtuvo, krasnodar, billete, octavos,...   \n",
       "102  [ronald, koeman, decidió, oportunidad, carles,...   \n",
       "103  [chiellini, bonucci, barzagli, zambrottala, li...   \n",
       "104  [darko, brasanac, principal, novedad, convocat...   \n",
       "\n",
       "                                               bigrams  \\\n",
       "0    [se trata, este tipo, se trata, ha sido, es de...   \n",
       "1    [sobre todo, se trata, frente al, segunda ola,...   \n",
       "2    [frente al, frente al, cada vez, new york, más...   \n",
       "3    [muy probable, se trata, sino también, sin emb...   \n",
       "4    [sin embargo, más allá, sin embargo, muchas pe...   \n",
       "..                                                 ...   \n",
       "100  [muchos casos, muchos casos, las autoridades, ...   \n",
       "101  [todas las, todas las, todas las, todas las, t...   \n",
       "102  [apostar por, apostar por, apostar por, frente...   \n",
       "103  [frente al, sin embargo, frente al, sin embarg...   \n",
       "104  [frente al, sin embargo, frente al, sin embarg...   \n",
       "\n",
       "                                      tokens + bigrams  \n",
       "0    [días, alejandro, díez, madrileño, años, levan...  \n",
       "1    [planes, coronavirus, pase, peor, basan, inmun...  \n",
       "2    [correcto, descanso, nocturno, importante, sen...  \n",
       "3    [problemas, sueño, frecuentes, sociedad, llega...  \n",
       "4    [estrés, rutina, diaria, preocupaciones, labor...  \n",
       "..                                                 ...  \n",
       "100  [cuarentena, cumplen, gimnastas, dificultades,...  \n",
       "101  [sevilla, obtuvo, krasnodar, billete, octavos,...  \n",
       "102  [ronald, koeman, decidió, oportunidad, carles,...  \n",
       "103  [chiellini, bonucci, barzagli, zambrottala, li...  \n",
       "104  [darko, brasanac, principal, novedad, convocat...  \n",
       "\n",
       "[105 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"bigrams\"] = test_data[\"preprocesado\"].apply(lambda x: check_bigram(x, bigrams))\n",
    "test_data[\"tokens + bigrams\"] = test_data[\"tokens\"] + test_data[\"bigrams\"]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.477897Z",
     "start_time": "2020-12-14T16:21:31.474897Z"
    }
   },
   "outputs": [],
   "source": [
    "glossaries = [keys_health, keys_sports, keys_politics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.488899Z",
     "start_time": "2020-12-14T16:21:31.478898Z"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(glossary for glossary in glossaries)\n",
    "dictionary.save('keys.dict')  # store the dictionary, for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.492899Z",
     "start_time": "2020-12-14T16:21:31.489900Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    \n",
    "    def __init__(self, docs, dictionary):\n",
    "        self.docs = docs\n",
    "        self.dict = dictionary\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for doc in self.docs:\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield self.dict.doc2bow(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.496900Z",
     "start_time": "2020-12-14T16:21:31.493899Z"
    }
   },
   "outputs": [],
   "source": [
    "bow = MyCorpus(glossaries, dictionary)\n",
    "corpora.MmCorpus.serialize(\"keys.mm\", bow, metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.504900Z",
     "start_time": "2020-12-14T16:21:31.497898Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "index_temp = get_tmpfile(\"index\")\n",
    "index = Similarity(index_temp, bow, num_features=len(dictionary))  # create index\n",
    "index.save(\"keys.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.509898Z",
     "start_time": "2020-12-14T16:21:31.505897Z"
    }
   },
   "outputs": [],
   "source": [
    "model_tfidf = models.TfidfModel(bow,smartirs=\"lpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.514897Z",
     "start_time": "2020-12-14T16:21:31.509898Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_document_tfidf(model, dictionary, bow, index, documents, i, verbose = False):\n",
    "    \"\"\"\n",
    "    Given a specific document, computes the ranking of the classes and returns the current class, \n",
    "    the predicted class and the probabilities for each class.\n",
    "    \n",
    "    \"\"\"\n",
    "    document = documents.iloc[i]\n",
    "    pq = document[\"tokens + bigrams\"]\n",
    "    vq = dictionary.doc2bow(pq)\n",
    "    qtfidf = model[vq]\n",
    "    sim = index[qtfidf]\n",
    "\n",
    "    ranking = sorted(enumerate(sim), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Document ==> \" + document[\"text\"][:100])\n",
    "        for doc, score in ranking:\n",
    "            cat = keys_dic[doc]\n",
    "            print(f\"[{cat}] ==> %.3f\" % round(score,3))\n",
    "            \n",
    "    \n",
    "    return [i, get_info_document(document, ranking, sim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.518898Z",
     "start_time": "2020-12-14T16:21:31.515898Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_info_document(document, ranking, sim):\n",
    "    \"\"\"\n",
    "    Given a ranking of classes, returns the current class, the predicted class and the probabilities for each class.\n",
    "    \n",
    "    \"\"\"\n",
    "    current_class = inverted_keys_dic[document[\"class\"]]\n",
    "    \n",
    "    if np.sum(sim) == 0.0:\n",
    "        predicted_class = -1\n",
    "        probabilities = np.array([1/3, 1/3, 1/3])\n",
    "    else:\n",
    "        predicted_class = ranking[0][0]\n",
    "        tfidf_scores = np.array(sim)\n",
    "        probabilities = tfidf_scores / np.sum(tfidf_scores)\n",
    "    \n",
    "    return {\"current_class\": current_class, \"predicted_class\": predicted_class, \n",
    "            \"probabilities\": probabilities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.526896Z",
     "start_time": "2020-12-14T16:21:31.519898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ==> La sentencia de la Audiencia Nacional que absuelve al jefe de los Mossos durante el 1-O, Josep Lluís\n",
      "[politics] ==> 0.258\n",
      "[health] ==> 0.000\n",
      "[sports] ==> 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[67,\n",
       " {'current_class': 2,\n",
       "  'predicted_class': 2,\n",
       "  'probabilities': array([0., 0., 1.], dtype=float32)}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_document_tfidf(model_tfidf, dictionary, bow, index, test_data, 67, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.529900Z",
     "start_time": "2020-12-14T16:21:31.527900Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_tfidf(function, model, dictionary, bow, index, data):\n",
    "    def classify(doc_i):\n",
    "        return function(model, dictionary, bow, index, data, doc_i)\n",
    "    return classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.569897Z",
     "start_time": "2020-12-14T16:21:31.530897Z"
    }
   },
   "outputs": [],
   "source": [
    "glossaries = [keys_health, keys_sports, keys_politics]\n",
    "model_w2v = models.Word2Vec(sentences = glossaries, window = 5, workers = 12, min_count = 1, seed=50)\n",
    "\n",
    "model_w2v.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.573900Z",
     "start_time": "2020-12-14T16:21:31.570900Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_max_min(model):\n",
    "    vocab = model.wv.vocab\n",
    "    \n",
    "    maxs = []\n",
    "    mins = []\n",
    "    \n",
    "    for key in vocab:\n",
    "        maxs.append(max(model.wv[key]))\n",
    "        mins.append(min(model.wv[key]))\n",
    "    return max(maxs), min(mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.583897Z",
     "start_time": "2020-12-14T16:21:31.574897Z"
    }
   },
   "outputs": [],
   "source": [
    "MAXI, MINI = get_max_min(model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.588897Z",
     "start_time": "2020-12-14T16:21:31.584898Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_embeddings_from_document(model, document):\n",
    "    embeddings = []\n",
    "    \n",
    "    for word in document:\n",
    "        if word in model.wv:\n",
    "            embeddings.append(model.wv[word])\n",
    "        else: # no está en el vocab\n",
    "            embeddings.append(np.random.uniform(low = MINI, high = MAXI, size = 100))\n",
    "    \n",
    "    return np.mean(embeddings, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.592898Z",
     "start_time": "2020-12-14T16:21:31.589897Z"
    }
   },
   "outputs": [],
   "source": [
    "glossaries_vector = [get_embeddings_from_document(model_w2v, glossary) for glossary in glossaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.597900Z",
     "start_time": "2020-12-14T16:21:31.593898Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_info_document_w2v(document, ranking, sim):\n",
    "    \"\"\"\n",
    "    Given a ranking of classes, returns the current class, the predicted class and the probabilities for each class.\n",
    "    \n",
    "    \"\"\"\n",
    "    current_class = inverted_keys_dic[document[\"class\"]]\n",
    "    \n",
    "    if np.count_nonzero(sim) == 0:\n",
    "        predicted_class = -1\n",
    "        probabilities = np.array([1/3, 1/3, 1/3])\n",
    "    else:\n",
    "        predicted_class = ranking[0][0]\n",
    "        w2v_scores = np.array(sim, dtype = \"float32\")\n",
    "        probabilities = (w2v_scores - w2v_scores.min()) / (w2v_scores.max() - w2v_scores.min()) \n",
    "        probabilities /= np.sum(probabilities)\n",
    "\n",
    "        \n",
    "    return {\"current_class\": current_class, \"predicted_class\": predicted_class, \n",
    "            \"probabilities\": probabilities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.602899Z",
     "start_time": "2020-12-14T16:21:31.598897Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_doc_w2v(glossaries_vector, model, documents, i, verbose = False):\n",
    "    document = documents.iloc[i]\n",
    "    doc_vector = get_embeddings_from_document(model, document[\"tokens + bigrams\"])\n",
    "\n",
    "    ranking = [[i, cosine_similarity(np.array(doc_vector).reshape(1,-1), np.array(glossary).reshape(1,-1)).item()] \n",
    "               for i, glossary in enumerate(glossaries_vector)]\n",
    "    \n",
    "    sim = [rank[1] for rank in ranking] \n",
    "    \n",
    "    ranking.sort(key = lambda x: x[1], reverse = True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Document ==> \" + document[\"text\"][:100])\n",
    "        print(\"Scores:\")\n",
    "        for doc, score in ranking:\n",
    "            cat = keys_dic[doc]\n",
    "            print(f\"[{cat}] ==> %.3f\" % round(score,3))\n",
    "    \n",
    "    return [i, get_info_document_w2v(document, ranking, sim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.610900Z",
     "start_time": "2020-12-14T16:21:31.603898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ==> El cerebro de los mamíferos está compuesto por dos lados, o hemisferios, que conecta los tractos ner\n",
      "Scores:\n",
      "[health] ==> 0.064\n",
      "[politics] ==> 0.033\n",
      "[sports] ==> -0.047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " {'current_class': 0,\n",
       "  'predicted_class': 0,\n",
       "  'probabilities': array([0.5830674 , 0.        , 0.41693264], dtype=float32)}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_doc_w2v(glossaries_vector, model_w2v, test_data, 16, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.614898Z",
     "start_time": "2020-12-14T16:21:31.611897Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_w2v(function, glossaries_vector, model, data):\n",
    "    def classify(doc_i):\n",
    "        return function(glossaries_vector, model, data, doc_i)\n",
    "    return classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.620896Z",
     "start_time": "2020-12-14T16:21:31.615897Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_doc_bayes(classifier, documents, i, verbose = False):\n",
    "    doc = documents.iloc[i]\n",
    "    #doc = vectorizer.transform([document[\"preprocesado\"]])\n",
    "    \n",
    "    y_pred = classifier.predict_proba([doc[\"preprocesado\"]])[0]\n",
    "    \n",
    "    ranking = [[i,prob] for i,prob in enumerate(y_pred)]\n",
    "    \n",
    "    probabilities = y_pred\n",
    "    \n",
    "    ranking.sort(key = lambda x: x[1], reverse = True)\n",
    "    \n",
    "    current_class = inverted_keys_dic[doc[\"class\"]]\n",
    "    predicted_class = ranking[0][0]\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Document ==> \" + doc[\"text\"][:100])\n",
    "        print(\"Scores:\")\n",
    "        for doc, score in ranking:\n",
    "            cat = keys_dic[doc]\n",
    "            print(f\"[{cat}] ==> %.3f\" % round(score,3))\n",
    "    \n",
    "    return [i, {\"current_class\": current_class, \"predicted_class\": predicted_class, \n",
    "            \"probabilities\": probabilities}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.627898Z",
     "start_time": "2020-12-14T16:21:31.621900Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_bayes(function, clf, documents):\n",
    "    def classify(doc_i):\n",
    "        return function(clf, documents, doc_i)\n",
    "    return classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.637897Z",
     "start_time": "2020-12-14T16:21:31.628896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glossaries_joined = [\" \".join(gloss) for gloss in glossaries]\n",
    "\n",
    "X_train = glossaries_joined\n",
    "y_train = [0,1,2]\n",
    "\n",
    "clf = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "                     ('clf', MultinomialNB(alpha=1e-1))])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.644897Z",
     "start_time": "2020-12-14T16:21:31.638898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ==> \n",
      "Chiellini, Bonucci, Barzagli, Zambrotta...la lista de defensas italianos que han triunfado y elevad\n",
      "Scores:\n",
      "[sports] ==> 0.749\n",
      "[health] ==> 0.126\n",
      "[politics] ==> 0.125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[103,\n",
       " {'current_class': 1,\n",
       "  'predicted_class': 1,\n",
       "  'probabilities': array([0.12635959, 0.7486078 , 0.12503262])}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_doc_bayes(clf, test_data, 103, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.648898Z",
     "start_time": "2020-12-14T16:21:31.645899Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_documents(test_data, classify):\n",
    "    \"\"\"\n",
    "    Classifies the documents given a specific classification function.\n",
    "    \n",
    "    \"\"\"\n",
    "    test_data = test_data.copy()\n",
    "    \n",
    "    infos = [classify(i) for i in range(len(test_data))]\n",
    "    data = fill_test_data(test_data, infos)\n",
    "        \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.653899Z",
     "start_time": "2020-12-14T16:21:31.649898Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_test_data(test_data, infos):\n",
    "    \"\"\"\n",
    "    Auxiliary function to fill the dataframe with info about the classification.\n",
    "    \n",
    "    \"\"\"\n",
    "    data = test_data.copy()\n",
    "    current_class = pd.Series([info[1][\"current_class\"] for info in infos])\n",
    "    predicted_class = pd.Series([info[1][\"predicted_class\"] for info in infos])\n",
    "    p_health = pd.Series([info[1][\"probabilities\"][0] for info in infos])\n",
    "    p_sports = pd.Series([info[1][\"probabilities\"][1] for info in infos])\n",
    "    p_politics = pd.Series([info[1][\"probabilities\"][2] for info in infos])\n",
    "\n",
    "    data[\"current_class\"] = current_class\n",
    "    data[\"predicted_class\"] = predicted_class\n",
    "    data[\"p_health\"] = p_health\n",
    "    data[\"p_sports\"] = p_sports\n",
    "    data[\"p_politics\"] = p_politics\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.658900Z",
     "start_time": "2020-12-14T16:21:31.654896Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_filename(df):\n",
    "    \"\"\"\n",
    "    Computes the filename for each document based on the performed classification.\n",
    "    \n",
    "    \"\"\"\n",
    "    confidence = \"%.3f\" % df[\"confidence\"]\n",
    "    current_class = df[\"class\"]\n",
    "    predicted_class = df[\"predicted_class_name\"]\n",
    "    correct = current_class == predicted_class\n",
    "    name = df[\"doc_name\"].split(\".\")[0]\n",
    "    \n",
    "    return f\"../classification/{predicted_class}/{confidence}_{name}-{correct}-{current_class}-{predicted_class}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.662899Z",
     "start_time": "2020-12-14T16:21:31.659899Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_file(path, content):\n",
    "    \"\"\"\n",
    "    Writes a file given its path and content.\n",
    "    \n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding = \"utf-8\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:31.669897Z",
     "start_time": "2020-12-14T16:21:31.663898Z"
    }
   },
   "outputs": [],
   "source": [
    "def move_files(data, tables=True):\n",
    "    \"\"\"\n",
    "    Moves the files to their corresponding new directory after classification is done.\n",
    "\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    classes = [[0, \"p_health\"], [1, \"p_sports\"], [2, \"p_politics\"]]\n",
    "\n",
    "    for cl in classes:\n",
    "        docs = data[data[\"current_class\"] == cl[0]]\n",
    "        docs = docs.sort_values(by=[cl[1]], ascending=False)\n",
    "        docs[\"predicted_class_name\"] = docs[\"predicted_class\"].apply(\n",
    "            lambda x: keys_dic[x])\n",
    "        docs[\"confidence\"] = docs[[\"p_health\",\n",
    "                                   \"p_sports\", \"p_politics\"]].max(axis=1)\n",
    "        docs[\"file\"] = docs.apply(lambda x: get_filename(x), axis=1)\n",
    "        docs.apply(lambda row: write_file(row[\"file\"], row[\"text\"]), axis=1)\n",
    "        if tables:\n",
    "            # tabla para la memoria\n",
    "            docs = docs[[\"doc_name\", \"class\", \"p_health\",\n",
    "                         \"p_sports\", \"p_politics\", \"predicted_class_name\"]]\n",
    "            docs = docs.rename(\n",
    "                columns={\"predicted_class_name\": \"predicted_class\"})\n",
    "            print(docs.to_latex(bold_rows=True, float_format=\"%.2f\",\n",
    "                                column_format=\"llllll\", index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:57.315937Z",
     "start_time": "2020-12-14T16:21:57.311929Z"
    }
   },
   "outputs": [],
   "source": [
    "def execute(test_data, classification_function, move = True, tables = False):\n",
    "    \"\"\"\n",
    "    General function that classifies the documents.\n",
    "    \n",
    "    \"\"\"\n",
    "    data = test_data.copy()\n",
    "    print(\"############################################################\")\n",
    "    print(\"Starting document´s classification...\")\n",
    "    data = classify_documents(data, classification_function)\n",
    "    sleep(1)\n",
    "    print(\"Document´s classification done...\")\n",
    "    if move:\n",
    "        print(\"-----------------------------------------------------------\")\n",
    "        sleep(1)\n",
    "        print(\"Moving files to the correct directories...\")\n",
    "        move_files(data)\n",
    "        sleep(1)\n",
    "        print(\"Files moved.\")\n",
    "    print(\"############################################################\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:39:43.330101Z",
     "start_time": "2020-12-14T16:39:33.734467Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "Starting document´s classification...\n",
      "Document´s classification done...\n",
      "-----------------------------------------------------------\n",
      "Moving files to the correct directories...\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " health\\_43.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      "  health\\_7.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      " health\\_48.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      "  health\\_3.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      " health\\_28.txt &  health &      0.94 &      0.06 &        0.00 &          health \\\\\n",
      " health\\_24.txt &  health &      0.90 &      0.07 &        0.03 &          health \\\\\n",
      " health\\_47.txt &  health &      0.88 &      0.12 &        0.00 &          health \\\\\n",
      " health\\_49.txt &  health &      0.88 &      0.00 &        0.12 &          health \\\\\n",
      " health\\_41.txt &  health &      0.88 &      0.12 &        0.00 &          health \\\\\n",
      "  health\\_6.txt &  health &      0.88 &      0.12 &        0.00 &          health \\\\\n",
      " health\\_35.txt &  health &      0.87 &      0.13 &        0.00 &          health \\\\\n",
      " health\\_45.txt &  health &      0.85 &      0.15 &        0.00 &          health \\\\\n",
      " health\\_23.txt &  health &      0.85 &      0.15 &        0.00 &          health \\\\\n",
      " health\\_34.txt &  health &      0.84 &      0.16 &        0.00 &          health \\\\\n",
      " health\\_46.txt &  health &      0.82 &      0.00 &        0.18 &          health \\\\\n",
      "  health\\_8.txt &  health &      0.81 &      0.00 &        0.19 &          health \\\\\n",
      " health\\_25.txt &  health &      0.78 &      0.11 &        0.11 &          health \\\\\n",
      " health\\_39.txt &  health &      0.77 &      0.23 &        0.00 &          health \\\\\n",
      " health\\_32.txt &  health &      0.76 &      0.24 &        0.00 &          health \\\\\n",
      "  health\\_9.txt &  health &      0.72 &      0.28 &        0.00 &          health \\\\\n",
      " health\\_30.txt &  health &      0.71 &      0.03 &        0.26 &          health \\\\\n",
      " health\\_36.txt &  health &      0.71 &      0.00 &        0.29 &          health \\\\\n",
      " health\\_42.txt &  health &      0.70 &      0.30 &        0.00 &          health \\\\\n",
      " health\\_31.txt &  health &      0.69 &      0.10 &        0.21 &          health \\\\\n",
      " health\\_50.txt &  health &      0.67 &      0.33 &        0.00 &          health \\\\\n",
      " health\\_26.txt &  health &      0.67 &      0.00 &        0.33 &          health \\\\\n",
      " health\\_44.txt &  health &      0.67 &      0.33 &        0.00 &          health \\\\\n",
      "  health\\_5.txt &  health &      0.62 &      0.09 &        0.28 &          health \\\\\n",
      " health\\_29.txt &  health &      0.57 &      0.25 &        0.18 &          health \\\\\n",
      " health\\_40.txt &  health &      0.50 &      0.00 &        0.50 &          health \\\\\n",
      " health\\_27.txt &  health &      0.47 &      0.53 &        0.00 &          sports \\\\\n",
      "  health\\_4.txt &  health &      0.25 &      0.50 &        0.25 &          sports \\\\\n",
      " health\\_38.txt &  health &      0.22 &      0.56 &        0.22 &          sports \\\\\n",
      " health\\_37.txt &  health &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " health\\_33.txt &  health &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " sports\\_49.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_30.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_43.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_24.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_37.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_34.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_33.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "  sports\\_5.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_41.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "  sports\\_3.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "  sports\\_6.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_28.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "  sports\\_7.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_26.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "  sports\\_8.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_47.txt &  sports &      0.03 &      0.97 &        0.00 &          sports \\\\\n",
      "  sports\\_9.txt &  sports &      0.08 &      0.92 &        0.00 &          sports \\\\\n",
      " sports\\_46.txt &  sports &      0.08 &      0.92 &        0.00 &          sports \\\\\n",
      " sports\\_42.txt &  sports &      0.04 &      0.88 &        0.08 &          sports \\\\\n",
      " sports\\_40.txt &  sports &      0.13 &      0.87 &        0.00 &          sports \\\\\n",
      " sports\\_44.txt &  sports &      0.17 &      0.83 &        0.00 &          sports \\\\\n",
      " sports\\_23.txt &  sports &      0.20 &      0.80 &        0.00 &          sports \\\\\n",
      "  sports\\_4.txt &  sports &      0.20 &      0.80 &        0.00 &          sports \\\\\n",
      " sports\\_29.txt &  sports &      0.20 &      0.80 &        0.00 &          sports \\\\\n",
      " sports\\_45.txt &  sports &      0.25 &      0.75 &        0.00 &          sports \\\\\n",
      " sports\\_38.txt &  sports &      0.00 &      0.67 &        0.33 &          sports \\\\\n",
      " sports\\_50.txt &  sports &      0.36 &      0.64 &        0.00 &          sports \\\\\n",
      " sports\\_36.txt &  sports &      0.50 &      0.50 &        0.00 &          health \\\\\n",
      " sports\\_48.txt &  sports &      0.53 &      0.47 &        0.00 &          health \\\\\n",
      " sports\\_31.txt &  sports &      0.53 &      0.47 &        0.00 &          health \\\\\n",
      " sports\\_32.txt &  sports &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " sports\\_27.txt &  sports &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " sports\\_39.txt &  sports &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " sports\\_35.txt &  sports &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      " sports\\_25.txt &  sports &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "        doc\\_name &     class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " politics\\_46.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      "  politics\\_8.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      "  politics\\_7.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      " politics\\_30.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      " politics\\_43.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      " politics\\_45.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      " politics\\_24.txt &  politics &      0.04 &      0.00 &        0.96 &        politics \\\\\n",
      " politics\\_27.txt &  politics &      0.05 &      0.00 &        0.95 &        politics \\\\\n",
      "  politics\\_4.txt &  politics &      0.00 &      0.10 &        0.90 &        politics \\\\\n",
      " politics\\_28.txt &  politics &      0.00 &      0.10 &        0.90 &        politics \\\\\n",
      " politics\\_32.txt &  politics &      0.13 &      0.00 &        0.87 &        politics \\\\\n",
      " politics\\_26.txt &  politics &      0.08 &      0.08 &        0.84 &        politics \\\\\n",
      "  politics\\_5.txt &  politics &      0.20 &      0.00 &        0.80 &        politics \\\\\n",
      " politics\\_48.txt &  politics &      0.04 &      0.18 &        0.78 &        politics \\\\\n",
      " politics\\_41.txt &  politics &      0.00 &      0.22 &        0.78 &        politics \\\\\n",
      " politics\\_23.txt &  politics &      0.24 &      0.00 &        0.76 &        politics \\\\\n",
      " politics\\_33.txt &  politics &      0.03 &      0.21 &        0.76 &        politics \\\\\n",
      " politics\\_36.txt &  politics &      0.04 &      0.27 &        0.69 &        politics \\\\\n",
      " politics\\_34.txt &  politics &      0.17 &      0.14 &        0.69 &        politics \\\\\n",
      " politics\\_39.txt &  politics &      0.22 &      0.11 &        0.67 &        politics \\\\\n",
      " politics\\_47.txt &  politics &      0.17 &      0.17 &        0.67 &        politics \\\\\n",
      " politics\\_25.txt &  politics &      0.17 &      0.17 &        0.67 &        politics \\\\\n",
      "  politics\\_9.txt &  politics &      0.26 &      0.09 &        0.66 &        politics \\\\\n",
      " politics\\_37.txt &  politics &      0.00 &      0.35 &        0.65 &        politics \\\\\n",
      " politics\\_40.txt &  politics &      0.06 &      0.30 &        0.64 &        politics \\\\\n",
      " politics\\_42.txt &  politics &      0.00 &      0.43 &        0.57 &        politics \\\\\n",
      " politics\\_35.txt &  politics &      0.00 &      0.45 &        0.55 &        politics \\\\\n",
      " politics\\_38.txt &  politics &      0.29 &      0.21 &        0.51 &        politics \\\\\n",
      " politics\\_29.txt &  politics &      0.35 &      0.17 &        0.48 &        politics \\\\\n",
      " politics\\_44.txt &  politics &      0.36 &      0.17 &        0.48 &        politics \\\\\n",
      " politics\\_50.txt &  politics &      0.53 &      0.00 &        0.47 &          health \\\\\n",
      "  politics\\_3.txt &  politics &      0.56 &      0.00 &        0.44 &          health \\\\\n",
      " politics\\_49.txt &  politics &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " politics\\_31.txt &  politics &      0.71 &      0.00 &        0.29 &          health \\\\\n",
      "  politics\\_6.txt &  politics &      0.70 &      0.05 &        0.25 &          health \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved.\n",
      "############################################################\n",
      "############################################################\n",
      "Starting document´s classification...\n",
      "Document´s classification done...\n",
      "-----------------------------------------------------------\n",
      "Moving files to the correct directories...\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " health\\_44.txt &  health &      0.92 &      0.08 &        0.00 &          health \\\\\n",
      " health\\_50.txt &  health &      0.92 &      0.08 &        0.00 &          health \\\\\n",
      " health\\_29.txt &  health &      0.89 &      0.00 &        0.11 &          health \\\\\n",
      " health\\_34.txt &  health &      0.85 &      0.15 &        0.00 &          health \\\\\n",
      "  health\\_3.txt &  health &      0.82 &      0.00 &        0.18 &          health \\\\\n",
      " health\\_24.txt &  health &      0.79 &      0.00 &        0.21 &          health \\\\\n",
      " health\\_35.txt &  health &      0.78 &      0.22 &        0.00 &          health \\\\\n",
      "  health\\_6.txt &  health &      0.76 &      0.24 &        0.00 &          health \\\\\n",
      " health\\_23.txt &  health &      0.74 &      0.00 &        0.26 &          health \\\\\n",
      " health\\_41.txt &  health &      0.74 &      0.26 &        0.00 &          health \\\\\n",
      " health\\_42.txt &  health &      0.73 &      0.27 &        0.00 &          health \\\\\n",
      " health\\_46.txt &  health &      0.69 &      0.31 &        0.00 &          health \\\\\n",
      " health\\_30.txt &  health &      0.68 &      0.32 &        0.00 &          health \\\\\n",
      "  health\\_9.txt &  health &      0.68 &      0.32 &        0.00 &          health \\\\\n",
      " health\\_36.txt &  health &      0.67 &      0.00 &        0.33 &          health \\\\\n",
      " health\\_28.txt &  health &      0.62 &      0.00 &        0.38 &          health \\\\\n",
      " health\\_33.txt &  health &      0.56 &      0.00 &        0.44 &          health \\\\\n",
      " health\\_49.txt &  health &      0.56 &      0.00 &        0.44 &          health \\\\\n",
      " health\\_39.txt &  health &      0.54 &      0.00 &        0.46 &          health \\\\\n",
      " health\\_43.txt &  health &      0.53 &      0.00 &        0.47 &          health \\\\\n",
      "  health\\_4.txt &  health &      0.47 &      0.53 &        0.00 &          sports \\\\\n",
      "  health\\_7.txt &  health &      0.43 &      0.00 &        0.57 &        politics \\\\\n",
      " health\\_25.txt &  health &      0.41 &      0.59 &        0.00 &          sports \\\\\n",
      "  health\\_5.txt &  health &      0.39 &      0.61 &        0.00 &          sports \\\\\n",
      " health\\_48.txt &  health &      0.32 &      0.68 &        0.00 &          sports \\\\\n",
      " health\\_40.txt &  health &      0.29 &      0.71 &        0.00 &          sports \\\\\n",
      "  health\\_8.txt &  health &      0.23 &      0.77 &        0.00 &          sports \\\\\n",
      " health\\_32.txt &  health &      0.19 &      0.00 &        0.81 &        politics \\\\\n",
      " health\\_31.txt &  health &      0.00 &      0.92 &        0.08 &          sports \\\\\n",
      " health\\_37.txt &  health &      0.00 &      0.43 &        0.57 &        politics \\\\\n",
      " health\\_27.txt &  health &      0.00 &      0.81 &        0.19 &          sports \\\\\n",
      " health\\_47.txt &  health &      0.00 &      0.04 &        0.96 &        politics \\\\\n",
      " health\\_38.txt &  health &      0.00 &      0.32 &        0.68 &        politics \\\\\n",
      " health\\_26.txt &  health &      0.00 &      0.48 &        0.52 &        politics \\\\\n",
      " health\\_45.txt &  health &      0.00 &      0.35 &        0.65 &        politics \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      "  sports\\_6.txt &  sports &      0.00 &      0.95 &        0.05 &          sports \\\\\n",
      " sports\\_40.txt &  sports &      0.00 &      0.94 &        0.06 &          sports \\\\\n",
      " sports\\_28.txt &  sports &      0.07 &      0.93 &        0.00 &          sports \\\\\n",
      " sports\\_33.txt &  sports &      0.00 &      0.88 &        0.12 &          sports \\\\\n",
      " sports\\_42.txt &  sports &      0.00 &      0.85 &        0.15 &          sports \\\\\n",
      " sports\\_23.txt &  sports &      0.00 &      0.83 &        0.17 &          sports \\\\\n",
      " sports\\_29.txt &  sports &      0.00 &      0.81 &        0.19 &          sports \\\\\n",
      " sports\\_34.txt &  sports &      0.00 &      0.80 &        0.20 &          sports \\\\\n",
      " sports\\_50.txt &  sports &      0.20 &      0.80 &        0.00 &          sports \\\\\n",
      "  sports\\_8.txt &  sports &      0.20 &      0.80 &        0.00 &          sports \\\\\n",
      "  sports\\_5.txt &  sports &      0.21 &      0.79 &        0.00 &          sports \\\\\n",
      " sports\\_48.txt &  sports &      0.21 &      0.79 &        0.00 &          sports \\\\\n",
      " sports\\_49.txt &  sports &      0.26 &      0.74 &        0.00 &          sports \\\\\n",
      " sports\\_46.txt &  sports &      0.30 &      0.70 &        0.00 &          sports \\\\\n",
      " sports\\_43.txt &  sports &      0.00 &      0.68 &        0.32 &          sports \\\\\n",
      " sports\\_47.txt &  sports &      0.00 &      0.66 &        0.34 &          sports \\\\\n",
      "  sports\\_9.txt &  sports &      0.00 &      0.66 &        0.34 &          sports \\\\\n",
      " sports\\_27.txt &  sports &      0.37 &      0.63 &        0.00 &          sports \\\\\n",
      " sports\\_30.txt &  sports &      0.00 &      0.62 &        0.38 &          sports \\\\\n",
      " sports\\_26.txt &  sports &      0.00 &      0.56 &        0.44 &          sports \\\\\n",
      " sports\\_24.txt &  sports &      0.00 &      0.54 &        0.46 &          sports \\\\\n",
      " sports\\_45.txt &  sports &      0.46 &      0.54 &        0.00 &          sports \\\\\n",
      "  sports\\_4.txt &  sports &      0.00 &      0.53 &        0.47 &          sports \\\\\n",
      " sports\\_44.txt &  sports &      0.00 &      0.51 &        0.49 &          sports \\\\\n",
      "  sports\\_7.txt &  sports &      0.00 &      0.26 &        0.74 &        politics \\\\\n",
      " sports\\_25.txt &  sports &      0.00 &      0.22 &        0.78 &        politics \\\\\n",
      " sports\\_31.txt &  sports &      0.81 &      0.19 &        0.00 &          health \\\\\n",
      " sports\\_38.txt &  sports &      0.00 &      0.03 &        0.97 &        politics \\\\\n",
      "  sports\\_3.txt &  sports &      0.79 &      0.00 &        0.21 &          health \\\\\n",
      " sports\\_32.txt &  sports &      0.25 &      0.00 &        0.75 &        politics \\\\\n",
      " sports\\_35.txt &  sports &      0.42 &      0.00 &        0.58 &        politics \\\\\n",
      " sports\\_36.txt &  sports &      0.33 &      0.00 &        0.67 &        politics \\\\\n",
      " sports\\_37.txt &  sports &      0.39 &      0.00 &        0.61 &        politics \\\\\n",
      " sports\\_41.txt &  sports &      0.10 &      0.00 &        0.90 &        politics \\\\\n",
      " sports\\_39.txt &  sports &      0.20 &      0.00 &        0.80 &        politics \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "        doc\\_name &     class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " politics\\_26.txt &  politics &      0.04 &      0.00 &        0.96 &        politics \\\\\n",
      " politics\\_43.txt &  politics &      0.00 &      0.12 &        0.88 &        politics \\\\\n",
      " politics\\_40.txt &  politics &      0.17 &      0.00 &        0.83 &        politics \\\\\n",
      " politics\\_45.txt &  politics &      0.00 &      0.18 &        0.82 &        politics \\\\\n",
      "  politics\\_4.txt &  politics &      0.00 &      0.18 &        0.82 &        politics \\\\\n",
      "  politics\\_3.txt &  politics &      0.00 &      0.19 &        0.81 &        politics \\\\\n",
      " politics\\_46.txt &  politics &      0.00 &      0.21 &        0.79 &        politics \\\\\n",
      " politics\\_27.txt &  politics &      0.00 &      0.22 &        0.78 &        politics \\\\\n",
      " politics\\_38.txt &  politics &      0.22 &      0.00 &        0.78 &        politics \\\\\n",
      " politics\\_24.txt &  politics &      0.24 &      0.00 &        0.76 &        politics \\\\\n",
      " politics\\_34.txt &  politics &      0.25 &      0.00 &        0.75 &        politics \\\\\n",
      "  politics\\_8.txt &  politics &      0.00 &      0.25 &        0.75 &        politics \\\\\n",
      " politics\\_36.txt &  politics &      0.00 &      0.27 &        0.73 &        politics \\\\\n",
      " politics\\_28.txt &  politics &      0.00 &      0.30 &        0.70 &        politics \\\\\n",
      " politics\\_41.txt &  politics &      0.30 &      0.00 &        0.70 &        politics \\\\\n",
      " politics\\_33.txt &  politics &      0.30 &      0.00 &        0.70 &        politics \\\\\n",
      "  politics\\_7.txt &  politics &      0.00 &      0.31 &        0.69 &        politics \\\\\n",
      " politics\\_32.txt &  politics &      0.39 &      0.00 &        0.61 &        politics \\\\\n",
      " politics\\_23.txt &  politics &      0.00 &      0.40 &        0.60 &        politics \\\\\n",
      " politics\\_42.txt &  politics &      0.00 &      0.40 &        0.60 &        politics \\\\\n",
      " politics\\_35.txt &  politics &      0.40 &      0.00 &        0.60 &        politics \\\\\n",
      "  politics\\_6.txt &  politics &      0.45 &      0.00 &        0.55 &        politics \\\\\n",
      "  politics\\_9.txt &  politics &      0.00 &      0.48 &        0.52 &        politics \\\\\n",
      " politics\\_25.txt &  politics &      0.00 &      0.50 &        0.50 &        politics \\\\\n",
      " politics\\_49.txt &  politics &      0.00 &      0.51 &        0.49 &          sports \\\\\n",
      " politics\\_50.txt &  politics &      0.52 &      0.00 &        0.48 &          health \\\\\n",
      " politics\\_44.txt &  politics &      0.53 &      0.00 &        0.47 &          health \\\\\n",
      " politics\\_39.txt &  politics &      0.54 &      0.00 &        0.46 &          health \\\\\n",
      " politics\\_30.txt &  politics &      0.00 &      0.55 &        0.45 &          sports \\\\\n",
      " politics\\_29.txt &  politics &      0.56 &      0.00 &        0.44 &          health \\\\\n",
      " politics\\_37.txt &  politics &      0.60 &      0.00 &        0.40 &          health \\\\\n",
      " politics\\_48.txt &  politics &      0.60 &      0.00 &        0.40 &          health \\\\\n",
      " politics\\_31.txt &  politics &      0.65 &      0.00 &        0.35 &          health \\\\\n",
      " politics\\_47.txt &  politics &      0.94 &      0.06 &        0.00 &          health \\\\\n",
      "  politics\\_5.txt &  politics &      0.83 &      0.17 &        0.00 &          health \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved.\n",
      "############################################################\n",
      "############################################################\n",
      "Starting document´s classification...\n",
      "Document´s classification done...\n",
      "-----------------------------------------------------------\n",
      "Moving files to the correct directories...\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " health\\_28.txt &  health &      0.79 &      0.11 &        0.10 &          health \\\\\n",
      " health\\_24.txt &  health &      0.77 &      0.11 &        0.12 &          health \\\\\n",
      " health\\_45.txt &  health &      0.72 &      0.16 &        0.12 &          health \\\\\n",
      " health\\_23.txt &  health &      0.71 &      0.15 &        0.14 &          health \\\\\n",
      "  health\\_3.txt &  health &      0.71 &      0.15 &        0.15 &          health \\\\\n",
      "  health\\_7.txt &  health &      0.70 &      0.13 &        0.16 &          health \\\\\n",
      "  health\\_6.txt &  health &      0.70 &      0.17 &        0.13 &          health \\\\\n",
      " health\\_49.txt &  health &      0.70 &      0.12 &        0.19 &          health \\\\\n",
      " health\\_43.txt &  health &      0.70 &      0.15 &        0.16 &          health \\\\\n",
      " health\\_35.txt &  health &      0.69 &      0.17 &        0.14 &          health \\\\\n",
      " health\\_30.txt &  health &      0.65 &      0.12 &        0.23 &          health \\\\\n",
      " health\\_32.txt &  health &      0.62 &      0.22 &        0.15 &          health \\\\\n",
      " health\\_34.txt &  health &      0.62 &      0.21 &        0.17 &          health \\\\\n",
      " health\\_41.txt &  health &      0.60 &      0.21 &        0.19 &          health \\\\\n",
      " health\\_46.txt &  health &      0.59 &      0.18 &        0.23 &          health \\\\\n",
      " health\\_31.txt &  health &      0.58 &      0.19 &        0.23 &          health \\\\\n",
      " health\\_47.txt &  health &      0.57 &      0.22 &        0.20 &          health \\\\\n",
      " health\\_25.txt &  health &      0.57 &      0.18 &        0.25 &          health \\\\\n",
      " health\\_48.txt &  health &      0.57 &      0.15 &        0.28 &          health \\\\\n",
      "  health\\_9.txt &  health &      0.54 &      0.27 &        0.19 &          health \\\\\n",
      "  health\\_5.txt &  health &      0.54 &      0.21 &        0.25 &          health \\\\\n",
      " health\\_42.txt &  health &      0.54 &      0.25 &        0.21 &          health \\\\\n",
      "  health\\_8.txt &  health &      0.50 &      0.22 &        0.28 &          health \\\\\n",
      " health\\_44.txt &  health &      0.50 &      0.29 &        0.21 &          health \\\\\n",
      " health\\_36.txt &  health &      0.49 &      0.20 &        0.31 &          health \\\\\n",
      " health\\_39.txt &  health &      0.49 &      0.26 &        0.25 &          health \\\\\n",
      " health\\_50.txt &  health &      0.46 &      0.32 &        0.22 &          health \\\\\n",
      " health\\_29.txt &  health &      0.44 &      0.27 &        0.29 &          health \\\\\n",
      " health\\_27.txt &  health &      0.37 &      0.46 &        0.17 &          sports \\\\\n",
      " health\\_26.txt &  health &      0.31 &      0.20 &        0.49 &        politics \\\\\n",
      " health\\_40.txt &  health &      0.28 &      0.20 &        0.52 &        politics \\\\\n",
      " health\\_38.txt &  health &      0.27 &      0.46 &        0.27 &          sports \\\\\n",
      "  health\\_4.txt &  health &      0.24 &      0.33 &        0.42 &        politics \\\\\n",
      " health\\_33.txt &  health &      0.23 &      0.54 &        0.23 &          sports \\\\\n",
      " health\\_37.txt &  health &      0.16 &      0.68 &        0.16 &          sports \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      "  sports\\_3.txt &  sports &      0.10 &      0.81 &        0.10 &          sports \\\\\n",
      "  sports\\_9.txt &  sports &      0.12 &      0.78 &        0.10 &          sports \\\\\n",
      " sports\\_47.txt &  sports &      0.11 &      0.78 &        0.11 &          sports \\\\\n",
      "  sports\\_6.txt &  sports &      0.12 &      0.77 &        0.11 &          sports \\\\\n",
      " sports\\_41.txt &  sports &      0.13 &      0.75 &        0.13 &          sports \\\\\n",
      "  sports\\_8.txt &  sports &      0.13 &      0.75 &        0.13 &          sports \\\\\n",
      " sports\\_24.txt &  sports &      0.13 &      0.75 &        0.13 &          sports \\\\\n",
      " sports\\_34.txt &  sports &      0.12 &      0.74 &        0.14 &          sports \\\\\n",
      " sports\\_42.txt &  sports &      0.13 &      0.73 &        0.13 &          sports \\\\\n",
      "  sports\\_5.txt &  sports &      0.11 &      0.72 &        0.17 &          sports \\\\\n",
      " sports\\_46.txt &  sports &      0.14 &      0.72 &        0.14 &          sports \\\\\n",
      " sports\\_30.txt &  sports &      0.15 &      0.71 &        0.14 &          sports \\\\\n",
      " sports\\_43.txt &  sports &      0.16 &      0.67 &        0.16 &          sports \\\\\n",
      "  sports\\_7.txt &  sports &      0.17 &      0.66 &        0.17 &          sports \\\\\n",
      " sports\\_49.txt &  sports &      0.16 &      0.66 &        0.18 &          sports \\\\\n",
      " sports\\_29.txt &  sports &      0.21 &      0.65 &        0.14 &          sports \\\\\n",
      " sports\\_44.txt &  sports &      0.19 &      0.65 &        0.17 &          sports \\\\\n",
      " sports\\_28.txt &  sports &      0.19 &      0.62 &        0.19 &          sports \\\\\n",
      " sports\\_26.txt &  sports &      0.19 &      0.62 &        0.19 &          sports \\\\\n",
      " sports\\_40.txt &  sports &      0.21 &      0.60 &        0.19 &          sports \\\\\n",
      " sports\\_45.txt &  sports &      0.25 &      0.59 &        0.16 &          sports \\\\\n",
      " sports\\_23.txt &  sports &      0.25 &      0.55 &        0.20 &          sports \\\\\n",
      "  sports\\_4.txt &  sports &      0.25 &      0.55 &        0.20 &          sports \\\\\n",
      " sports\\_33.txt &  sports &      0.23 &      0.54 &        0.23 &          sports \\\\\n",
      " sports\\_50.txt &  sports &      0.31 &      0.50 &        0.19 &          sports \\\\\n",
      " sports\\_37.txt &  sports &      0.22 &      0.47 &        0.31 &          sports \\\\\n",
      " sports\\_38.txt &  sports &      0.18 &      0.42 &        0.40 &          sports \\\\\n",
      " sports\\_36.txt &  sports &      0.39 &      0.39 &        0.22 &          sports \\\\\n",
      " sports\\_31.txt &  sports &      0.45 &      0.34 &        0.21 &          health \\\\\n",
      " sports\\_48.txt &  sports &      0.46 &      0.34 &        0.21 &          health \\\\\n",
      " sports\\_32.txt &  sports &      0.33 &      0.33 &        0.33 &          health \\\\\n",
      " sports\\_27.txt &  sports &      0.33 &      0.33 &        0.33 &          health \\\\\n",
      " sports\\_39.txt &  sports &      0.33 &      0.33 &        0.33 &          health \\\\\n",
      " sports\\_25.txt &  sports &      0.31 &      0.20 &        0.49 &        politics \\\\\n",
      " sports\\_35.txt &  sports &      0.19 &      0.19 &        0.62 &        politics \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "        doc\\_name &     class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " politics\\_33.txt &  politics &      0.06 &      0.10 &        0.84 &        politics \\\\\n",
      " politics\\_28.txt &  politics &      0.07 &      0.09 &        0.84 &        politics \\\\\n",
      " politics\\_43.txt &  politics &      0.09 &      0.09 &        0.82 &        politics \\\\\n",
      "  politics\\_4.txt &  politics &      0.09 &      0.10 &        0.81 &        politics \\\\\n",
      " politics\\_27.txt &  politics &      0.11 &      0.10 &        0.79 &        politics \\\\\n",
      " politics\\_24.txt &  politics &      0.11 &      0.10 &        0.79 &        politics \\\\\n",
      " politics\\_32.txt &  politics &      0.11 &      0.10 &        0.79 &        politics \\\\\n",
      " politics\\_23.txt &  politics &      0.14 &      0.08 &        0.78 &        politics \\\\\n",
      " politics\\_30.txt &  politics &      0.11 &      0.11 &        0.78 &        politics \\\\\n",
      " politics\\_46.txt &  politics &      0.11 &      0.11 &        0.78 &        politics \\\\\n",
      " politics\\_48.txt &  politics &      0.11 &      0.13 &        0.76 &        politics \\\\\n",
      " politics\\_26.txt &  politics &      0.12 &      0.12 &        0.75 &        politics \\\\\n",
      " politics\\_39.txt &  politics &      0.15 &      0.12 &        0.74 &        politics \\\\\n",
      "  politics\\_8.txt &  politics &      0.14 &      0.14 &        0.71 &        politics \\\\\n",
      " politics\\_45.txt &  politics &      0.14 &      0.15 &        0.71 &        politics \\\\\n",
      " politics\\_36.txt &  politics &      0.10 &      0.20 &        0.70 &        politics \\\\\n",
      " politics\\_34.txt &  politics &      0.17 &      0.15 &        0.69 &        politics \\\\\n",
      " politics\\_47.txt &  politics &      0.16 &      0.16 &        0.68 &        politics \\\\\n",
      " politics\\_41.txt &  politics &      0.13 &      0.20 &        0.67 &        politics \\\\\n",
      "  politics\\_9.txt &  politics &      0.20 &      0.14 &        0.66 &        politics \\\\\n",
      " politics\\_44.txt &  politics &      0.22 &      0.16 &        0.62 &        politics \\\\\n",
      "  politics\\_5.txt &  politics &      0.20 &      0.18 &        0.62 &        politics \\\\\n",
      " politics\\_40.txt &  politics &      0.15 &      0.23 &        0.62 &        politics \\\\\n",
      " politics\\_35.txt &  politics &      0.13 &      0.26 &        0.61 &        politics \\\\\n",
      "  politics\\_7.txt &  politics &      0.20 &      0.20 &        0.60 &        politics \\\\\n",
      " politics\\_25.txt &  politics &      0.21 &      0.21 &        0.59 &        politics \\\\\n",
      " politics\\_29.txt &  politics &      0.25 &      0.19 &        0.56 &        politics \\\\\n",
      " politics\\_31.txt &  politics &      0.30 &      0.15 &        0.55 &        politics \\\\\n",
      " politics\\_38.txt &  politics &      0.24 &      0.21 &        0.55 &        politics \\\\\n",
      " politics\\_49.txt &  politics &      0.24 &      0.24 &        0.52 &        politics \\\\\n",
      " politics\\_37.txt &  politics &      0.17 &      0.33 &        0.50 &        politics \\\\\n",
      "  politics\\_3.txt &  politics &      0.36 &      0.15 &        0.49 &        politics \\\\\n",
      " politics\\_50.txt &  politics &      0.34 &      0.17 &        0.49 &        politics \\\\\n",
      " politics\\_42.txt &  politics &      0.21 &      0.42 &        0.37 &          sports \\\\\n",
      "  politics\\_6.txt &  politics &      0.68 &      0.11 &        0.20 &          health \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved.\n",
      "############################################################\n"
     ]
    }
   ],
   "source": [
    "data = execute(test_data, classify_tfidf(classify_document_tfidf, model_tfidf, dictionary, bow, index, test_data))\n",
    "data = execute(test_data, classify_w2v(classify_doc_w2v, glossaries_vector, model_w2v, test_data))\n",
    "data = execute(test_data, classify_bayes(classify_doc_bayes, clf, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:34.792597Z",
     "start_time": "2020-12-14T16:21:34.788597Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_single_model(data, model, classify_function):\n",
    "    \"\"\"\n",
    "    Function that evaluates the performance of a specific model.\n",
    "    \n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    print(\"#######################################################\")\n",
    "    print(\"Evaluating \"+ model + \"...\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    data = classify_documents(data, classify_function)\n",
    "    \n",
    "    y_true = data[\"current_class\"]\n",
    "    y_pred = data[\"predicted_class\"]\n",
    "    original = len(y_pred)\n",
    "    y_pred = data[data[\"predicted_class\"] != -1][\"predicted_class\"]\n",
    "    unknown = original - len(y_pred)\n",
    "    y_true = y_true.loc[y_pred.index]\n",
    "        \n",
    "    print(classification_report(y_true, y_pred, target_names=[\"health\", \"sports\", \"politics\"]))\n",
    "    print(\"Confusion matrix ==>\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    print(f\"{unknown} documents couldn´t been classified.\")\n",
    "\n",
    "    #precisions = []\n",
    "    #recalls = []\n",
    "\n",
    "    #for i in range(len(cm[0])):\n",
    "     #   name = keys_dic[i]\n",
    "      #  print(f\"Computing statistics about {name}:\")\n",
    "       # recall = cm[i,i] / np.sum(cm[i,:])\n",
    "      #  precision = cm[i,i] / np.sum(cm[:,i])\n",
    "      #  print(f\"\\tPrecision ==> {precision}\")\n",
    "      #  print(f\"\\tRecall ==> {recall}\")\n",
    "\n",
    "      #  precisions.append(precision)\n",
    "      #  recalls.append(recall)\n",
    "\n",
    "    #precisions = np.array(precisions)\n",
    "    #recalls = np.array(recalls)\n",
    "    #f1 = f1_score(y_true, y_pred, average = \"macro\")\n",
    "    #accuracy = accuracy_score(y_true, y_pred)\n",
    "    #print(f\"Average precision ==> {precisions.mean()}\")\n",
    "    #print(f\"Average recall ==> {recalls.mean()}\")\n",
    "    #print(f\"F1-Score ==> {f1}\")\n",
    "    #print(f\"Overall accuracy score ==> {accuracy}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Model evaluated\")\n",
    "    print(\"#######################################################\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:34.838597Z",
     "start_time": "2020-12-14T16:21:34.793596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "Evaluating tf-idf...\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      health       0.79      0.86      0.82        35\n",
      "      sports       0.84      0.84      0.84        32\n",
      "    politics       0.97      0.88      0.92        34\n",
      "\n",
      "    accuracy                           0.86       101\n",
      "   macro avg       0.87      0.86      0.86       101\n",
      "weighted avg       0.87      0.86      0.86       101\n",
      "\n",
      "Confusion matrix ==>\n",
      "[[30  5  0]\n",
      " [ 4 27  1]\n",
      " [ 4  0 30]]\n",
      "4 documents couldn´t been classified.\n",
      "-------------------------------------------------------\n",
      "Model evaluated\n",
      "#######################################################\n"
     ]
    }
   ],
   "source": [
    "data_tfidf = evaluate_single_model(test_data, \"tf-idf\", classify_tfidf(classify_document_tfidf, model_tfidf, dictionary, bow, index, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:35.107623Z",
     "start_time": "2020-12-14T16:21:34.839601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "Evaluating Word2Vec...\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      health       0.50      0.43      0.46        35\n",
      "      sports       0.62      0.57      0.60        35\n",
      "    politics       0.51      0.63      0.56        35\n",
      "\n",
      "    accuracy                           0.54       105\n",
      "   macro avg       0.55      0.54      0.54       105\n",
      "weighted avg       0.55      0.54      0.54       105\n",
      "\n",
      "Confusion matrix ==>\n",
      "[[15  6 14]\n",
      " [ 8 20  7]\n",
      " [ 7  6 22]]\n",
      "0 documents couldn´t been classified.\n",
      "-------------------------------------------------------\n",
      "Model evaluated\n",
      "#######################################################\n"
     ]
    }
   ],
   "source": [
    "data_w2v = evaluate_single_model(test_data, \"Word2Vec\", classify_w2v(classify_doc_w2v, glossaries_vector, model_w2v, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:35.267441Z",
     "start_time": "2020-12-14T16:21:35.108624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "Evaluating Multinomial NB (tfidf)...\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      health       0.82      0.80      0.81        35\n",
      "      sports       0.85      0.80      0.82        35\n",
      "    politics       0.87      0.94      0.90        35\n",
      "\n",
      "    accuracy                           0.85       105\n",
      "   macro avg       0.85      0.85      0.85       105\n",
      "weighted avg       0.85      0.85      0.85       105\n",
      "\n",
      "Confusion matrix ==>\n",
      "[[28  4  3]\n",
      " [ 5 28  2]\n",
      " [ 1  1 33]]\n",
      "0 documents couldn´t been classified.\n",
      "-------------------------------------------------------\n",
      "Model evaluated\n",
      "#######################################################\n"
     ]
    }
   ],
   "source": [
    "data_bayes = evaluate_single_model(test_data, \"Multinomial NB (tfidf)\", classify_bayes(classify_doc_bayes, clf, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T16:21:35.373435Z",
     "start_time": "2020-12-14T16:21:35.268441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>preprocesado</th>\n",
       "      <th>tokens</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>tokens + bigrams</th>\n",
       "      <th>current_class</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>p_health</th>\n",
       "      <th>p_sports</th>\n",
       "      <th>p_politics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>health_23.txt</td>\n",
       "      <td>Hace unos días Alejandro Díez, madrileño de 24...</td>\n",
       "      <td>health</td>\n",
       "      <td>hace unos días alejandro díez madrileño de  añ...</td>\n",
       "      <td>[días, alejandro, díez, madrileño, años, levan...</td>\n",
       "      <td>[se trata, este tipo, se trata, ha sido, es de...</td>\n",
       "      <td>[días, alejandro, díez, madrileño, años, levan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.847396</td>\n",
       "      <td>0.152605</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>health_24.txt</td>\n",
       "      <td>Casi todos los planes contra el coronavirus un...</td>\n",
       "      <td>health</td>\n",
       "      <td>casi todos los planes contra el coronavirus un...</td>\n",
       "      <td>[planes, coronavirus, pase, peor, basan, inmun...</td>\n",
       "      <td>[sobre todo, se trata, frente al, segunda ola,...</td>\n",
       "      <td>[planes, coronavirus, pase, peor, basan, inmun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.895831</td>\n",
       "      <td>0.069446</td>\n",
       "      <td>0.034723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>health_25.txt</td>\n",
       "      <td>Un correcto descanso nocturno no sólo es impor...</td>\n",
       "      <td>health</td>\n",
       "      <td>un correcto descanso nocturno no sólo es impor...</td>\n",
       "      <td>[correcto, descanso, nocturno, importante, sen...</td>\n",
       "      <td>[frente al, frente al, cada vez, new york, más...</td>\n",
       "      <td>[correcto, descanso, nocturno, importante, sen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>health_26.txt</td>\n",
       "      <td>Los problemas de sueño son cada vez más frecue...</td>\n",
       "      <td>health</td>\n",
       "      <td>los problemas de sueño son cada vez más frecue...</td>\n",
       "      <td>[problemas, sueño, frecuentes, sociedad, llega...</td>\n",
       "      <td>[muy probable, se trata, sino también, sin emb...</td>\n",
       "      <td>[problemas, sueño, frecuentes, sociedad, llega...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>health_27.txt</td>\n",
       "      <td>El estrés de la rutina diaria, las preocupacio...</td>\n",
       "      <td>health</td>\n",
       "      <td>el estrés de la rutina diaria las preocupacion...</td>\n",
       "      <td>[estrés, rutina, diaria, preocupaciones, labor...</td>\n",
       "      <td>[sin embargo, más allá, sin embargo, muchas pe...</td>\n",
       "      <td>[estrés, rutina, diaria, preocupaciones, labor...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465931</td>\n",
       "      <td>0.534069</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>health_28.txt</td>\n",
       "      <td>Cerca del 53 por ciento de los centros sociosa...</td>\n",
       "      <td>health</td>\n",
       "      <td>cerca del  por ciento de los centros sociosani...</td>\n",
       "      <td>[ciento, centros, sociosanitarios, comunidad, ...</td>\n",
       "      <td>[frente al, frente al, frente al, sars cov, fr...</td>\n",
       "      <td>[ciento, centros, sociosanitarios, comunidad, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944681</td>\n",
       "      <td>0.055319</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>health_29.txt</td>\n",
       "      <td>Las residencias de mayores constituyen el gran...</td>\n",
       "      <td>health</td>\n",
       "      <td>las residencias de mayores constituyen el gran...</td>\n",
       "      <td>[residencias, mayores, constituyen, punto, neg...</td>\n",
       "      <td>[segunda ola, semanas después, segunda ola, lu...</td>\n",
       "      <td>[residencias, mayores, constituyen, punto, neg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571379</td>\n",
       "      <td>0.249865</td>\n",
       "      <td>0.178756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>health_3.txt</td>\n",
       "      <td>El ejercicio físico es necesario para mantener...</td>\n",
       "      <td>health</td>\n",
       "      <td>el ejercicio físico es necesario para mantener...</td>\n",
       "      <td>[ejercicio, físico, necesario, mantenerse, for...</td>\n",
       "      <td>[tu cuerpo, sin embargo, más allá, sin embargo...</td>\n",
       "      <td>[ejercicio, físico, necesario, mantenerse, for...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>health_30.txt</td>\n",
       "      <td>La segunda ola del coronavirus sigue sin dar t...</td>\n",
       "      <td>health</td>\n",
       "      <td>la segunda ola del coronavirus sigue sin dar t...</td>\n",
       "      <td>[ola, coronavirus, tregua, españa, abocada, cu...</td>\n",
       "      <td>[entre ellas, segunda ola, sin embargo, ha sid...</td>\n",
       "      <td>[ola, coronavirus, tregua, españa, abocada, cu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.711204</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>0.262074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>health_31.txt</td>\n",
       "      <td>Tres de los proyectos de la vacuna contra el c...</td>\n",
       "      <td>health</td>\n",
       "      <td>tres de los proyectos de la vacuna contra el c...</td>\n",
       "      <td>[proyectos, vacuna, covid, investigan, españa,...</td>\n",
       "      <td>[este martes, este martes, ha indicado, ha ind...</td>\n",
       "      <td>[proyectos, vacuna, covid, investigan, españa,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687010</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>0.208660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>health_32.txt</td>\n",
       "      <td>La vacuna desarrollada por la Universidad de O...</td>\n",
       "      <td>health</td>\n",
       "      <td>la vacuna desarrollada por la universidad de o...</td>\n",
       "      <td>[vacuna, desarrollada, universidad, oxford, as...</td>\n",
       "      <td>[efectos secundarios, reino unido, reino unido...</td>\n",
       "      <td>[vacuna, desarrollada, universidad, oxford, as...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.761620</td>\n",
       "      <td>0.238380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>health_33.txt</td>\n",
       "      <td>El mundo onírico… tan oscuro, tan extraño.\\n\\n...</td>\n",
       "      <td>health</td>\n",
       "      <td>el mundo onírico… tan oscuro tan extraño\\n\\nca...</td>\n",
       "      <td>[mundo, onírico, oscuro, extraño, noche, cerra...</td>\n",
       "      <td>[te has, me he, han sido, han sido, una person...</td>\n",
       "      <td>[mundo, onírico, oscuro, extraño, noche, cerra...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>health_34.txt</td>\n",
       "      <td>La tripanosomiasis africana humana (también co...</td>\n",
       "      <td>health</td>\n",
       "      <td>la tripanosomiasis africana humana también con...</td>\n",
       "      <td>[tripanosomiasis, africana, humana, conocida, ...</td>\n",
       "      <td>[se trata, se trata, se encuentra, se trata, s...</td>\n",
       "      <td>[tripanosomiasis, africana, humana, conocida, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.837688</td>\n",
       "      <td>0.162312</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28</td>\n",
       "      <td>health_35.txt</td>\n",
       "      <td>Las personas con psoriasis que reciben terapia...</td>\n",
       "      <td>health</td>\n",
       "      <td>las personas con psoriasis que reciben terapia...</td>\n",
       "      <td>[personas, psoriasis, reciben, terapias, bioló...</td>\n",
       "      <td>[se encuentra, estudio publicado, presión arte...</td>\n",
       "      <td>[personas, psoriasis, reciben, terapias, bioló...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.873477</td>\n",
       "      <td>0.126523</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>health_36.txt</td>\n",
       "      <td>Gestionar en cualquier ámbito y el sanitario n...</td>\n",
       "      <td>health</td>\n",
       "      <td>gestionar en cualquier ámbito y el sanitario n...</td>\n",
       "      <td>[gestionar, ámbito, sanitario, excepción, prec...</td>\n",
       "      <td>[sino también, cada vez, cada vez, puede ser, ...</td>\n",
       "      <td>[gestionar, ámbito, sanitario, excepción, prec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30</td>\n",
       "      <td>health_37.txt</td>\n",
       "      <td>Una prueba de tumor podría ayudar a identifica...</td>\n",
       "      <td>health</td>\n",
       "      <td>una prueba de tumor podría ayudar a identifica...</td>\n",
       "      <td>[prueba, tumor, ayudar, identificar, pacientes...</td>\n",
       "      <td>[dos años, ensayos clínicos, ensayos clínicos,...</td>\n",
       "      <td>[prueba, tumor, ayudar, identificar, pacientes...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31</td>\n",
       "      <td>health_38.txt</td>\n",
       "      <td>El cerebro de los mamíferos está compuesto por...</td>\n",
       "      <td>health</td>\n",
       "      <td>el cerebro de los mamíferos está compuesto por...</td>\n",
       "      <td>[cerebro, mamíferos, compuesto, lados, hemisfe...</td>\n",
       "      <td>[más eficiente, sin embargo, sin embargo, lo l...</td>\n",
       "      <td>[cerebro, mamíferos, compuesto, lados, hemisfe...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.218104</td>\n",
       "      <td>0.563791</td>\n",
       "      <td>0.218104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>health_39.txt</td>\n",
       "      <td>Científicos de Johns Hopkins Medicine, que uti...</td>\n",
       "      <td>health</td>\n",
       "      <td>científicos de johns hopkins medicine que util...</td>\n",
       "      <td>[científicos, johns, hopkins, medicine, utiliz...</td>\n",
       "      <td>[por ejemplo, por ejemplo, por ejemplo, cada u...</td>\n",
       "      <td>[científicos, johns, hopkins, medicine, utiliz...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.768622</td>\n",
       "      <td>0.231378</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>health_4.txt</td>\n",
       "      <td>No os diré no lloréis, pues no todas las lágri...</td>\n",
       "      <td>health</td>\n",
       "      <td>no os diré no lloréis pues no todas las lágrim...</td>\n",
       "      <td>[diré, lloréis, lágrimas, amargas, enunciaba, ...</td>\n",
       "      <td>[se trata, sino también, más allá, se trata, l...</td>\n",
       "      <td>[diré, lloréis, lágrimas, amargas, enunciaba, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34</td>\n",
       "      <td>health_40.txt</td>\n",
       "      <td>En ocasiones tenemos la impresión de que nuest...</td>\n",
       "      <td>health</td>\n",
       "      <td>en ocasiones tenemos la impresión de que nuest...</td>\n",
       "      <td>[ocasiones, impresión, vida, estática, cambia,...</td>\n",
       "      <td>[te has, tu cuerpo, cada vez, cada vez, tu cue...</td>\n",
       "      <td>[ocasiones, impresión, vida, estática, cambia,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35</td>\n",
       "      <td>health_41.txt</td>\n",
       "      <td>Las células epiteliales receptoras tienen un p...</td>\n",
       "      <td>health</td>\n",
       "      <td>las células epiteliales receptoras tienen un p...</td>\n",
       "      <td>[células, epiteliales, receptoras, papel, fund...</td>\n",
       "      <td>[sobre todo, dos años, es decir, lo largo, dos...</td>\n",
       "      <td>[células, epiteliales, receptoras, papel, fund...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.876988</td>\n",
       "      <td>0.123012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36</td>\n",
       "      <td>health_42.txt</td>\n",
       "      <td>Como una escena de La invasión de los ultracue...</td>\n",
       "      <td>health</td>\n",
       "      <td>como una escena de la invasión de los ultracue...</td>\n",
       "      <td>[escena, invasión, ultracuerpos, philip, kaufm...</td>\n",
       "      <td>[este tipo, puede ser, sistema inmune, sistema...</td>\n",
       "      <td>[escena, invasión, ultracuerpos, philip, kaufm...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697181</td>\n",
       "      <td>0.302820</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>37</td>\n",
       "      <td>health_43.txt</td>\n",
       "      <td>Tras la primera ola de coronavirus y el primer...</td>\n",
       "      <td>health</td>\n",
       "      <td>tras la primera ola de coronavirus y el primer...</td>\n",
       "      <td>[ola, coronavirus, alarma, colegios, guardería...</td>\n",
       "      <td>[sobre todo, se trata, sin embargo, se trata, ...</td>\n",
       "      <td>[ola, coronavirus, alarma, colegios, guardería...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>38</td>\n",
       "      <td>health_44.txt</td>\n",
       "      <td>Siempre vas con prisas, pero apenas te separas...</td>\n",
       "      <td>health</td>\n",
       "      <td>siempre vas con prisas pero apenas te separas ...</td>\n",
       "      <td>[vas, prisas, separas, silla, cuerpo, movimien...</td>\n",
       "      <td>[sobre todo, se trata, tu cuerpo, sin embargo,...</td>\n",
       "      <td>[vas, prisas, separas, silla, cuerpo, movimien...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>39</td>\n",
       "      <td>health_45.txt</td>\n",
       "      <td>De entre las múltiples preocupaciones que tene...</td>\n",
       "      <td>health</td>\n",
       "      <td>de entre las múltiples preocupaciones que tene...</td>\n",
       "      <td>[múltiples, preocupaciones, padres, persiguen,...</td>\n",
       "      <td>[sobre todo, una dieta, es decir, sars cov, es...</td>\n",
       "      <td>[múltiples, preocupaciones, padres, persiguen,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852778</td>\n",
       "      <td>0.147222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40</td>\n",
       "      <td>health_46.txt</td>\n",
       "      <td>La Asociación Española Contra el Cáncer y Unid...</td>\n",
       "      <td>health</td>\n",
       "      <td>la asociación española contra el cáncer y unid...</td>\n",
       "      <td>[asociación, española, cáncer, unidad, editori...</td>\n",
       "      <td>[se trata, sin embargo, se trata, sin embargo,...</td>\n",
       "      <td>[asociación, española, cáncer, unidad, editori...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>41</td>\n",
       "      <td>health_47.txt</td>\n",
       "      <td>La Organización Mundial de la Salud (OMS) ha a...</td>\n",
       "      <td>health</td>\n",
       "      <td>la organización mundial de la salud oms ha act...</td>\n",
       "      <td>[organización, mundial, salud, oms, actualizad...</td>\n",
       "      <td>[sino también, hasta ahora, hasta ahora, todas...</td>\n",
       "      <td>[organización, mundial, salud, oms, actualizad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.881789</td>\n",
       "      <td>0.118211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42</td>\n",
       "      <td>health_48.txt</td>\n",
       "      <td>Eso fue lo que afirmaron los expertos de la Es...</td>\n",
       "      <td>health</td>\n",
       "      <td>eso fue lo que afirmaron los expertos de la es...</td>\n",
       "      <td>[afirmaron, expertos, escuela, medicina, harva...</td>\n",
       "      <td>[este tipo, una persona, estudio publicado, es...</td>\n",
       "      <td>[afirmaron, expertos, escuela, medicina, harva...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>43</td>\n",
       "      <td>health_49.txt</td>\n",
       "      <td>La diabetes es una patología crónica silencios...</td>\n",
       "      <td>health</td>\n",
       "      <td>la diabetes es una patología crónica silencios...</td>\n",
       "      <td>[diabetes, patología, crónica, silenciosa, afe...</td>\n",
       "      <td>[perder peso, se trata, perder peso, se trata,...</td>\n",
       "      <td>[diabetes, patología, crónica, silenciosa, afe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>44</td>\n",
       "      <td>health_5.txt</td>\n",
       "      <td>Un estudio español, galardonado con el premio ...</td>\n",
       "      <td>health</td>\n",
       "      <td>un estudio español galardonado con el premio a...</td>\n",
       "      <td>[estudio, español, galardonado, premio, invest...</td>\n",
       "      <td>[una dieta, es decir, media hora, puede ser, e...</td>\n",
       "      <td>[estudio, español, galardonado, premio, invest...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.622105</td>\n",
       "      <td>0.094474</td>\n",
       "      <td>0.283421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>45</td>\n",
       "      <td>health_50.txt</td>\n",
       "      <td>Envejecer es mucho más que sumar canas o arrug...</td>\n",
       "      <td>health</td>\n",
       "      <td>envejecer es mucho más que sumar canas o arrug...</td>\n",
       "      <td>[envejecer, sumar, canas, arrugas, proceso, ex...</td>\n",
       "      <td>[sobre todo, se trata, este tipo, frente al, s...</td>\n",
       "      <td>[envejecer, sumar, canas, arrugas, proceso, ex...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>46</td>\n",
       "      <td>health_6.txt</td>\n",
       "      <td>Algunos tienden a dormir boca arriba y otros s...</td>\n",
       "      <td>health</td>\n",
       "      <td>algunos tienden a dormir boca arriba y otros s...</td>\n",
       "      <td>[tienden, dormir, boca, pegar, ojo, boca, abaj...</td>\n",
       "      <td>[sino también, por ejemplo, es decir, puede se...</td>\n",
       "      <td>[tienden, dormir, boca, pegar, ojo, boca, abaj...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>47</td>\n",
       "      <td>health_7.txt</td>\n",
       "      <td>La entrada del otoño de este año ha venido mar...</td>\n",
       "      <td>health</td>\n",
       "      <td>la entrada del otoño de este año ha venido mar...</td>\n",
       "      <td>[entrada, otoño, año, venido, marcada, crisis,...</td>\n",
       "      <td>[sobre todo, se trata, sin embargo, por ejempl...</td>\n",
       "      <td>[entrada, otoño, año, venido, marcada, crisis,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>48</td>\n",
       "      <td>health_8.txt</td>\n",
       "      <td>Tener una mascota es algo muy saludable en sit...</td>\n",
       "      <td>health</td>\n",
       "      <td>tener una mascota es algo muy saludable en sit...</td>\n",
       "      <td>[mascota, saludable, situaciones, confinamient...</td>\n",
       "      <td>[salud mental, salud mental, salud mental, sal...</td>\n",
       "      <td>[mascota, saludable, situaciones, confinamient...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.806574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>49</td>\n",
       "      <td>health_9.txt</td>\n",
       "      <td>Jugar entre el verdor y la maleza de la natura...</td>\n",
       "      <td>health</td>\n",
       "      <td>jugar entre el verdor y la maleza de la natura...</td>\n",
       "      <td>[jugar, verdor, maleza, naturaleza, mes, sufic...</td>\n",
       "      <td>[salud mental, salud mental, salud mental, sal...</td>\n",
       "      <td>[jugar, verdor, maleza, naturaleza, mes, sufic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.718104</td>\n",
       "      <td>0.281896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index       doc_name                                               text  \\\n",
       "0      15  health_23.txt  Hace unos días Alejandro Díez, madrileño de 24...   \n",
       "1      16  health_24.txt  Casi todos los planes contra el coronavirus un...   \n",
       "2      17  health_25.txt  Un correcto descanso nocturno no sólo es impor...   \n",
       "3      18  health_26.txt  Los problemas de sueño son cada vez más frecue...   \n",
       "4      19  health_27.txt  El estrés de la rutina diaria, las preocupacio...   \n",
       "5      20  health_28.txt  Cerca del 53 por ciento de los centros sociosa...   \n",
       "6      21  health_29.txt  Las residencias de mayores constituyen el gran...   \n",
       "7      22   health_3.txt  El ejercicio físico es necesario para mantener...   \n",
       "8      23  health_30.txt  La segunda ola del coronavirus sigue sin dar t...   \n",
       "9      24  health_31.txt  Tres de los proyectos de la vacuna contra el c...   \n",
       "10     25  health_32.txt  La vacuna desarrollada por la Universidad de O...   \n",
       "11     26  health_33.txt  El mundo onírico… tan oscuro, tan extraño.\\n\\n...   \n",
       "12     27  health_34.txt  La tripanosomiasis africana humana (también co...   \n",
       "13     28  health_35.txt  Las personas con psoriasis que reciben terapia...   \n",
       "14     29  health_36.txt  Gestionar en cualquier ámbito y el sanitario n...   \n",
       "15     30  health_37.txt  Una prueba de tumor podría ayudar a identifica...   \n",
       "16     31  health_38.txt  El cerebro de los mamíferos está compuesto por...   \n",
       "17     32  health_39.txt  Científicos de Johns Hopkins Medicine, que uti...   \n",
       "18     33   health_4.txt  No os diré no lloréis, pues no todas las lágri...   \n",
       "19     34  health_40.txt  En ocasiones tenemos la impresión de que nuest...   \n",
       "20     35  health_41.txt  Las células epiteliales receptoras tienen un p...   \n",
       "21     36  health_42.txt  Como una escena de La invasión de los ultracue...   \n",
       "22     37  health_43.txt  Tras la primera ola de coronavirus y el primer...   \n",
       "23     38  health_44.txt  Siempre vas con prisas, pero apenas te separas...   \n",
       "24     39  health_45.txt  De entre las múltiples preocupaciones que tene...   \n",
       "25     40  health_46.txt  La Asociación Española Contra el Cáncer y Unid...   \n",
       "26     41  health_47.txt  La Organización Mundial de la Salud (OMS) ha a...   \n",
       "27     42  health_48.txt  Eso fue lo que afirmaron los expertos de la Es...   \n",
       "28     43  health_49.txt  La diabetes es una patología crónica silencios...   \n",
       "29     44   health_5.txt  Un estudio español, galardonado con el premio ...   \n",
       "30     45  health_50.txt  Envejecer es mucho más que sumar canas o arrug...   \n",
       "31     46   health_6.txt  Algunos tienden a dormir boca arriba y otros s...   \n",
       "32     47   health_7.txt  La entrada del otoño de este año ha venido mar...   \n",
       "33     48   health_8.txt  Tener una mascota es algo muy saludable en sit...   \n",
       "34     49   health_9.txt  Jugar entre el verdor y la maleza de la natura...   \n",
       "\n",
       "     class                                       preprocesado  \\\n",
       "0   health  hace unos días alejandro díez madrileño de  añ...   \n",
       "1   health  casi todos los planes contra el coronavirus un...   \n",
       "2   health  un correcto descanso nocturno no sólo es impor...   \n",
       "3   health  los problemas de sueño son cada vez más frecue...   \n",
       "4   health  el estrés de la rutina diaria las preocupacion...   \n",
       "5   health  cerca del  por ciento de los centros sociosani...   \n",
       "6   health  las residencias de mayores constituyen el gran...   \n",
       "7   health  el ejercicio físico es necesario para mantener...   \n",
       "8   health  la segunda ola del coronavirus sigue sin dar t...   \n",
       "9   health  tres de los proyectos de la vacuna contra el c...   \n",
       "10  health  la vacuna desarrollada por la universidad de o...   \n",
       "11  health  el mundo onírico… tan oscuro tan extraño\\n\\nca...   \n",
       "12  health  la tripanosomiasis africana humana también con...   \n",
       "13  health  las personas con psoriasis que reciben terapia...   \n",
       "14  health  gestionar en cualquier ámbito y el sanitario n...   \n",
       "15  health  una prueba de tumor podría ayudar a identifica...   \n",
       "16  health  el cerebro de los mamíferos está compuesto por...   \n",
       "17  health  científicos de johns hopkins medicine que util...   \n",
       "18  health  no os diré no lloréis pues no todas las lágrim...   \n",
       "19  health  en ocasiones tenemos la impresión de que nuest...   \n",
       "20  health  las células epiteliales receptoras tienen un p...   \n",
       "21  health  como una escena de la invasión de los ultracue...   \n",
       "22  health  tras la primera ola de coronavirus y el primer...   \n",
       "23  health  siempre vas con prisas pero apenas te separas ...   \n",
       "24  health  de entre las múltiples preocupaciones que tene...   \n",
       "25  health  la asociación española contra el cáncer y unid...   \n",
       "26  health  la organización mundial de la salud oms ha act...   \n",
       "27  health  eso fue lo que afirmaron los expertos de la es...   \n",
       "28  health  la diabetes es una patología crónica silencios...   \n",
       "29  health  un estudio español galardonado con el premio a...   \n",
       "30  health  envejecer es mucho más que sumar canas o arrug...   \n",
       "31  health  algunos tienden a dormir boca arriba y otros s...   \n",
       "32  health  la entrada del otoño de este año ha venido mar...   \n",
       "33  health  tener una mascota es algo muy saludable en sit...   \n",
       "34  health  jugar entre el verdor y la maleza de la natura...   \n",
       "\n",
       "                                               tokens  \\\n",
       "0   [días, alejandro, díez, madrileño, años, levan...   \n",
       "1   [planes, coronavirus, pase, peor, basan, inmun...   \n",
       "2   [correcto, descanso, nocturno, importante, sen...   \n",
       "3   [problemas, sueño, frecuentes, sociedad, llega...   \n",
       "4   [estrés, rutina, diaria, preocupaciones, labor...   \n",
       "5   [ciento, centros, sociosanitarios, comunidad, ...   \n",
       "6   [residencias, mayores, constituyen, punto, neg...   \n",
       "7   [ejercicio, físico, necesario, mantenerse, for...   \n",
       "8   [ola, coronavirus, tregua, españa, abocada, cu...   \n",
       "9   [proyectos, vacuna, covid, investigan, españa,...   \n",
       "10  [vacuna, desarrollada, universidad, oxford, as...   \n",
       "11  [mundo, onírico, oscuro, extraño, noche, cerra...   \n",
       "12  [tripanosomiasis, africana, humana, conocida, ...   \n",
       "13  [personas, psoriasis, reciben, terapias, bioló...   \n",
       "14  [gestionar, ámbito, sanitario, excepción, prec...   \n",
       "15  [prueba, tumor, ayudar, identificar, pacientes...   \n",
       "16  [cerebro, mamíferos, compuesto, lados, hemisfe...   \n",
       "17  [científicos, johns, hopkins, medicine, utiliz...   \n",
       "18  [diré, lloréis, lágrimas, amargas, enunciaba, ...   \n",
       "19  [ocasiones, impresión, vida, estática, cambia,...   \n",
       "20  [células, epiteliales, receptoras, papel, fund...   \n",
       "21  [escena, invasión, ultracuerpos, philip, kaufm...   \n",
       "22  [ola, coronavirus, alarma, colegios, guardería...   \n",
       "23  [vas, prisas, separas, silla, cuerpo, movimien...   \n",
       "24  [múltiples, preocupaciones, padres, persiguen,...   \n",
       "25  [asociación, española, cáncer, unidad, editori...   \n",
       "26  [organización, mundial, salud, oms, actualizad...   \n",
       "27  [afirmaron, expertos, escuela, medicina, harva...   \n",
       "28  [diabetes, patología, crónica, silenciosa, afe...   \n",
       "29  [estudio, español, galardonado, premio, invest...   \n",
       "30  [envejecer, sumar, canas, arrugas, proceso, ex...   \n",
       "31  [tienden, dormir, boca, pegar, ojo, boca, abaj...   \n",
       "32  [entrada, otoño, año, venido, marcada, crisis,...   \n",
       "33  [mascota, saludable, situaciones, confinamient...   \n",
       "34  [jugar, verdor, maleza, naturaleza, mes, sufic...   \n",
       "\n",
       "                                              bigrams  \\\n",
       "0   [se trata, este tipo, se trata, ha sido, es de...   \n",
       "1   [sobre todo, se trata, frente al, segunda ola,...   \n",
       "2   [frente al, frente al, cada vez, new york, más...   \n",
       "3   [muy probable, se trata, sino también, sin emb...   \n",
       "4   [sin embargo, más allá, sin embargo, muchas pe...   \n",
       "5   [frente al, frente al, frente al, sars cov, fr...   \n",
       "6   [segunda ola, semanas después, segunda ola, lu...   \n",
       "7   [tu cuerpo, sin embargo, más allá, sin embargo...   \n",
       "8   [entre ellas, segunda ola, sin embargo, ha sid...   \n",
       "9   [este martes, este martes, ha indicado, ha ind...   \n",
       "10  [efectos secundarios, reino unido, reino unido...   \n",
       "11  [te has, me he, han sido, han sido, una person...   \n",
       "12  [se trata, se trata, se encuentra, se trata, s...   \n",
       "13  [se encuentra, estudio publicado, presión arte...   \n",
       "14  [sino también, cada vez, cada vez, puede ser, ...   \n",
       "15  [dos años, ensayos clínicos, ensayos clínicos,...   \n",
       "16  [más eficiente, sin embargo, sin embargo, lo l...   \n",
       "17  [por ejemplo, por ejemplo, por ejemplo, cada u...   \n",
       "18  [se trata, sino también, más allá, se trata, l...   \n",
       "19  [te has, tu cuerpo, cada vez, cada vez, tu cue...   \n",
       "20  [sobre todo, dos años, es decir, lo largo, dos...   \n",
       "21  [este tipo, puede ser, sistema inmune, sistema...   \n",
       "22  [sobre todo, se trata, sin embargo, se trata, ...   \n",
       "23  [sobre todo, se trata, tu cuerpo, sin embargo,...   \n",
       "24  [sobre todo, una dieta, es decir, sars cov, es...   \n",
       "25  [se trata, sin embargo, se trata, sin embargo,...   \n",
       "26  [sino también, hasta ahora, hasta ahora, todas...   \n",
       "27  [este tipo, una persona, estudio publicado, es...   \n",
       "28  [perder peso, se trata, perder peso, se trata,...   \n",
       "29  [una dieta, es decir, media hora, puede ser, e...   \n",
       "30  [sobre todo, se trata, este tipo, frente al, s...   \n",
       "31  [sino también, por ejemplo, es decir, puede se...   \n",
       "32  [sobre todo, se trata, sin embargo, por ejempl...   \n",
       "33  [salud mental, salud mental, salud mental, sal...   \n",
       "34  [salud mental, salud mental, salud mental, sal...   \n",
       "\n",
       "                                     tokens + bigrams  current_class  \\\n",
       "0   [días, alejandro, díez, madrileño, años, levan...              0   \n",
       "1   [planes, coronavirus, pase, peor, basan, inmun...              0   \n",
       "2   [correcto, descanso, nocturno, importante, sen...              0   \n",
       "3   [problemas, sueño, frecuentes, sociedad, llega...              0   \n",
       "4   [estrés, rutina, diaria, preocupaciones, labor...              0   \n",
       "5   [ciento, centros, sociosanitarios, comunidad, ...              0   \n",
       "6   [residencias, mayores, constituyen, punto, neg...              0   \n",
       "7   [ejercicio, físico, necesario, mantenerse, for...              0   \n",
       "8   [ola, coronavirus, tregua, españa, abocada, cu...              0   \n",
       "9   [proyectos, vacuna, covid, investigan, españa,...              0   \n",
       "10  [vacuna, desarrollada, universidad, oxford, as...              0   \n",
       "11  [mundo, onírico, oscuro, extraño, noche, cerra...              0   \n",
       "12  [tripanosomiasis, africana, humana, conocida, ...              0   \n",
       "13  [personas, psoriasis, reciben, terapias, bioló...              0   \n",
       "14  [gestionar, ámbito, sanitario, excepción, prec...              0   \n",
       "15  [prueba, tumor, ayudar, identificar, pacientes...              0   \n",
       "16  [cerebro, mamíferos, compuesto, lados, hemisfe...              0   \n",
       "17  [científicos, johns, hopkins, medicine, utiliz...              0   \n",
       "18  [diré, lloréis, lágrimas, amargas, enunciaba, ...              0   \n",
       "19  [ocasiones, impresión, vida, estática, cambia,...              0   \n",
       "20  [células, epiteliales, receptoras, papel, fund...              0   \n",
       "21  [escena, invasión, ultracuerpos, philip, kaufm...              0   \n",
       "22  [ola, coronavirus, alarma, colegios, guardería...              0   \n",
       "23  [vas, prisas, separas, silla, cuerpo, movimien...              0   \n",
       "24  [múltiples, preocupaciones, padres, persiguen,...              0   \n",
       "25  [asociación, española, cáncer, unidad, editori...              0   \n",
       "26  [organización, mundial, salud, oms, actualizad...              0   \n",
       "27  [afirmaron, expertos, escuela, medicina, harva...              0   \n",
       "28  [diabetes, patología, crónica, silenciosa, afe...              0   \n",
       "29  [estudio, español, galardonado, premio, invest...              0   \n",
       "30  [envejecer, sumar, canas, arrugas, proceso, ex...              0   \n",
       "31  [tienden, dormir, boca, pegar, ojo, boca, abaj...              0   \n",
       "32  [entrada, otoño, año, venido, marcada, crisis,...              0   \n",
       "33  [mascota, saludable, situaciones, confinamient...              0   \n",
       "34  [jugar, verdor, maleza, naturaleza, mes, sufic...              0   \n",
       "\n",
       "    predicted_class  p_health  p_sports  p_politics  \n",
       "0                 0  0.847396  0.152605    0.000000  \n",
       "1                 0  0.895831  0.069446    0.034723  \n",
       "2                 0  0.777778  0.111111    0.111111  \n",
       "3                 0  0.666667  0.000000    0.333333  \n",
       "4                 1  0.465931  0.534069    0.000000  \n",
       "5                 0  0.944681  0.055319    0.000000  \n",
       "6                 0  0.571379  0.249865    0.178756  \n",
       "7                 0  1.000000  0.000000    0.000000  \n",
       "8                 0  0.711204  0.026722    0.262074  \n",
       "9                 0  0.687010  0.104330    0.208660  \n",
       "10                0  0.761620  0.238380    0.000000  \n",
       "11                1  0.000000  1.000000    0.000000  \n",
       "12                0  0.837688  0.162312    0.000000  \n",
       "13                0  0.873477  0.126523    0.000000  \n",
       "14                0  0.706200  0.000000    0.293800  \n",
       "15                1  0.000000  1.000000    0.000000  \n",
       "16                1  0.218104  0.563791    0.218104  \n",
       "17                0  0.768622  0.231378    0.000000  \n",
       "18                1  0.250000  0.500000    0.250000  \n",
       "19                0  0.500000  0.000000    0.500000  \n",
       "20                0  0.876988  0.123012    0.000000  \n",
       "21                0  0.697181  0.302820    0.000000  \n",
       "22                0  1.000000  0.000000    0.000000  \n",
       "23                0  0.666667  0.333333    0.000000  \n",
       "24                0  0.852778  0.147222    0.000000  \n",
       "25                0  0.820948  0.000000    0.179052  \n",
       "26                0  0.881789  0.118211    0.000000  \n",
       "27                0  1.000000  0.000000    0.000000  \n",
       "28                0  0.879409  0.000000    0.120591  \n",
       "29                0  0.622105  0.094474    0.283421  \n",
       "30                0  0.666667  0.333333    0.000000  \n",
       "31                0  0.875000  0.125000    0.000000  \n",
       "32                0  1.000000  0.000000    0.000000  \n",
       "33                0  0.806574  0.000000    0.193426  \n",
       "34                0  0.718104  0.281896    0.000000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tfidf[data_tfidf[\"class\"] == \"health\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Índice",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
