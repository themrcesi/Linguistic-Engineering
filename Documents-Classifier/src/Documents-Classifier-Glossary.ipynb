{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Índice<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Carga-de-documentos\" data-toc-modified-id=\"Carga-de-documentos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Carga de documentos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preprocesado\" data-toc-modified-id=\"Preprocesado-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Preprocesado</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bigramas\" data-toc-modified-id=\"Bigramas-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Bigramas</a></span></li></ul></li></ul></li><li><span><a href=\"#Glosario\" data-toc-modified-id=\"Glosario-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Glosario</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extracción-de-keywords\" data-toc-modified-id=\"Extracción-de-keywords-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Extracción de keywords</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extracción-propia\" data-toc-modified-id=\"Extracción-propia-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Extracción propia</a></span></li><li><span><a href=\"#Gensim\" data-toc-modified-id=\"Gensim-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Gensim</a></span></li><li><span><a href=\"#Kmeans\" data-toc-modified-id=\"Kmeans-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Kmeans</a></span></li></ul></li><li><span><a href=\"#Formación-del-glosario\" data-toc-modified-id=\"Formación-del-glosario-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Formación del glosario</a></span><ul class=\"toc-item\"><li><span><a href=\"#Automatizado\" data-toc-modified-id=\"Automatizado-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Automatizado</a></span></li></ul></li></ul></li><li><span><a href=\"#Clasificador\" data-toc-modified-id=\"Clasificador-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Clasificador</a></span><ul class=\"toc-item\"><li><span><a href=\"#Carga-de-glosarios\" data-toc-modified-id=\"Carga-de-glosarios-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Carga de glosarios</a></span></li><li><span><a href=\"#Bigramas-de-test-data\" data-toc-modified-id=\"Bigramas-de-test-data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Bigramas de test data</a></span></li><li><span><a href=\"#Modelos\" data-toc-modified-id=\"Modelos-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Modelos</a></span><ul class=\"toc-item\"><li><span><a href=\"#TFIDF\" data-toc-modified-id=\"TFIDF-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>TFIDF</a></span></li><li><span><a href=\"#Word2Vec\" data-toc-modified-id=\"Word2Vec-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Word2Vec</a></span></li><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Naive Bayes</a></span></li></ul></li></ul></li><li><span><a href=\"#Clasificación-de-documentos\" data-toc-modified-id=\"Clasificación-de-documentos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Clasificación de documentos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Funciones-auxiliares\" data-toc-modified-id=\"Funciones-auxiliares-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Funciones auxiliares</a></span></li><li><span><a href=\"#Clasificación\" data-toc-modified-id=\"Clasificación-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Clasificación</a></span></li></ul></li><li><span><a href=\"#Evaluación-de-modelos\" data-toc-modified-id=\"Evaluación-de-modelos-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluación de modelos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Funciones-auxiliares\" data-toc-modified-id=\"Funciones-auxiliares-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Funciones auxiliares</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:29.551872Z",
     "start_time": "2020-12-15T21:13:28.435872Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# NLTK\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import pos_tag\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.summarization import keywords\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.similarities import Similarity\n",
    "\n",
    "# Operatos\n",
    "from operator import itemgetter\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "from spacy_spanish_lemmatizer import SpacyCustomLemmatizer\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# statistics\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# utils\n",
    "from time import sleep\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:29.555872Z",
     "start_time": "2020-12-15T21:13:29.552873Z"
    }
   },
   "outputs": [],
   "source": [
    "path_health = \"../documents/health\"\n",
    "path_politics = \"../documents/politics\"\n",
    "path_sports = \"../documents/sports\"\n",
    "path_documents = \"../documents\"\n",
    "path_stopwords = \"../documents/stopwords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:29.559872Z",
     "start_time": "2020-12-15T21:13:29.556872Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_document(path):\n",
    "    return path.split(\"\\\\\")[-1], open(path,encoding='utf-8').read(), path.split(\"\\\\\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:30.045872Z",
     "start_time": "2020-12-15T21:13:29.560873Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = Parallel(n_jobs = -1)(delayed(load_document)(path) for path in glob.glob(path_documents+\"/*/*.txt\"))\n",
    "documents = pd.DataFrame(documents, columns=[\"doc_name\", \"text\", \"class\"])\n",
    "documents['text'] = documents['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:30.059873Z",
     "start_time": "2020-12-15T21:13:30.046874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>sports_20.txt</td>\n",
       "      <td>No paró el crono en 9.58, pero casi. Aunque en...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>health_36.txt</td>\n",
       "      <td>Gestionar en cualquier ámbito y el sanitario n...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>technology_39.txt</td>\n",
       "      <td>Cuando se creó internet, la red sólo estaba di...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>technology_9.txt</td>\n",
       "      <td>Cada vez se llevan a cabo un mayor número de c...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>technology_49.txt</td>\n",
       "      <td>FORD TRABAJA EN UNA TECNOLOGÍA CAPAZ DE PREVEN...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              doc_name                                               text  \\\n",
       "112      sports_20.txt  No paró el crono en 9.58, pero casi. Aunque en...   \n",
       "29       health_36.txt  Gestionar en cualquier ámbito y el sanitario n...   \n",
       "182  technology_39.txt  Cuando se creó internet, la red sólo estaba di...   \n",
       "199   technology_9.txt  Cada vez se llevan a cabo un mayor número de c...   \n",
       "193  technology_49.txt  FORD TRABAJA EN UNA TECNOLOGÍA CAPAZ DE PREVEN...   \n",
       "\n",
       "          class  \n",
       "112      sports  \n",
       "29       health  \n",
       "182  technology  \n",
       "199  technology  \n",
       "193  technology  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = documents.sample(frac=1, random_state = 2)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:30.936872Z",
     "start_time": "2020-12-15T21:13:30.060872Z"
    }
   },
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"(\\&)|(\\%)|(\\$)|(\\€)|(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)|(\\⁰)|(\\•)|(\\\\')\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "    \n",
    "nlp = spacy.load(\"es\")\n",
    "lemmatizer = SpacyCustomLemmatizer()\n",
    "\n",
    "def load_stopwords(path):\n",
    "    return [line.strip() for line in open(path_stopwords, encoding = \"utf-8\").readlines()]\n",
    "\n",
    "STOP_WORDS = set(load_stopwords(path_stopwords))\n",
    "\n",
    "def delete_stop_words(doc):\n",
    "    tokens = wordpunct_tokenize(doc)\n",
    "    clean = [token for token in tokens if token not in STOP_WORDS and len(token) > 2]\n",
    "    return clean\n",
    "\n",
    "def preprocess_document(document):\n",
    "    document = REPLACE_NO_SPACE.sub(NO_SPACE, document.lower())\n",
    "    document = REPLACE_WITH_SPACE.sub(SPACE, document)\n",
    "    # tokens = wordpunct_tokenize(document)\n",
    "    # tokens = delete_proper_nouns(tokens)\n",
    "    return document\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    tokens = nlp(\" \".join(tokens))\n",
    "    return [token.lemma_ for token in tokens]\n",
    "\n",
    "\n",
    "# TODO: REVISAR ESTO\n",
    "\n",
    "def delete_proper_nouns(tokens):\n",
    "    # Tag the tokens with their type - ie are they nouns or not\n",
    "    lTokens = pos_tag(tokens)\n",
    "    # find all the proper nouns and print them out\n",
    "    lTagDict = findtags('NNP', lTokens)\n",
    "    return [token.lower() for token in tokens if token not in lTagDict]\n",
    "    \n",
    "def findtags(tag_prefix, tagged_text):\n",
    "    \"\"\"\n",
    "    Find tokens matching the specified tag_prefix\n",
    "    \"\"\"\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
    "                                  if tag.startswith(tag_prefix))\n",
    "    print(cfd.conditions())\n",
    "    return [list(cfd[tag].keys()) for tag in cfd.conditions()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:31.437872Z",
     "start_time": "2020-12-15T21:13:30.937873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>preprocesado</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>sports_20.txt</td>\n",
       "      <td>No paró el crono en 9.58, pero casi. Aunque en...</td>\n",
       "      <td>sports</td>\n",
       "      <td>no paró el crono en  pero casi aunque en esta ...</td>\n",
       "      <td>[paró, crono, ocasión, minutos, segundos, usai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>health_36.txt</td>\n",
       "      <td>Gestionar en cualquier ámbito y el sanitario n...</td>\n",
       "      <td>health</td>\n",
       "      <td>gestionar en cualquier ámbito y el sanitario n...</td>\n",
       "      <td>[gestionar, ámbito, sanitario, excepción, prec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>technology_39.txt</td>\n",
       "      <td>Cuando se creó internet, la red sólo estaba di...</td>\n",
       "      <td>technology</td>\n",
       "      <td>cuando se creó internet la red sólo estaba dis...</td>\n",
       "      <td>[creó, internet, red, disponible, pequeño, gru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>technology_9.txt</td>\n",
       "      <td>Cada vez se llevan a cabo un mayor número de c...</td>\n",
       "      <td>technology</td>\n",
       "      <td>cada vez se llevan a cabo un mayor número de c...</td>\n",
       "      <td>[llevan, cabo, número, compras, internet, estu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>technology_49.txt</td>\n",
       "      <td>FORD TRABAJA EN UNA TECNOLOGÍA CAPAZ DE PREVEN...</td>\n",
       "      <td>technology</td>\n",
       "      <td>ford trabaja en una tecnología capaz de preven...</td>\n",
       "      <td>[ford, tecnología, capaz, prevenir, accidentes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              doc_name                                               text  \\\n",
       "112      sports_20.txt  No paró el crono en 9.58, pero casi. Aunque en...   \n",
       "29       health_36.txt  Gestionar en cualquier ámbito y el sanitario n...   \n",
       "182  technology_39.txt  Cuando se creó internet, la red sólo estaba di...   \n",
       "199   technology_9.txt  Cada vez se llevan a cabo un mayor número de c...   \n",
       "193  technology_49.txt  FORD TRABAJA EN UNA TECNOLOGÍA CAPAZ DE PREVEN...   \n",
       "\n",
       "          class                                       preprocesado  \\\n",
       "112      sports  no paró el crono en  pero casi aunque en esta ...   \n",
       "29       health  gestionar en cualquier ámbito y el sanitario n...   \n",
       "182  technology  cuando se creó internet la red sólo estaba dis...   \n",
       "199  technology  cada vez se llevan a cabo un mayor número de c...   \n",
       "193  technology  ford trabaja en una tecnología capaz de preven...   \n",
       "\n",
       "                                                tokens  \n",
       "112  [paró, crono, ocasión, minutos, segundos, usai...  \n",
       "29   [gestionar, ámbito, sanitario, excepción, prec...  \n",
       "182  [creó, internet, red, disponible, pequeño, gru...  \n",
       "199  [llevan, cabo, número, compras, internet, estu...  \n",
       "193  [ford, tecnología, capaz, prevenir, accidentes...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[\"preprocesado\"] = documents[\"text\"].apply(lambda x: preprocess_document(x))\n",
    "documents[\"tokens\"] = documents[\"preprocesado\"].apply(lambda x: delete_stop_words(x))\n",
    "# documents[\"lematizado\"] = documents[\"preprocesado\"].apply(lambda x: lemmatize(x))\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:31.446872Z",
     "start_time": "2020-12-15T21:13:31.439873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data ==> 45 documents\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_health = documents[documents[\"class\"] == \"health\"].iloc[:15]\n",
    "train_politics = documents[documents[\"class\"] == \"politics\"].iloc[:15]\n",
    "train_sports = documents[documents[\"class\"] == \"sports\"].iloc[:15]\n",
    "\n",
    "train_data = pd.concat([train_health, train_politics, train_sports])\n",
    "print(f\"Training data ==> {len(train_data)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:31.453872Z",
     "start_time": "2020-12-15T21:13:31.447872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data ==> 105 documents\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_health = documents[documents[\"class\"] == \"health\"].iloc[15:]\n",
    "test_politics = documents[documents[\"class\"] == \"politics\"].iloc[15:]\n",
    "test_sports = documents[documents[\"class\"] == \"sports\"].iloc[15:]\n",
    "\n",
    "test_data = pd.concat([test_health, test_politics, test_sports])\n",
    "test_data.reset_index(inplace = True)\n",
    "print(f\"Testing data ==> {len(test_data)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:31.458873Z",
     "start_time": "2020-12-15T21:13:31.454873Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bigrams(documents, threshold):\n",
    "    token_ = [doc.split(\" \") for doc in documents]\n",
    "    bigram = Phrases(token_, min_count=1, threshold=threshold, delimiter=b' ')\n",
    "    bigram_phraser = Phraser(bigram)\n",
    "    bigram_token = []\n",
    "    for sent in token_:\n",
    "        for bigram in bigram_phraser[sent]:\n",
    "            if len(bigram.split(\" \")) > 1: # comprobamos que realmente es un bigrama\n",
    "                bigram_token.append(bigram) \n",
    "    return bigram_token\n",
    "           \n",
    "def check_bigram(x, bigrams):\n",
    "    if x.find(\"jamón serrano\") != -1 or x.find(\"jamón\") != -1:\n",
    "        print(x)\n",
    "    return [bigram for bigram in bigrams if x.find(bigram) != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:32.374872Z",
     "start_time": "2020-12-15T21:13:31.459873Z"
    }
   },
   "outputs": [],
   "source": [
    "bigrams_sports = get_bigrams(train_sports[\"preprocesado\"].values, 50)\n",
    "bigrams_health = get_bigrams(train_health[\"preprocesado\"].values, 50)\n",
    "bigrams_politics = get_bigrams(train_politics[\"preprocesado\"].values, 50)\n",
    "bigrams = get_bigrams(train_data[\"preprocesado\"].values, 50)\n",
    "\n",
    "\n",
    "train_sports[\"bigrams\"] = train_sports[\"preprocesado\"].apply(lambda x: check_bigram(x, bigrams_sports))\n",
    "train_health[\"bigrams\"] = train_health[\"preprocesado\"].apply(lambda x: check_bigram(x, bigrams_health))\n",
    "train_politics[\"bigrams\"] = train_politics[\"preprocesado\"].apply(lambda x: check_bigram(x, bigrams_politics))\n",
    "\n",
    "train_sports[\"tokens + bigrams\"] = train_sports[\"tokens\"] + train_sports[\"bigrams\"]\n",
    "train_health[\"tokens + bigrams\"] = train_health[\"tokens\"] + train_health[\"bigrams\"]\n",
    "train_politics[\"tokens + bigrams\"] = train_politics[\"tokens\"] + train_politics[\"bigrams\"]\n",
    "\n",
    "train_data[\"bigrams\"] = train_data[\"preprocesado\"].apply(lambda x: check_bigram(x, bigrams))\n",
    "train_data[\"tokens + bigrams\"] = train_data[\"tokens\"] + train_data[\"bigrams\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glosario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción propia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:32.378873Z",
     "start_time": "2020-12-15T21:13:32.375872Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_dir = \"../documents/stopwords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:32.384877Z",
     "start_time": "2020-12-15T21:13:32.379872Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_k_tfidf_keywords(df, k):\n",
    "    tokens = df[\"tokens + bigrams\"].values\n",
    "    dictionary = corpora.Dictionary(tokens)\n",
    "    bow = [dictionary.doc2bow(doc) for doc in tokens]\n",
    "    tfidf = models.TfidfModel(bow)\n",
    "    bow_tfidf = tfidf[bow]\n",
    "    tfidf_dic = {dictionary.get(id): value for doc in bow_tfidf for id, value in doc}\n",
    "    tfidf_list = [k for k, v in sorted(tfidf_dic.items(), key=lambda item: item[1], reverse = True)]\n",
    "    return tfidf_list[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:32.491871Z",
     "start_time": "2020-12-15T21:13:32.385872Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_tfidf_health = get_k_tfidf_keywords(train_health, 100)\n",
    "keywords_tfidf_politics = get_k_tfidf_keywords(train_politics, 100)\n",
    "keywords_tfidf_sports = get_k_tfidf_keywords(train_sports, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:32.495874Z",
     "start_time": "2020-12-15T21:13:32.492872Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(d1, d2, d3):\n",
    "\n",
    "    i1 = set(d1) & set(d2)\n",
    "    i2 = set(d1) & set(d3)\n",
    "    i3 = set(d2) & set(d3)\n",
    "    \n",
    "    deleted = set(list(i1.union(i2).union(i3)))\n",
    "    \n",
    "    for key in deleted:\n",
    "        try:\n",
    "            d1.remove(key)\n",
    "        except:\n",
    "            print(f\"D1 no tiene {key}\")\n",
    "        try:\n",
    "            d2.remove(key)\n",
    "        except:\n",
    "            print(f\"D2 no tiene {key}\")\n",
    "        try:\n",
    "            d3.remove(key)\n",
    "        except:\n",
    "            print(f\"D3 no tiene {key}\")\n",
    "            \n",
    "    return d1, d2, d3   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:32.501874Z",
     "start_time": "2020-12-15T21:13:32.496872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D3 no tiene gestión\n",
      "D1 no tiene grupos\n"
     ]
    }
   ],
   "source": [
    "keywords_tfidf_health, keywords_tfidf_politics, keywords_tfidf_sports = remove_duplicates(keywords_tfidf_health, keywords_tfidf_politics, keywords_tfidf_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:32.506872Z",
     "start_time": "2020-12-15T21:13:32.502872Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_table_keywords(health, sports, politics):\n",
    "    aa = pd.DataFrame(health, columns=[\"health\"])\n",
    "    aa[\"sports\"] = pd.Series(sports)\n",
    "    aa[\"politics\"] = pd.Series(politics)\n",
    "    print(aa.to_latex(bold_rows = True, column_format = \"lll\", index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:32.516873Z",
     "start_time": "2020-12-15T21:13:32.507872Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "               health &          sports &             politics \\\\\n",
      "\\midrule\n",
      "         tuberculosis &            golf &              estatal \\\\\n",
      "                  vph &           grupo &             canarias \\\\\n",
      "            teléfonos &       griezmann &                cajas \\\\\n",
      "              móviles &        mingueza &            las cajas \\\\\n",
      "             mascotas &         stéfano &            monarquía \\\\\n",
      "          metabolismo &         alfredo &                media \\\\\n",
      "                dosis &      di stéfano &             sociedad \\\\\n",
      "             próstata &         colinas &                 mesa \\\\\n",
      "    teléfonos móviles &         antoine &             interior \\\\\n",
      "             encierro &             par &            migrantes \\\\\n",
      "          este sábado &     candidatura &               fusión \\\\\n",
      "               sábado &             coi &      manifestaciones \\\\\n",
      "              alergia &          juegos &  armonización fiscal \\\\\n",
      "             facebook &      campeonato &                  iva \\\\\n",
      "             factores &         recinto &                nieto \\\\\n",
      "               vacuna &          koeman &                  pnv \\\\\n",
      "            contagios &         country &                  don \\\\\n",
      "         salud mental &    country club &              montero \\\\\n",
      "                láser &     necesitamos &               fiscal \\\\\n",
      "                fruta &      documental &            enmiendas \\\\\n",
      "            las redes &      inglaterra &             carrillo \\\\\n",
      "                redes &        competir &                  pnl \\\\\n",
      "               mental &           nadal &               rufián \\\\\n",
      "              cirugía &            liga &            república \\\\\n",
      "              cambiar &          birdie &           feministas \\\\\n",
      "                magra &      dechambeau &              defensa \\\\\n",
      "           masa magra &            hoyo &            expulsión \\\\\n",
      "            auténtica &             jon &             gallegas \\\\\n",
      "              mascota &            putt &        investigación \\\\\n",
      "          las células &         clásico &              interés \\\\\n",
      "              corazón &     las colinas &         interés para \\\\\n",
      "         personalidad &        bernabéu &          ha señalado \\\\\n",
      "                quizá &    acreditación &               acabar \\\\\n",
      "               grasas &         decidir &               delito \\\\\n",
      "        profesionales &           debut &             exterior \\\\\n",
      "              viernes &           óscar &                penal \\\\\n",
      "         dosificación &      diversidad &       unidas podemos \\\\\n",
      "           metabólica &        hamilton &            catalanes \\\\\n",
      "               animal &    herramientas &        media estatal \\\\\n",
      "             animales &          no soy &             gonzález \\\\\n",
      "               dueños &     ¿cómo puedo &               callar \\\\\n",
      "             lesiones &           rugby &            rodríguez \\\\\n",
      "             verrugas &            bolt &             hacienda \\\\\n",
      "            comunidad &          daniil &         ha defendido \\\\\n",
      "                  bes &        medvedev &          chiringuito \\\\\n",
      "                maira &            abdi &             don juan \\\\\n",
      "            maira bes &          ademar &                elena \\\\\n",
      "           mortalidad &          leonés &                 hija \\\\\n",
      " mortalidad prematura &           bogey &             ministra \\\\\n",
      "              navarra &     otro birdie &        un referéndum \\\\\n",
      "            prematura &            rahm &           acabar con \\\\\n",
      "           algún tipo &            bola &                 edad \\\\\n",
      "            enfermera &        femenino &               lastra \\\\\n",
      "              ensayos &          huella &             libertad \\\\\n",
      "              placebo &         leyenda &         convocatoria \\\\\n",
      "                robot &             coe &                mujer \\\\\n",
      "             cardíaca &     generalitat &            sanitaria \\\\\n",
      "               fritas &         puestos &           regulación \\\\\n",
      "                  sal &     reclamación &              causado \\\\\n",
      "              belleza &       salamanca &            diputadas \\\\\n",
      "              tinción &       todas las &        semana pasada \\\\\n",
      "          utilización &         talento &               teresa \\\\\n",
      "            microbios &        ha hecho &     teresa rodríguez \\\\\n",
      "            patógenos &       azulgrana &        transfuguismo \\\\\n",
      "        salud pública &   aparentemente &                ayuda \\\\\n",
      "              escuela &         regresa &           ayuda para \\\\\n",
      "           idealizada &         sevilla &             consenso \\\\\n",
      "             usuarios &         equipos &            diciembre \\\\\n",
      "          inmunitario &         campeón &                morir \\\\\n",
      "  sistema inmunitario &     los últimos &             ponencia \\\\\n",
      "                sueño &           goles &              armadas \\\\\n",
      "           tu sistema &         ha sido &     defensa nacional \\\\\n",
      "             compañía &  domingo contra &        instalaciones \\\\\n",
      "           se sentían &         osasuna &               loyola \\\\\n",
      "              sentían &          ronald &              militar \\\\\n",
      "              soledad &  óscar mingueza &               moción \\\\\n",
      "         sus mascotas &         costado &            eutanasia \\\\\n",
      "            tu cuerpo &      está lejos &             justicia \\\\\n",
      "              tu tasa &          genial &                pleno \\\\\n",
      "            dos dosis &     gente puede &                texto \\\\\n",
      "             estudios &      ha costado &           autonómica \\\\\n",
      "               aragón &       he estado &                vivan \\\\\n",
      "                queda &      industrias &            por tanto \\\\\n",
      "                toque &  las industrias &           migratoria \\\\\n",
      "          reino unido &     mucho mucho &  política migratoria \\\\\n",
      "          alto riesgo &          pensar &               vuelos \\\\\n",
      "            genitales &      schumacher &     tribunal supremo \\\\\n",
      "          oncogénicos &           serlo &               feijóo \\\\\n",
      "             hospital &      siempre he &              gallego \\\\\n",
      "        incontinencia &       tan bueno &            populares \\\\\n",
      "               sexual &      tiempo ser &                xunta \\\\\n",
      "             urinaria &     todos somos &          información \\\\\n",
      "               gestor &           habla &          las fuerzas \\\\\n",
      "         humanización &         valdano &                gámez \\\\\n",
      "              valores &          cuerpo &      decisiones pesc \\\\\n",
      "          por ejemplo &       mi cuerpo &                delcy \\\\\n",
      "             un nuevo &       wilkinson &      delcy rodríguez \\\\\n",
      "             alergias &           wilko &     las obligaciones \\\\\n",
      "          alimentaria &        millones &                  NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_table_keywords(keywords_tfidf_health, keywords_tfidf_sports, keywords_tfidf_politics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:32.520873Z",
     "start_time": "2020-12-15T21:13:32.517872Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_k_gensim_keywords(data, k):\n",
    "    data = data.copy()\n",
    "    data[\"joined\"] = data[\"tokens + bigrams\"].apply(lambda x: \" \".join(x))\n",
    "    data['joined'] = data.joined.astype(str)\n",
    "    data = \" \".join(data[\"joined\"].values)\n",
    "    return [key[0] for key in keywords(data, scores=True, words=k, pos_filter=('NNP', 'JJ', \"NNPS\", \"VB\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:33.705872Z",
     "start_time": "2020-12-15T21:13:32.521873Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D2 no tiene jovenes\n",
      "D3 no tiene pais\n",
      "D3 no tiene efecto\n",
      "D2 no tiene mundial\n",
      "D2 no tiene tecnica\n",
      "D1 no tiene real\n",
      "D2 no tiene anos\n",
      "D3 no tiene frente\n",
      "D2 no tiene dificil\n",
      "D2 no tiene herramientas\n",
      "D3 no tiene investigacion\n",
      "D3 no tiene hablar\n",
      "D3 no tiene proceso\n",
      "D3 no tiene general\n",
      "D3 no tiene publica\n",
      "D3 no tiene puntos\n",
      "D2 no tiene sabado\n",
      "D1 no tiene situacion\n",
      "D3 no tiene coronavirus\n",
      "D3 no tiene palabras\n",
      "D3 no tiene decision\n",
      "D3 no tiene papel\n",
      "D3 no tiene medidas\n",
      "D1 no tiene dudas\n",
      "D1 no tiene numeros\n",
      "D1 no tiene posibles\n",
      "D3 no tiene nuestro\n",
      "D3 no tiene decada\n",
      "D2 no tiene llegar\n",
      "D3 no tiene media\n",
      "D1 no tiene catalan\n",
      "D3 no tiene este\n",
      "D1 no tiene declaracion\n",
      "D3 no tiene decadas\n",
      "D3 no tiene comunidades\n",
      "D3 no tiene obstante\n",
      "D3 no tiene medida\n",
      "D2 no tiene importantes\n",
      "D1 no tiene servicios\n",
      "D3 no tiene vidas\n",
      "D3 no tiene tipo\n",
      "D3 no tiene mundo\n",
      "D3 no tiene caso\n",
      "D2 no tiene horas\n",
      "D3 no tiene sin embargo\n",
      "D3 no tiene casos\n",
      "D2 no tiene record\n",
      "D3 no tiene millon\n",
      "D1 no tiene duda\n",
      "D3 no tiene palabra\n",
      "D1 no tiene linea\n",
      "D3 no tiene presidentes\n",
      "D3 no tiene cambio\n",
      "D1 no tiene proyecto\n",
      "D3 no tiene altas\n",
      "D3 no tiene autonomas\n",
      "D1 no tiene espanoles\n",
      "D2 no tiene importante\n",
      "D3 no tiene ejecutivo\n",
      "D3 no tiene contagio\n",
      "D3 no tiene edad\n",
      "D3 no tiene comunidad\n",
      "D2 no tiene opcion\n",
      "D3 no tiene problema\n",
      "D3 no tiene ley\n",
      "D3 no tiene sobre todo\n",
      "D2 no tiene maximo\n",
      "D2 no tiene resultados\n",
      "D2 no tiene resultado\n",
      "D1 no tiene por\n",
      "D3 no tiene objetivo\n",
      "D3 no tiene social\n",
      "D3 no tiene sistema\n",
      "D1 no tiene espanol\n",
      "D3 no tiene conjunto\n",
      "D2 no tiene cada\n",
      "D3 no tiene las\n",
      "D2 no tiene ideas\n",
      "D1 no tiene condiciones\n",
      "D2 no tiene resto\n",
      "D1 no tiene espacio\n",
      "D3 no tiene han\n",
      "D3 no tiene trata\n",
      "D3 no tiene autonomicos\n",
      "D3 no tiene objetivos\n",
      "D3 no tiene jueves\n",
      "D1 no tiene declaraciones\n",
      "D3 no tiene control\n"
     ]
    }
   ],
   "source": [
    "keywords_gensim_health = get_k_gensim_keywords(train_health, 300)\n",
    "keywords_gensim_politics = get_k_gensim_keywords(train_politics, 300)\n",
    "keywords_gensim_sports = get_k_gensim_keywords(train_sports, 300)\n",
    "\n",
    "keywords_gensim_health, keywords_k_gensim_politics, keywords_k_gensim_sports = remove_duplicates(keywords_gensim_health, keywords_gensim_politics, keywords_gensim_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:33.721873Z",
     "start_time": "2020-12-15T21:13:33.706872Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "                     health &                       sports &                               politics \\\\\n",
      "\\midrule\n",
      "                 saludables &                     partidos &                              gobiernos \\\\\n",
      "                  saludable &                       equipo &                        gobierno unidas \\\\\n",
      "                    estudio &                      equipos &                                 madrid \\\\\n",
      "                   estudios &                        juego &                              diputados \\\\\n",
      "                    gestion &                        barca &                               diputado \\\\\n",
      "                 enfermedad &               jugado partido &                              politicas \\\\\n",
      "               enfermedades &                        goles &                               politica \\\\\n",
      "                      tipos &                    temporada &                               vox psoe \\\\\n",
      "         humanizacion salud &                   temporadas &                               comision \\\\\n",
      "                     riesgo &                  competicion &                                partido \\\\\n",
      "                     formas &                competiciones &                              monarquia \\\\\n",
      "                  pacientes &                         club &                               fiscales \\\\\n",
      "                   paciente &                        grupo &                              ciudadano \\\\\n",
      "            cambios riesgos &              juegos invierno &                              proyectos \\\\\n",
      "                    efectos &                     gano las &                               portavoz \\\\\n",
      "                     vacuna &                    jugadores &                              andalucia \\\\\n",
      "                    vacunas &              atletico madrid &                                 debate \\\\\n",
      "                     cuerpo &                    champions &                                debates \\\\\n",
      "                      puede &           mingueza barcelona &                            socialistas \\\\\n",
      "                     puedes &                       futbol &                             socialista \\\\\n",
      "                    mascota &                         liga &                             anos hijos \\\\\n",
      "                   mascotas &                     clasicos &                    armonizacion fiscal \\\\\n",
      "                   telefono &                      clasico &                              catalanes \\\\\n",
      "                  telefonos &                       maxima &                     mayoria ciudadanos \\\\\n",
      "                   pandemia &                      maximas &                                derecho \\\\\n",
      "                  pandemias &                    azulgrana &                             territorio \\\\\n",
      "                     alarma &                   azulgranas &  baja grupo parlamentario consecuencia \\\\\n",
      "                      mucho &                       minuto &                         pacto partidos \\\\\n",
      "                     muchos &                          muy &                                  forma \\\\\n",
      "                   prostata &                     registro &                        rey juan carlos \\\\\n",
      "                    viernes &            antoine griezmann &                               congreso \\\\\n",
      "               tuberculosis &                      stefano &                             argumentos \\\\\n",
      "                   tecnicas &              ocasion minutos &                              argumento \\\\\n",
      "             investigadores &                 ruso jugador &                              republica \\\\\n",
      "               investigador &                      haaland &                                informe \\\\\n",
      "                      datos &           jornadas registros &                               informes \\\\\n",
      "                    corazon &                        jugar &                           constitucion \\\\\n",
      "                    explica &                          gol &                         constitucional \\\\\n",
      "                   procesos &                          vio &                                defensa \\\\\n",
      "          sistemas pantalla &                         toda &           apoyo presupuestos generales \\\\\n",
      "                      covid &                        todas &                                montero \\\\\n",
      "               tejido virus &                 colinas golf &                               acuerdos \\\\\n",
      "               forma futuro &                      estadio &                     territorios acabar \\\\\n",
      "                universidad &                      domingo &                              reuniones \\\\\n",
      "                      dosis &                         cita &                 sanchez vicepresidente \\\\\n",
      "                    celulas &                        citas &                               canarias \\\\\n",
      "                     celula &                         copa &                                canaria \\\\\n",
      "                    comidas &                        campo &                               nacional \\\\\n",
      "                     grasas &                         alli &                                 reales \\\\\n",
      "                     unidos &                         bota &                              catalunya \\\\\n",
      "            grupo alimentos &                        botas &                              enmiendas \\\\\n",
      "                    cirugia &                      jornada &                               enmienda \\\\\n",
      "                   alimento &                  gente pasar &                                    pnv \\\\\n",
      "                      serie &                   mundo zona &                              rodriguez \\\\\n",
      "        presidente gobierno &                  candidatura &                                  texto \\\\\n",
      " alergias alimentarias hora &                 candidaturas &                         parlamentarios \\\\\n",
      "                voluntarios &                     femenino &                                iglesia \\\\\n",
      "                     doctor &                         duro &                               impuesto \\\\\n",
      "                metabolismo &                        duros &                               ministro \\\\\n",
      "                  sanitaria &                        costo &                              ministros \\\\\n",
      "                  por todos &                   presidente &                              formacion \\\\\n",
      "                  autentica &                      campeon &                            formaciones \\\\\n",
      "                 autenticas &                         pese &                       presidente pedro \\\\\n",
      "                    moderna &                          coi &                         defendido hora \\\\\n",
      "                        vph &                        marca &                            reunion mes \\\\\n",
      "                   bacteria &                        hoyos &                              militares \\\\\n",
      "                  bacterias &                         hoyo &                                militar \\\\\n",
      "                   encierro &                 acreditacion &                                  bildu \\\\\n",
      "             confinamientos &               acreditaciones &                            republicano \\\\\n",
      "              confinamiento &                         putt &                           republicanos \\\\\n",
      "                   probable &                        putts &                             democracia \\\\\n",
      "                      tasas &                      titulos &                                derecha \\\\\n",
      "                     medico &                 titulo falta &                               derechas \\\\\n",
      "                    medicos &                          mal &                             propuestas \\\\\n",
      "                     mental &          pandemia conseguido &                               publicas \\\\\n",
      "                      laser &                     camiseta &                                   voto \\\\\n",
      "                    laseres &                    camisetas &             derechos responsabilidades \\\\\n",
      "                  sanitario &                        aires &                             diaz ayuso \\\\\n",
      "                      clave &                   documental &                                cuentas \\\\\n",
      "                       debe &                        mejor &                         pablo iglesias \\\\\n",
      "                      debes &                      birdies &                                fuerzas \\\\\n",
      "                diferencias &                      rivales &                       autonomico calvo \\\\\n",
      "                 diferencia &                   entrevista &                                estatal \\\\\n",
      "                   ejemplos &                       pelota &                                podemos \\\\\n",
      "        gestores sanitarios &                      pelotas &                              asegurado \\\\\n",
      "           cantidades grasa &                        feliz &                               carrillo \\\\\n",
      "                    sanchez &        instalaciones recinto &                              diputadas \\\\\n",
      "                      gente &  maximos goleadores historia &                               diputada \\\\\n",
      "  records contagios diarios &                    companero &                                 visita \\\\\n",
      "                    moviles &                   companeros &                                visitas \\\\\n",
      "                      movil &                      decidir &                                    erc \\\\\n",
      "            investigaciones &                       obligo &             independentistas propuesta \\\\\n",
      "               muertes tasa &                     estrella &                                popular \\\\\n",
      "       desarrollar opciones &                    estrellas &                              populares \\\\\n",
      "                       alta &             mundiales puntos &                            nieto horas \\\\\n",
      "                     gestor &                 llevo marcas &                                 felipe \\\\\n",
      "                reino unido &                          los &                           expresidente \\\\\n",
      "        alimentacion comida &                       europa &                               sociedad \\\\\n",
      "                    ensayos &             mejores opciones &                             sociedades \\\\\n",
      "                     ensayo &                     marcador &                            informacion \\\\\n",
      "                    niveles &                         bola &                          informaciones \\\\\n",
      "                      nivel &                     goleador &                              eutanasia \\\\\n",
      "         provocar problemas &                        balon &                       tribunal supremo \\\\\n",
      "                  organismo &                  idea volver &                       bajada impuestos \\\\\n",
      "                 organismos &                   industrias &         publico fuentes parlamentarias \\\\\n",
      "                     muerte &                    industria &                                 lineas \\\\\n",
      "                   clinicos &                 entrenadores &                          juridico mesa \\\\\n",
      "                    clinico &                   entrenador &                                   para \\\\\n",
      "                   facebook &              servicio blanco &                             referendum \\\\\n",
      "                   regiones &             duelos femeninos &                                  maria \\\\\n",
      "                     region &                records nivel &                             decisiones \\\\\n",
      "                   regional &                   campeonato &                                 callar \\\\\n",
      "                     factor &                       queria &                                    pnl \\\\\n",
      "                   factores &                         hora &                         pandemia covid \\\\\n",
      "                    factors &                     siquiera &                               mayorias \\\\\n",
      "             casas modernas &                        todos &                              condicion \\\\\n",
      "                     centro &                         todo &                                  enero \\\\\n",
      "                    centros &                         pero &                         vicepresidenta \\\\\n",
      "                    tincion &                          psg &                              migrantes \\\\\n",
      "                  tinciones &                   rojiblanco &                               gonzalez \\\\\n",
      "           energia necesita &                       encima &                                  bajas \\\\\n",
      "                     prueba &          campeonatos igualar &                              izquierda \\\\\n",
      "                    pruebas &                   complicado &                             izquierdas \\\\\n",
      "             sanitarias uci &                  complicados &                             parlamento \\\\\n",
      "                    cambiar &                     olimpica &                           jose ignacio \\\\\n",
      "                herramienta &                        palos &                    camara votos marcha \\\\\n",
      "                       pene &                         palo &                               publicos \\\\\n",
      "                      robot &                     dortmund &                                   unas \\\\\n",
      "                 secundario &                bogeys birdie &                               sociales \\\\\n",
      "                secundarios &                          par &                             madrilenos \\\\\n",
      "                       cabo &                        unico &                              madrileno \\\\\n",
      "                  ejercicio &                         alla &                        independentista \\\\\n",
      "                 ejercicios &                  semifinales &                                escrito \\\\\n",
      "                     frutas &                  aficionados &                                 asunto \\\\\n",
      "                      fruta &                        nadal &                                  falta \\\\\n",
      "                      nuevo &                        joven &                                  comun \\\\\n",
      "                     nuevos &                      talento &                                comunes \\\\\n",
      "                  infeccion &                       koeman &                              juridicos \\\\\n",
      "                infecciones &                        mismo &                              direccion \\\\\n",
      "              ejemplo mejor &                  aire ganado &                              politicos \\\\\n",
      "                    vinculo &                   dechambeau &                               politico \\\\\n",
      "                   vinculos &                    realmente &                             libertades \\\\\n",
      "                   eficacia &                      noruego &                               libertad \\\\\n",
      "             sufrir alergia &                          red &                             garcia luz \\\\\n",
      "                actividades &                      alfredo &                               senalado \\\\\n",
      "                  actividad &           diversidad defensa &                              respuesta \\\\\n",
      "                   atencion &                       golpes &                     asuntos sanitarios \\\\\n",
      "     mayores probabilidades &                        golpe &                         cajas gallegas \\\\\n",
      "                  inyeccion &                   inglaterra &                               discurso \\\\\n",
      "                       idea &                    sensacion &                              discursos \\\\\n",
      "                 demostrado &                  sensaciones &                                 delito \\\\\n",
      " aragon asturias registrado &                       metros &                                delitos \\\\\n",
      "                     javier &                      puestos &                               interior \\\\\n",
      "                      menor &                       puesto &                                 rufian \\\\\n",
      "                    menores &                        podia &                                felones \\\\\n",
      "                       malo &                       leones &                                  felon \\\\\n",
      "               probabilidad &               calderon wanda &                               familias \\\\\n",
      "                     cancer &                       volvio &                     importante familia \\\\\n",
      "                   canceres &                        nueve &                              funciones \\\\\n",
      "                       alto &                     terminos &                                funcion \\\\\n",
      "                   nuestros &                      termino &                               espacios \\\\\n",
      "                  necesitas &                         otro &                                 medios \\\\\n",
      "                    capaces &                      limites &                                  medio \\\\\n",
      "                  bienestar &                       limite &                               ministra \\\\\n",
      "                     dietas &                       empate &                                 fusion \\\\\n",
      "                      dieta &                      empates &                                   peor \\\\\n",
      "                mayor parte &   manos especialmente figura &                           obligaciones \\\\\n",
      "                   lesiones &                        lucha &                             obligacion \\\\\n",
      "                     lesion &             figuras conjunto &                     esperanza asimismo \\\\\n",
      "                       mano &                    convirtio &                                opinion \\\\\n",
      "                      manos &                        cifra &                          instalaciones \\\\\n",
      "             tejidos indica &                       cifras &                            instalacion \\\\\n",
      "                    sentian &                       tantos &                                  carta \\\\\n",
      "                    placebo &                      mercado &                            presentadas \\\\\n",
      "                   placebos &                        juega &                         intervenciones \\\\\n",
      "                   hospital &             problema apostar &                           intervencion \\\\\n",
      "                       fase &                        bogey &                                 actual \\\\\n",
      "                   cuidados &                        sigue &                               actuales \\\\\n",
      "                    cuidado &                      triunfo &                                  zonas \\\\\n",
      "              profesionales &                        sobre &                              coherente \\\\\n",
      "                    produce &                  necesitamos &   sanitario manifestaciones feministas \\\\\n",
      "                    maximos &                       carlos &                          union europea \\\\\n",
      "                   calorias &                     porteria &                             estrategia \\\\\n",
      "                    valores &               enfrentamiento &                manifestacion feminista \\\\\n",
      "              publicaciones &              enfrentamientos &                              contagios \\\\\n",
      "                publicacion &                    problemas &                              provocado \\\\\n",
      "                   vitamina &                deporte culpa &                        independentismo \\\\\n",
      "                  vitaminas &                     hamilton &                  mismo tiempo adelante \\\\\n",
      "                     muchas &                 leon penalti &                             referencia \\\\\n",
      "                    higiene &                         sido &                                mujeres \\\\\n",
      "                   patogeno &                        messi &                                  vuelo \\\\\n",
      "                  patogenos &            recuerda sonrisas &                                 vuelos \\\\\n",
      "                       test &                        duelo &                             autonomica \\\\\n",
      "               organizacion &                        river &                            autonomicas \\\\\n",
      "                     duenos &                      frances &                   alta responsabilidad \\\\\n",
      "                      capas &                     competir &                                  plena \\\\\n",
      "                       capa &                       alexia &                       crisis sanitaria \\\\\n",
      "                    aumento &                      planeta &                                 martes \\\\\n",
      "                   aumentos &                    categoria &                    peticion presentada \\\\\n",
      "                 autonomico &                   categorias &                                   hijo \\\\\n",
      "                  sustancia &                    supercopa &                       zona comunitaria \\\\\n",
      "                 sustancias &                     presenta &                               criticas \\\\\n",
      "                     diario &               detras sonrisa &                                critica \\\\\n",
      "                   cantidad &                       ademar &                                  norma \\\\\n",
      "                     placas &                       torneo &                                 carmen \\\\\n",
      "                      placa &                      directa &                          abordar curso \\\\\n",
      "             redes sociales &                     directas &                                interes \\\\\n",
      "                     sexual &                  generalitat &                             elecciones \\\\\n",
      "                alimentaria &                          que &                                  vivas \\\\\n",
      "                  positivos &                     bernabeu &                                  gamez \\\\\n",
      "                  enfermera &                         galo &                                consejo \\\\\n",
      "                  prematura &               salida cambios &                             particular \\\\\n",
      "                 prematuras &                     jon rahm &                    ministerio hacienda \\\\\n",
      "                     partes &           cuerpo herramienta &                                gallega \\\\\n",
      "                      vasco &                 exitos lejos &                                quieren \\\\\n",
      "                     vascos &                    presencia &                              expulsion \\\\\n",
      "                     senala &                       puerta &                                impacto \\\\\n",
      "                    journal &                       estilo &                                moncloa \\\\\n",
      "     incontinencia urinaria &                        perez &                                 teresa \\\\\n",
      "                   ereccion &            huella banquillos &                               terrenos \\\\\n",
      "                 erecciones &                         saco &                                terreno \\\\\n",
      "                    mayoria &                          sin &                               defendio \\\\\n",
      "                 porcentaje &                          coe &                            ministerios \\\\\n",
      "                porcentajes &                          sur &                                   mayo \\\\\n",
      "                     evitar &                    salamanca &                        violencia mujer \\\\\n",
      "                      otras &                      goleada &                              contrario \\\\\n",
      "                       otra &                     goleadas &                             contrarios \\\\\n",
      "                       diez &                    consiguio &                               victoria \\\\\n",
      "                      danar &                         vive &                              victorias \\\\\n",
      "                    musculo &                        claro &                               absoluta \\\\\n",
      "                   musculos &                       claros &                             prestacion \\\\\n",
      "                   animales &                      aficion &                                 lastra \\\\\n",
      "             asocio belleza &                      leyenda &                              subrayado \\\\\n",
      "                      amigo &                     relacion &                             garantizar \\\\\n",
      "                     amigos &                    conjuntos &                          parlamentaria \\\\\n",
      "                       casa &                    wilkinson &                                 amplio \\\\\n",
      "             ayudar aumenta &                      parecen &                              coalicion \\\\\n",
      "        masa magra realidad &                      carrera &                                provoco \\\\\n",
      "               medicamentos &                        fases &                              necesario \\\\\n",
      "                  publicado &                     penaltis &                             necesarios \\\\\n",
      "                 publicados &              daniil medvedev &                               miembros \\\\\n",
      "                    momento &                         bolt &                                miembro \\\\\n",
      "                   momentos &       cambio defensivo galos &                              economica \\\\\n",
      "                transmision &                         kiev &                             economicas \\\\\n",
      "                   llamadas &                       debajo &                              encuestas \\\\\n",
      "                    llamada &                      cuerpos &                               encuesta \\\\\n",
      "                disminucion &                oportunidades &                             sanitarias \\\\\n",
      "              disminuciones &                  oportunidad &                                  penal \\\\\n",
      "                      largo &                    banquillo &                             peticiones \\\\\n",
      "               trato humano &                      ultimos &                                sentido \\\\\n",
      "                     graves &                    recuerdas &                          instituciones \\\\\n",
      "                      grave &                  rendimiento &                            institucion \\\\\n",
      "                utilizacion &                         tomo &                                cambios \\\\\n",
      "                      siglo &                    encontrar &                              consentir \\\\\n",
      "                    mejores &                  reclamacion &                            celebracion \\\\\n",
      "               personalidad &               participa fase &                            sentimiento \\\\\n",
      "                  microbios &                    catalanas &                               servicio \\\\\n",
      "                     animal &       recuerdo entrenamiento &                             naturaleza \\\\\n",
      "                   sintomas &                        bueno &                             dirigentes \\\\\n",
      "                    entorno &                       buenos &                              dirigente \\\\\n",
      "                   entornos &                         mala &                             respondido \\\\\n",
      "                    decreto &                   ademarista &                                felonia \\\\\n",
      "                diagnostico &                  ademaristas &                               votacion \\\\\n",
      "                      meses &                      edicion &                             votaciones \\\\\n",
      "                   seguidas &                    ediciones &                                  pleno \\\\\n",
      "                    seguida &                        exito &                            chiringuito \\\\\n",
      "                    humanos &                        sedes &                          consecuencias \\\\\n",
      "                  aumentado &                         sede &                               igualdad \\\\\n",
      "                    revista &                       manana &                                    rae \\\\\n",
      "                   revistas &                      sevilla &                             escandalos \\\\\n",
      "            alcohol mujeres &                       gerard &                              escandalo \\\\\n",
      "                  dificiles &                    principio &                              expresado \\\\\n",
      "                       ucis &                    britanico &                                  padre \\\\\n",
      "                    fuentes &                      estreno &                               noticias \\\\\n",
      "                     fuente &                        queda &                                noticia \\\\\n",
      "                 suficiente &                     acciones &                             violencias \\\\\n",
      "                suficientes &                      abierta &                               espanola \\\\\n",
      "                 valenciana &                       suerte &                              espanolas \\\\\n",
      "                emergencias &                        debut &                                    NaN \\\\\n",
      "                 emergencia &                     borussia &                                    NaN \\\\\n",
      "                   cardiaco &                        lucin &                                    NaN \\\\\n",
      "                  historico &                      encajar &                                    NaN \\\\\n",
      "                     paises &                    seleccion &                                    NaN \\\\\n",
      "                toque queda &                      publico &                                    NaN \\\\\n",
      "                fundamental &                     alcanzar &                                    NaN \\\\\n",
      "                    soledad &                        local &                                    NaN \\\\\n",
      "                       puig &                      ventaja &                                    NaN \\\\\n",
      "                      quiza &                     ventajas &                                    NaN \\\\\n",
      "                   robotica &                      llevaba &                                    NaN \\\\\n",
      "                     rapida &                     supuesto &                                    NaN \\\\\n",
      "                    rapidas &                          NaN &                                    NaN \\\\\n",
      "                   farmacos &                          NaN &                                    NaN \\\\\n",
      "                   concluye &                          NaN &                                    NaN \\\\\n",
      "                 frecuencia &                          NaN &                                    NaN \\\\\n",
      "                frecuencias &                          NaN &                                    NaN \\\\\n",
      "                    teorias &                          NaN &                                    NaN \\\\\n",
      "                     teoria &                          NaN &                                    NaN \\\\\n",
      "                   asociada &                          NaN &                                    NaN \\\\\n",
      "                  asociadas &                          NaN &                                    NaN \\\\\n",
      "                      mujer &                          NaN &                                    NaN \\\\\n",
      "             fallecimientos &                          NaN &                                    NaN \\\\\n",
      "              fallecimiento &                          NaN &                                    NaN \\\\\n",
      "                  pantallas &                          NaN &                                    NaN \\\\\n",
      "                       leon &                          NaN &                                    NaN \\\\\n",
      "                 reduciendo &                          NaN &                                    NaN \\\\\n",
      "                   clinicas &                          NaN &                                    NaN \\\\\n",
      "                    clinica &                          NaN &                                    NaN \\\\\n",
      "                     fiebre &                          NaN &                                    NaN \\\\\n",
      "                    estados &                          NaN &                                    NaN \\\\\n",
      "                   completa &                          NaN &                                    NaN \\\\\n",
      "                  completas &                          NaN &                                    NaN \\\\\n",
      "                   personal &                          NaN &                                    NaN \\\\\n",
      "                   autonoma &                          NaN &                                    NaN \\\\\n",
      "                   practica &                          NaN &                                    NaN \\\\\n",
      "                  practicas &                          NaN &                                    NaN \\\\\n",
      "                     activo &                          NaN &                                    NaN \\\\\n",
      "                    activos &                          NaN &                                    NaN \\\\\n",
      "                       piel &                          NaN &                                    NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_table_keywords(keywords_gensim_health, keywords_k_gensim_sports, keywords_k_gensim_politics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:33.762871Z",
     "start_time": "2020-12-15T21:13:33.722872Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_k_kmeans_keywords(data, k):\n",
    "    data = data.copy()\n",
    "    data[\"joined\"] = data[\"tokens\"].apply(lambda x: \" \".join(x))\n",
    "    k_means_data = data[\"joined\"].values\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "    X = vectorizer.fit_transform(k_means_data)\n",
    "    \n",
    "    model = KMeans(n_clusters=3, init='k-means++', max_iter=1000, n_init=1, random_state = 5, algorithm=\"full\")\n",
    "    model.fit(X)\n",
    "    \n",
    "    order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    \n",
    "    keywords_kmeans_politics = [terms[ind] for ind in order_centroids[0, :k]]\n",
    "    keywords_kmeans_health = [terms[ind] for ind in order_centroids[1, :k]]\n",
    "    keywords_kmeans_sports = [terms[ind] for ind in order_centroids[2, :k]]\n",
    "    \n",
    "    return keywords_kmeans_politics, keywords_kmeans_health, keywords_kmeans_sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:33.882871Z",
     "start_time": "2020-12-15T21:13:33.765871Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n",
      "D2 no tiene ley\n",
      "D2 no tiene horas\n",
      "D2 no tiene año\n",
      "D2 no tiene semana\n",
      "D2 no tiene gobierno\n",
      "D3 no tiene juego\n",
      "D1 no tiene media\n",
      "D2 no tiene día\n",
      "D3 no tiene español\n",
      "D2 no tiene sánchez\n",
      "D2 no tiene comisión\n",
      "D2 no tiene sistema\n",
      "D2 no tiene enfermedad\n",
      "D1 no tiene andalucía\n",
      "D2 no tiene años\n",
      "D2 no tiene forma\n",
      "D1 no tiene salud\n",
      "D2 no tiene fiscal\n",
      "D2 no tiene goles\n",
      "D2 no tiene presupuestos\n",
      "78 90 77\n"
     ]
    }
   ],
   "source": [
    "keywords_kmeans_politics, keywords_kmeans_health, keywords_kmeans_sports = get_k_kmeans_keywords(train_data, 100)\n",
    "print(len(keywords_kmeans_politics), len(keywords_kmeans_health), len(keywords_kmeans_sports))\n",
    "keywords_kmeans_politics, keywords_kmeans_health, keywords_kmeans_sports = remove_duplicates(keywords_kmeans_politics, keywords_kmeans_health, keywords_kmeans_sports)\n",
    "print(len(keywords_kmeans_politics), len(keywords_kmeans_health), len(keywords_kmeans_sports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:33.893871Z",
     "start_time": "2020-12-15T21:13:33.884871Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "              health &               sports &          politics \\\\\n",
      "\\midrule\n",
      "           monarquía &                grupo &           gestión \\\\\n",
      "                 rey &               vacuna &              golf \\\\\n",
      "           teléfonos &                dosis &             barça \\\\\n",
      "           república &                  vph &          proyecto \\\\\n",
      "             móviles &                covid &      tuberculosis \\\\\n",
      "            mascotas &            contagios &            equipo \\\\\n",
      "             estatal &               riesgo &           partido \\\\\n",
      "         metabolismo &               grupos &         griezmann \\\\\n",
      "             stéfano &          coronavirus &         barcelona \\\\\n",
      "              carlos &              montero &           defensa \\\\\n",
      "   teléfonos móviles &                casos &          política \\\\\n",
      "            encierro &                virus &              club \\\\\n",
      "                juan &                 tipo &          canarias \\\\\n",
      "         juan carlos &             próstata &          mingueza \\\\\n",
      "              mental &              haaland &              liga \\\\\n",
      "             alfredo &              moderna &          atlético \\\\\n",
      "        salud mental &             eficacia &               pnv \\\\\n",
      "                 par &               sábado &          ministro \\\\\n",
      "                 don &              alergia &             cajas \\\\\n",
      "                bola &            comunidad &         auténtica \\\\\n",
      "           catalanes &            ejecutivo &           supremo \\\\\n",
      "              cuerpo &            enmiendas &             gente \\\\\n",
      "          masa magra &              medidas &          facebook \\\\\n",
      "               magra &               grasas &           espacio \\\\\n",
      "             mascota &               alarma &            cambio \\\\\n",
      "              birdie &                 mesa &              vida \\\\\n",
      "          dechambeau &             ministra &          partidos \\\\\n",
      "                putt &                 baja &           colinas \\\\\n",
      "                 jon &                láser &           antoine \\\\\n",
      "                hoyo &            diputados &       competición \\\\\n",
      "                real &  armonización fiscal &          congreso \\\\\n",
      "            bernabéu &                ayuso &            fusión \\\\\n",
      "               nadal &          voluntarios &          nacional \\\\\n",
      "                masa &              corazón &         migrantes \\\\\n",
      "       media estatal &            champions &             mundo \\\\\n",
      "          referéndum &              informe &          portavoz \\\\\n",
      "                tasa &          comunidades &         azulgrana \\\\\n",
      "              dueños &              escrito &       necesitamos \\\\\n",
      "            animales &              células &     investigación \\\\\n",
      "              animal &                 fase &     instalaciones \\\\\n",
      "     tasa metabólica &              cirugía &          sociedad \\\\\n",
      "          metabólica &                texto &            juegos \\\\\n",
      "            carrillo &         armonización &               coi \\\\\n",
      "                 pnl &             millones &          factores \\\\\n",
      "            probable &      manifestaciones &      country club \\\\\n",
      "                casa &            pacientes &      colinas golf \\\\\n",
      "          democracia &              efectos &           country \\\\\n",
      "          ciudadanos &             pandemia &      golf country \\\\\n",
      "           catalunya &                fruta &    redes sociales \\\\\n",
      "            estudios &            situación &             redes \\\\\n",
      "               elena &                tipos &            quería \\\\\n",
      "               bogey &                 país &          interior \\\\\n",
      "                rahm &             hacienda &        documental \\\\\n",
      "            compañía &        parlamentario &               mes \\\\\n",
      "              felipe &                 días &        campeonato \\\\\n",
      "             leyenda &                final &           recinto \\\\\n",
      "              huella &               bajada &         rodríguez \\\\\n",
      "              daniil &                nieto &            koeman \\\\\n",
      "            medvedev &                  iva &            callar \\\\\n",
      "              blanco &              explica &         temporada \\\\\n",
      "             obtiene &               comida &        inglaterra \\\\\n",
      "            diputado &                 malo &        socialista \\\\\n",
      "        constitución &               doctor &       candidatura \\\\\n",
      "           microbios &                 idea &           cambiar \\\\\n",
      "           patógenos &               precio &           domingo \\\\\n",
      "             soledad &               frente &          gonzález \\\\\n",
      "             sentían &                datos &      herramientas \\\\\n",
      "               carta &            infección &        decisiones \\\\\n",
      "            rey juan &                quizá &             campo \\\\\n",
      "            don juan &               oxford &      expresidente \\\\\n",
      "          complicada &              campeón &          competir \\\\\n",
      "                ruso &               ensayo &           talento \\\\\n",
      "            teléfono &            inyección &          sociales \\\\\n",
      "       confinamiento &                mitad &           acuerdo \\\\\n",
      "                hija &                  vox &             fácil \\\\\n",
      "             persona &           feministas &    investigadores \\\\\n",
      " monarquía república &             técnicas &          exterior \\\\\n",
      "             familia &                  NaN &  defensa nacional \\\\\n",
      "            servicio &                  NaN &               NaN \\\\\n",
      "           bacterias &                  NaN &               NaN \\\\\n",
      "            calorías &                  NaN &               NaN \\\\\n",
      "             mayoría &                  NaN &               NaN \\\\\n",
      " monarquía catalunya &                  NaN &               NaN \\\\\n",
      "        puntos media &                  NaN &               NaN \\\\\n",
      "           alimentos &                  NaN &               NaN \\\\\n",
      "               único &                  NaN &               NaN \\\\\n",
      "                 iba &                  NaN &               NaN \\\\\n",
      "               gámez &                  NaN &               NaN \\\\\n",
      "              debate &                  NaN &               NaN \\\\\n",
      "          finalmente &                  NaN &               NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_table_keywords(keywords_kmeans_health, keywords_kmeans_sports, keywords_kmeans_politics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formación del glosario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:33.905871Z",
     "start_time": "2020-12-15T21:13:33.894872Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_relevant_keywords(d1, d2, d3):\n",
    "    i1 = set(d1) & set(d2)\n",
    "    i2 = set(d1) & set(d3)\n",
    "    i3 = set(d2) & set(d3)\n",
    "    \n",
    "    deleted = set(list(i1.union(i2).union(i3)))\n",
    "    return deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:33.916872Z",
     "start_time": "2020-12-15T21:13:33.906871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politics ==>  ['decisiones', 'penal', 'sociedad', 'delito', 'defensa nacional', 'populares', 'investigación', 'rodríguez', 'lastra', 'chiringuito', 'vuelos', 'gonzález', 'catalanes', 'portavoz', 'expresidente', 'eutanasia', 'diputadas', 'ministro', 'nacional', 'defensa', 'pnv', 'tribunal supremo', 'fusión', 'cajas', 'canarias', 'partido', 'pleno', 'sociales', 'texto', 'socialista', 'montero', 'enmiendas', 'callar', 'congreso', 'teresa', 'carrillo', 'ministra', 'estatal', 'militar', 'instalaciones', 'exterior', 'libertad', 'pnl', 'interior', 'migrantes']\n",
      "Sports ==>  ['competir', 'necesitamos', 'debut', 'koeman', 'bogey', 'documental', 'industrias', 'dechambeau', 'candidatura', 'puestos', 'hamilton', 'champions', 'coi', 'ademar', 'par', 'sevilla', 'haaland', 'alfredo', 'decidir', 'femenino', 'campeón', 'liga', 'inglaterra', 'azulgrana', 'nadal', 'equipos', 'millones', 'campeonato', 'goles', 'bola', 'generalitat', 'grupo', 'leyenda', 'coe', 'talento', 'bolt', 'wilkinson', 'putt', 'salamanca', 'hoyo']\n",
      "Health ==>  ['profesionales', 'viernes', 'mascota', 'confinamiento', 'dueños', 'prematura', 'valores', 'robot', 'probable', 'grasas', 'sentían', 'salud mental', 'cambiar', 'metabólica', 'tuberculosis', 'fruta', 'hospital', 'facebook', 'enfermera', 'animales', 'animal', 'móviles', 'dosis', 'mental', 'ensayos', 'casa', 'patógenos', 'personalidad', 'encierro', 'teléfonos', 'mascotas', 'vph', 'placebo', 'cuerpo', 'alimentaria', 'lesiones', 'reino unido', 'factores', 'estudios', 'sexual', 'magra', 'microbios', 'vacuna', 'gestor', 'bacterias', 'teléfonos móviles', 'compañía', 'masa magra', 'metabolismo', 'soledad']\n"
     ]
    }
   ],
   "source": [
    "relevant_keywords_politics = list(check_relevant_keywords(keywords_kmeans_politics, keywords_gensim_politics, keywords_tfidf_politics))\n",
    "relevant_keywords_health = list(check_relevant_keywords(keywords_kmeans_health, keywords_gensim_health, keywords_tfidf_health))\n",
    "relevant_keywords_sports = list(check_relevant_keywords(keywords_kmeans_sports, keywords_gensim_sports, keywords_tfidf_sports))\n",
    "\n",
    "print(\"Politics ==> \", relevant_keywords_politics)\n",
    "print(\"Sports ==> \", relevant_keywords_sports)\n",
    "print(\"Health ==> \", relevant_keywords_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:33.925871Z",
     "start_time": "2020-12-15T21:13:33.917872Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "            health &       sports &          politics \\\\\n",
      "\\midrule\n",
      "     profesionales &     competir &        decisiones \\\\\n",
      "           viernes &  necesitamos &             penal \\\\\n",
      "           mascota &        debut &          sociedad \\\\\n",
      "     confinamiento &       koeman &            delito \\\\\n",
      "            dueños &        bogey &  defensa nacional \\\\\n",
      "         prematura &   documental &         populares \\\\\n",
      "           valores &   industrias &     investigación \\\\\n",
      "             robot &   dechambeau &         rodríguez \\\\\n",
      "          probable &  candidatura &            lastra \\\\\n",
      "            grasas &      puestos &       chiringuito \\\\\n",
      "           sentían &     hamilton &            vuelos \\\\\n",
      "      salud mental &    champions &          gonzález \\\\\n",
      "           cambiar &          coi &         catalanes \\\\\n",
      "        metabólica &       ademar &          portavoz \\\\\n",
      "      tuberculosis &          par &      expresidente \\\\\n",
      "             fruta &      sevilla &         eutanasia \\\\\n",
      "          hospital &      haaland &         diputadas \\\\\n",
      "          facebook &      alfredo &          ministro \\\\\n",
      "         enfermera &      decidir &          nacional \\\\\n",
      "          animales &     femenino &           defensa \\\\\n",
      "            animal &      campeón &               pnv \\\\\n",
      "           móviles &         liga &  tribunal supremo \\\\\n",
      "             dosis &   inglaterra &            fusión \\\\\n",
      "            mental &    azulgrana &             cajas \\\\\n",
      "           ensayos &        nadal &          canarias \\\\\n",
      "              casa &      equipos &           partido \\\\\n",
      "         patógenos &     millones &             pleno \\\\\n",
      "      personalidad &   campeonato &          sociales \\\\\n",
      "          encierro &        goles &             texto \\\\\n",
      "         teléfonos &         bola &        socialista \\\\\n",
      "          mascotas &  generalitat &           montero \\\\\n",
      "               vph &        grupo &         enmiendas \\\\\n",
      "           placebo &      leyenda &            callar \\\\\n",
      "            cuerpo &          coe &          congreso \\\\\n",
      "       alimentaria &      talento &            teresa \\\\\n",
      "          lesiones &         bolt &          carrillo \\\\\n",
      "       reino unido &    wilkinson &          ministra \\\\\n",
      "          factores &         putt &           estatal \\\\\n",
      "          estudios &    salamanca &           militar \\\\\n",
      "            sexual &         hoyo &     instalaciones \\\\\n",
      "             magra &          NaN &          exterior \\\\\n",
      "         microbios &          NaN &          libertad \\\\\n",
      "            vacuna &          NaN &               pnl \\\\\n",
      "            gestor &          NaN &          interior \\\\\n",
      "         bacterias &          NaN &         migrantes \\\\\n",
      " teléfonos móviles &          NaN &               NaN \\\\\n",
      "          compañía &          NaN &               NaN \\\\\n",
      "        masa magra &          NaN &               NaN \\\\\n",
      "       metabolismo &          NaN &               NaN \\\\\n",
      "           soledad &          NaN &               NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_table_keywords(relevant_keywords_health, relevant_keywords_sports, relevant_keywords_politics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de glosarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:33.929871Z",
     "start_time": "2020-12-15T21:13:33.926872Z"
    }
   },
   "outputs": [],
   "source": [
    "path_keys_health = \"../keywords/keys_health.txt\"\n",
    "path_keys_sports = \"../keywords/keys_sports.txt\"\n",
    "path_keys_politics = \"../keywords/keys_politics.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:33.945872Z",
     "start_time": "2020-12-15T21:13:33.930872Z"
    }
   },
   "outputs": [],
   "source": [
    "keys_health = [key.strip() for key in open(path_keys_health, encoding=\"utf-8\").readlines()]\n",
    "keys_sports = [key.strip() for key in open(path_keys_sports, encoding=\"utf-8\").readlines()]\n",
    "keys_politics = [key.strip() for key in open(path_keys_politics, encoding=\"utf-8\").readlines()]\n",
    "\n",
    "keys_dic = {-1: \"unknown\", 0: \"health\", 1: \"sports\", 2: \"politics\"}\n",
    "inverted_keys_dic = {\"unknown\": -1, \"health\": 0, \"sports\": 1, \"politics\": 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigramas de test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.494872Z",
     "start_time": "2020-12-15T21:13:33.946873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>preprocesado</th>\n",
       "      <th>tokens</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>tokens + bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>health_47.txt</td>\n",
       "      <td>La Organización Mundial de la Salud (OMS) ha a...</td>\n",
       "      <td>health</td>\n",
       "      <td>la organización mundial de la salud oms ha act...</td>\n",
       "      <td>[organización, mundial, salud, oms, actualizad...</td>\n",
       "      <td>[sino también, sino también, organización mund...</td>\n",
       "      <td>[organización, mundial, salud, oms, actualizad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>health_14.txt</td>\n",
       "      <td>Viven entre nosotros, puede ser ese hombre que...</td>\n",
       "      <td>health</td>\n",
       "      <td>viven entre nosotros puede ser ese hombre que ...</td>\n",
       "      <td>[viven, hombre, camina, prisa, lluvia, aquella...</td>\n",
       "      <td>[puede ser, debe tener, debe tener, sobre todo...</td>\n",
       "      <td>[viven, hombre, camina, prisa, lluvia, aquella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>health_2.txt</td>\n",
       "      <td>Las autoridades de Senegal han comenzado una i...</td>\n",
       "      <td>health</td>\n",
       "      <td>las autoridades de senegal han comenzado una i...</td>\n",
       "      <td>[autoridades, senegal, comenzado, investigació...</td>\n",
       "      <td>[una serie, se trata, sin embargo, se trata, u...</td>\n",
       "      <td>[autoridades, senegal, comenzado, investigació...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>health_31.txt</td>\n",
       "      <td>Tres de los proyectos de la vacuna contra el c...</td>\n",
       "      <td>health</td>\n",
       "      <td>tres de los proyectos de la vacuna contra el c...</td>\n",
       "      <td>[proyectos, vacuna, covid, investigan, españa,...</td>\n",
       "      <td>[no obstante, son suficientes, no obstante, no...</td>\n",
       "      <td>[proyectos, vacuna, covid, investigan, españa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>health_17.txt</td>\n",
       "      <td>En lo que se refiere a nuestro aparato cardioc...</td>\n",
       "      <td>health</td>\n",
       "      <td>en lo que se refiere a nuestro aparato cardioc...</td>\n",
       "      <td>[refiere, aparato, cardiocirculatorio, corazón...</td>\n",
       "      <td>[este contexto, sobre todo, se trata, las célu...</td>\n",
       "      <td>[refiere, aparato, cardiocirculatorio, corazón...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>102</td>\n",
       "      <td>sports_11.txt</td>\n",
       "      <td>Para muchos el nombre de Sonny Vaccaro apenas ...</td>\n",
       "      <td>sports</td>\n",
       "      <td>para muchos el nombre de sonny vaccaro apenas ...</td>\n",
       "      <td>[nombre, sonny, vaccaro, relevante, aficionado...</td>\n",
       "      <td>[por culpa, por culpa]</td>\n",
       "      <td>[nombre, sonny, vaccaro, relevante, aficionado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>116</td>\n",
       "      <td>sports_24.txt</td>\n",
       "      <td>Rafael Nadal se clasificó este jueves por sext...</td>\n",
       "      <td>sports</td>\n",
       "      <td>rafael nadal se clasificó este jueves por sext...</td>\n",
       "      <td>[rafael, nadal, clasificó, jueves, sexta, semi...</td>\n",
       "      <td>[ha demostrado, primera vez, sigue siendo, est...</td>\n",
       "      <td>[rafael, nadal, clasificó, jueves, sexta, semi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>124</td>\n",
       "      <td>sports_31.txt</td>\n",
       "      <td>La selección de Australia se rehizo ante Nueva...</td>\n",
       "      <td>sports</td>\n",
       "      <td>la selección de australia se rehizo ante nueva...</td>\n",
       "      <td>[selección, australia, rehizo, zelanda, termin...</td>\n",
       "      <td>[sin embargo, sin embargo, sin embargo, sin em...</td>\n",
       "      <td>[selección, australia, rehizo, zelanda, termin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>148</td>\n",
       "      <td>sports_8.txt</td>\n",
       "      <td>\\nChiellini, Bonucci, Barzagli, Zambrotta...la...</td>\n",
       "      <td>sports</td>\n",
       "      <td>\\nchiellini bonucci barzagli zambrottala lista...</td>\n",
       "      <td>[chiellini, bonucci, barzagli, zambrottala, li...</td>\n",
       "      <td>[primera vez, sin embargo, mayor parte, mayor ...</td>\n",
       "      <td>[chiellini, bonucci, barzagli, zambrottala, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>sports_13.txt</td>\n",
       "      <td>ARicky Rubio todavía le dura el descontento po...</td>\n",
       "      <td>sports</td>\n",
       "      <td>aricky rubio todavía le dura el descontento po...</td>\n",
       "      <td>[aricky, rubio, dura, descontento, forma, sali...</td>\n",
       "      <td>[una estrella, una estrella]</td>\n",
       "      <td>[aricky, rubio, dura, descontento, forma, sali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       doc_name                                               text  \\\n",
       "0       41  health_47.txt  La Organización Mundial de la Salud (OMS) ha a...   \n",
       "1        5  health_14.txt  Viven entre nosotros, puede ser ese hombre que...   \n",
       "2       11   health_2.txt  Las autoridades de Senegal han comenzado una i...   \n",
       "3       24  health_31.txt  Tres de los proyectos de la vacuna contra el c...   \n",
       "4        8  health_17.txt  En lo que se refiere a nuestro aparato cardioc...   \n",
       "..     ...            ...                                                ...   \n",
       "100    102  sports_11.txt  Para muchos el nombre de Sonny Vaccaro apenas ...   \n",
       "101    116  sports_24.txt  Rafael Nadal se clasificó este jueves por sext...   \n",
       "102    124  sports_31.txt  La selección de Australia se rehizo ante Nueva...   \n",
       "103    148   sports_8.txt  \\nChiellini, Bonucci, Barzagli, Zambrotta...la...   \n",
       "104    104  sports_13.txt  ARicky Rubio todavía le dura el descontento po...   \n",
       "\n",
       "      class                                       preprocesado  \\\n",
       "0    health  la organización mundial de la salud oms ha act...   \n",
       "1    health  viven entre nosotros puede ser ese hombre que ...   \n",
       "2    health  las autoridades de senegal han comenzado una i...   \n",
       "3    health  tres de los proyectos de la vacuna contra el c...   \n",
       "4    health  en lo que se refiere a nuestro aparato cardioc...   \n",
       "..      ...                                                ...   \n",
       "100  sports  para muchos el nombre de sonny vaccaro apenas ...   \n",
       "101  sports  rafael nadal se clasificó este jueves por sext...   \n",
       "102  sports  la selección de australia se rehizo ante nueva...   \n",
       "103  sports  \\nchiellini bonucci barzagli zambrottala lista...   \n",
       "104  sports  aricky rubio todavía le dura el descontento po...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [organización, mundial, salud, oms, actualizad...   \n",
       "1    [viven, hombre, camina, prisa, lluvia, aquella...   \n",
       "2    [autoridades, senegal, comenzado, investigació...   \n",
       "3    [proyectos, vacuna, covid, investigan, españa,...   \n",
       "4    [refiere, aparato, cardiocirculatorio, corazón...   \n",
       "..                                                 ...   \n",
       "100  [nombre, sonny, vaccaro, relevante, aficionado...   \n",
       "101  [rafael, nadal, clasificó, jueves, sexta, semi...   \n",
       "102  [selección, australia, rehizo, zelanda, termin...   \n",
       "103  [chiellini, bonucci, barzagli, zambrottala, li...   \n",
       "104  [aricky, rubio, dura, descontento, forma, sali...   \n",
       "\n",
       "                                               bigrams  \\\n",
       "0    [sino también, sino también, organización mund...   \n",
       "1    [puede ser, debe tener, debe tener, sobre todo...   \n",
       "2    [una serie, se trata, sin embargo, se trata, u...   \n",
       "3    [no obstante, son suficientes, no obstante, no...   \n",
       "4    [este contexto, sobre todo, se trata, las célu...   \n",
       "..                                                 ...   \n",
       "100                             [por culpa, por culpa]   \n",
       "101  [ha demostrado, primera vez, sigue siendo, est...   \n",
       "102  [sin embargo, sin embargo, sin embargo, sin em...   \n",
       "103  [primera vez, sin embargo, mayor parte, mayor ...   \n",
       "104                       [una estrella, una estrella]   \n",
       "\n",
       "                                      tokens + bigrams  \n",
       "0    [organización, mundial, salud, oms, actualizad...  \n",
       "1    [viven, hombre, camina, prisa, lluvia, aquella...  \n",
       "2    [autoridades, senegal, comenzado, investigació...  \n",
       "3    [proyectos, vacuna, covid, investigan, españa,...  \n",
       "4    [refiere, aparato, cardiocirculatorio, corazón...  \n",
       "..                                                 ...  \n",
       "100  [nombre, sonny, vaccaro, relevante, aficionado...  \n",
       "101  [rafael, nadal, clasificó, jueves, sexta, semi...  \n",
       "102  [selección, australia, rehizo, zelanda, termin...  \n",
       "103  [chiellini, bonucci, barzagli, zambrottala, li...  \n",
       "104  [aricky, rubio, dura, descontento, forma, sali...  \n",
       "\n",
       "[105 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"bigrams\"] = test_data[\"preprocesado\"].apply(lambda x: check_bigram(x, bigrams))\n",
    "test_data[\"tokens + bigrams\"] = test_data[\"tokens\"] + test_data[\"bigrams\"]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.497872Z",
     "start_time": "2020-12-15T21:13:34.495872Z"
    }
   },
   "outputs": [],
   "source": [
    "glossaries = [keys_health, keys_sports, keys_politics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.503872Z",
     "start_time": "2020-12-15T21:13:34.498872Z"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(glossary for glossary in glossaries)\n",
    "dictionary.save('keys.dict')  # store the dictionary, for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.506873Z",
     "start_time": "2020-12-15T21:13:34.504873Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    \n",
    "    def __init__(self, docs, dictionary):\n",
    "        self.docs = docs\n",
    "        self.dict = dictionary\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for doc in self.docs:\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield self.dict.doc2bow(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.511872Z",
     "start_time": "2020-12-15T21:13:34.507873Z"
    }
   },
   "outputs": [],
   "source": [
    "bow = MyCorpus(glossaries, dictionary)\n",
    "corpora.MmCorpus.serialize(\"keys.mm\", bow, metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.517873Z",
     "start_time": "2020-12-15T21:13:34.512872Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "index_temp = get_tmpfile(\"index\")\n",
    "index = Similarity(index_temp, bow, num_features=len(dictionary))  # create index\n",
    "index.save(\"keys.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.522872Z",
     "start_time": "2020-12-15T21:13:34.518873Z"
    }
   },
   "outputs": [],
   "source": [
    "model_tfidf = models.TfidfModel(bow,smartirs=\"lpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.527874Z",
     "start_time": "2020-12-15T21:13:34.523872Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_document_tfidf(model, dictionary, bow, index, documents, i, verbose = False):\n",
    "    \"\"\"\n",
    "    Given a specific document, computes the ranking of the classes and returns the current class, \n",
    "    the predicted class and the probabilities for each class.\n",
    "    \n",
    "    \"\"\"\n",
    "    document = documents.iloc[i]\n",
    "    pq = document[\"tokens + bigrams\"]\n",
    "    vq = dictionary.doc2bow(pq)\n",
    "    qtfidf = model[vq]\n",
    "    sim = index[qtfidf]\n",
    "\n",
    "    ranking = sorted(enumerate(sim), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Document ==> \" + document[\"text\"][:100])\n",
    "        for doc, score in ranking:\n",
    "            cat = keys_dic[doc]\n",
    "            print(f\"[{cat}] ==> %.3f\" % round(score,3))\n",
    "            \n",
    "    \n",
    "    return [i, get_info_document(document, ranking, sim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.531874Z",
     "start_time": "2020-12-15T21:13:34.528872Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_info_document(document, ranking, sim):\n",
    "    \"\"\"\n",
    "    Given a ranking of classes, returns the current class, the predicted class and the probabilities for each class.\n",
    "    \n",
    "    \"\"\"\n",
    "    current_class = inverted_keys_dic[document[\"class\"]]\n",
    "    \n",
    "    if np.sum(sim) == 0.0:\n",
    "        predicted_class = -1\n",
    "        probabilities = np.array([1/3, 1/3, 1/3])\n",
    "    else:\n",
    "        predicted_class = ranking[0][0]\n",
    "        tfidf_scores = np.array(sim)\n",
    "        probabilities = tfidf_scores / np.sum(tfidf_scores)\n",
    "    \n",
    "    return {\"current_class\": current_class, \"predicted_class\": predicted_class, \n",
    "            \"probabilities\": probabilities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.538873Z",
     "start_time": "2020-12-15T21:13:34.532874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ==> En lo que se refiere a nuestro aparato cardiocirculatorio (corazón, venas y arterias), es importante\n",
      "[health] ==> 0.438\n",
      "[sports] ==> 0.000\n",
      "[politics] ==> 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " {'current_class': 0,\n",
       "  'predicted_class': 0,\n",
       "  'probabilities': array([1., 0., 0.], dtype=float32)}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_document_tfidf(model_tfidf, dictionary, bow, index, test_data, 4, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.541873Z",
     "start_time": "2020-12-15T21:13:34.539873Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_tfidf(function, model, dictionary, bow, index, data):\n",
    "    def classify(doc_i):\n",
    "        return function(model, dictionary, bow, index, data, doc_i)\n",
    "    return classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.581874Z",
     "start_time": "2020-12-15T21:13:34.542873Z"
    }
   },
   "outputs": [],
   "source": [
    "glossaries = [keys_health, keys_sports, keys_politics]\n",
    "model_w2v = models.Word2Vec(sentences = glossaries, window = 5, workers = 12, min_count = 1, seed=50)\n",
    "\n",
    "model_w2v.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.585874Z",
     "start_time": "2020-12-15T21:13:34.582874Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_max_min(model):\n",
    "    vocab = model.wv.vocab\n",
    "    \n",
    "    maxs = []\n",
    "    mins = []\n",
    "    \n",
    "    for key in vocab:\n",
    "        maxs.append(max(model.wv[key]))\n",
    "        mins.append(min(model.wv[key]))\n",
    "    return max(maxs), min(mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.590874Z",
     "start_time": "2020-12-15T21:13:34.586874Z"
    }
   },
   "outputs": [],
   "source": [
    "MAXI, MINI = get_max_min(model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.597875Z",
     "start_time": "2020-12-15T21:13:34.591875Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_embeddings_from_document(model, document):\n",
    "    embeddings = []\n",
    "    \n",
    "    for word in document:\n",
    "        if word in model.wv:\n",
    "            embeddings.append(model.wv[word])\n",
    "        else: # no está en el vocab\n",
    "            embeddings.append(np.random.uniform(low = MINI, high = MAXI, size = 100))\n",
    "    \n",
    "    return np.mean(embeddings, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.600875Z",
     "start_time": "2020-12-15T21:13:34.598874Z"
    }
   },
   "outputs": [],
   "source": [
    "glossaries_vector = [get_embeddings_from_document(model_w2v, glossary) for glossary in glossaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.605874Z",
     "start_time": "2020-12-15T21:13:34.601873Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_info_document_w2v(document, ranking, sim):\n",
    "    \"\"\"\n",
    "    Given a ranking of classes, returns the current class, the predicted class and the probabilities for each class.\n",
    "    \n",
    "    \"\"\"\n",
    "    current_class = inverted_keys_dic[document[\"class\"]]\n",
    "    \n",
    "    if np.count_nonzero(sim) == 0:\n",
    "        predicted_class = -1\n",
    "        probabilities = np.array([1/3, 1/3, 1/3])\n",
    "    else:\n",
    "        predicted_class = ranking[0][0]\n",
    "        w2v_scores = np.array(sim, dtype = \"float32\")\n",
    "        probabilities = (w2v_scores - w2v_scores.min()) / (w2v_scores.max() - w2v_scores.min()) \n",
    "        probabilities /= np.sum(probabilities)\n",
    "\n",
    "        \n",
    "    return {\"current_class\": current_class, \"predicted_class\": predicted_class, \n",
    "            \"probabilities\": probabilities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.611873Z",
     "start_time": "2020-12-15T21:13:34.606873Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_doc_w2v(glossaries_vector, model, documents, i, verbose = False):\n",
    "    document = documents.iloc[i]\n",
    "    doc_vector = get_embeddings_from_document(model, document[\"tokens + bigrams\"])\n",
    "\n",
    "    ranking = [[i, cosine_similarity(np.array(doc_vector).reshape(1,-1), np.array(glossary).reshape(1,-1)).item()] \n",
    "               for i, glossary in enumerate(glossaries_vector)]\n",
    "    \n",
    "    sim = [rank[1] for rank in ranking] \n",
    "    \n",
    "    ranking.sort(key = lambda x: x[1], reverse = True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Document ==> \" + document[\"text\"][:100])\n",
    "        print(\"Scores:\")\n",
    "        for doc, score in ranking:\n",
    "            cat = keys_dic[doc]\n",
    "            print(f\"[{cat}] ==> %.3f\" % round(score,3))\n",
    "    \n",
    "    return [i, get_info_document_w2v(document, ranking, sim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.620874Z",
     "start_time": "2020-12-15T21:13:34.612873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ==> En lo que se refiere a nuestro aparato cardiocirculatorio (corazón, venas y arterias), es importante\n",
      "Scores:\n",
      "[health] ==> 0.212\n",
      "[politics] ==> 0.144\n",
      "[sports] ==> -0.012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " {'current_class': 0,\n",
       "  'predicted_class': 0,\n",
       "  'probabilities': array([0.5890365 , 0.        , 0.41096348], dtype=float32)}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_doc_w2v(glossaries_vector, model_w2v, test_data, 4, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.624873Z",
     "start_time": "2020-12-15T21:13:34.621874Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_w2v(function, glossaries_vector, model, data):\n",
    "    def classify(doc_i):\n",
    "        return function(glossaries_vector, model, data, doc_i)\n",
    "    return classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.630874Z",
     "start_time": "2020-12-15T21:13:34.625873Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_doc_bayes(classifier, documents, i, verbose = False):\n",
    "    doc = documents.iloc[i]\n",
    "    #doc = vectorizer.transform([document[\"preprocesado\"]])\n",
    "    \n",
    "    y_pred = classifier.predict_proba([doc[\"preprocesado\"]])[0]\n",
    "    \n",
    "    ranking = [[i,prob] for i,prob in enumerate(y_pred)]\n",
    "    \n",
    "    probabilities = y_pred\n",
    "    \n",
    "    ranking.sort(key = lambda x: x[1], reverse = True)\n",
    "    \n",
    "    current_class = inverted_keys_dic[doc[\"class\"]]\n",
    "    \n",
    "    if np.count_nonzero(y_pred == 1/3) > 1 or np.count_nonzero(y_pred == 1/2) > 1:\n",
    "        predicted_class = -1\n",
    "    else:\n",
    "        predicted_class = ranking[0][0]\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Document ==> \" + doc[\"text\"][:100])\n",
    "        print(\"Scores:\")\n",
    "        for doc, score in ranking:\n",
    "            cat = keys_dic[doc]\n",
    "            print(f\"[{cat}] ==> %.3f\" % round(score,3))\n",
    "    \n",
    "    return [i, {\"current_class\": current_class, \"predicted_class\": predicted_class, \n",
    "            \"probabilities\": probabilities}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.634873Z",
     "start_time": "2020-12-15T21:13:34.631873Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_bayes(function, clf, documents):\n",
    "    def classify(doc_i):\n",
    "        return function(clf, documents, doc_i)\n",
    "    return classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.645874Z",
     "start_time": "2020-12-15T21:13:34.635873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glossaries_joined = [\" \".join(gloss) for gloss in glossaries]\n",
    "\n",
    "X_train = glossaries_joined\n",
    "y_train = [0,1,2]\n",
    "\n",
    "clf = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "                     ('clf', MultinomialNB(alpha=1e-1))])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.653872Z",
     "start_time": "2020-12-15T21:13:34.646873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ==> Eso fue lo que afirmaron los expertos de la Escuela de Medicina de Harvard en su informe 'Core exerc\n",
      "Scores:\n",
      "[health] ==> 0.569\n",
      "[politics] ==> 0.281\n",
      "[sports] ==> 0.150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " {'current_class': 0,\n",
       "  'predicted_class': 0,\n",
       "  'probabilities': array([0.56923051, 0.14994128, 0.2808282 ])}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_doc_bayes(clf, test_data, 6, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.657875Z",
     "start_time": "2020-12-15T21:13:34.654874Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_documents(test_data, classify):\n",
    "    \"\"\"\n",
    "    Classifies the documents given a specific classification function.\n",
    "    \n",
    "    \"\"\"\n",
    "    test_data = test_data.copy()\n",
    "    \n",
    "    infos = [classify(i) for i in range(len(test_data))]\n",
    "    data = fill_test_data(test_data, infos)\n",
    "        \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.669873Z",
     "start_time": "2020-12-15T21:13:34.658873Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_test_data(test_data, infos):\n",
    "    \"\"\"\n",
    "    Auxiliary function to fill the dataframe with info about the classification.\n",
    "    \n",
    "    \"\"\"\n",
    "    data = test_data.copy()\n",
    "    current_class = pd.Series([info[1][\"current_class\"] for info in infos])\n",
    "    predicted_class = pd.Series([info[1][\"predicted_class\"] for info in infos])\n",
    "    p_health = pd.Series([info[1][\"probabilities\"][0] for info in infos])\n",
    "    p_sports = pd.Series([info[1][\"probabilities\"][1] for info in infos])\n",
    "    p_politics = pd.Series([info[1][\"probabilities\"][2] for info in infos])\n",
    "\n",
    "    data[\"current_class\"] = current_class\n",
    "    data[\"predicted_class\"] = predicted_class\n",
    "    data[\"p_health\"] = p_health\n",
    "    data[\"p_sports\"] = p_sports\n",
    "    data[\"p_politics\"] = p_politics\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.673873Z",
     "start_time": "2020-12-15T21:13:34.670873Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_filename(df):\n",
    "    \"\"\"\n",
    "    Computes the filename for each document based on the performed classification.\n",
    "    \n",
    "    \"\"\"\n",
    "    confidence = \"%.3f\" % df[\"confidence\"]\n",
    "    current_class = df[\"class\"]\n",
    "    predicted_class = df[\"predicted_class_name\"]\n",
    "    correct = current_class == predicted_class\n",
    "    name = df[\"doc_name\"].split(\".\")[0]\n",
    "    \n",
    "    return f\"../classification/{predicted_class}/{confidence}_{name}-{correct}-{current_class}-{predicted_class}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.676873Z",
     "start_time": "2020-12-15T21:13:34.674872Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_file(path, content):\n",
    "    \"\"\"\n",
    "    Writes a file given its path and content.\n",
    "    \n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding = \"utf-8\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.686873Z",
     "start_time": "2020-12-15T21:13:34.677873Z"
    }
   },
   "outputs": [],
   "source": [
    "def move_files(data, tables=True):\n",
    "    \"\"\"\n",
    "    Moves the files to their corresponding new directory after classification is done.\n",
    "\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    classes = [[0, \"p_health\"], [1, \"p_sports\"], [2, \"p_politics\"]]\n",
    "\n",
    "    for cl in classes:\n",
    "        docs = data[data[\"current_class\"] == cl[0]]\n",
    "        docs = docs.sort_values(by=[cl[1]], ascending=False)\n",
    "        docs[\"predicted_class_name\"] = docs[\"predicted_class\"].apply(\n",
    "            lambda x: keys_dic[x])\n",
    "        docs[\"confidence\"] = docs[[\"p_health\",\n",
    "                                   \"p_sports\", \"p_politics\"]].max(axis=1)\n",
    "        docs[\"file\"] = docs.apply(lambda x: get_filename(x), axis=1)\n",
    "        docs.apply(lambda row: write_file(row[\"file\"], row[\"text\"]), axis=1)\n",
    "        if tables:\n",
    "            # tabla para la memoria\n",
    "            docs = docs[[\"doc_name\", \"class\", \"p_health\",\n",
    "                         \"p_sports\", \"p_politics\", \"predicted_class_name\"]]\n",
    "            docs = docs.rename(\n",
    "                columns={\"predicted_class_name\": \"predicted_class\"})\n",
    "            print(docs.to_latex(bold_rows=True, float_format=\"%.2f\",\n",
    "                                column_format=\"llllll\", index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:34.691873Z",
     "start_time": "2020-12-15T21:13:34.687873Z"
    }
   },
   "outputs": [],
   "source": [
    "def execute(test_data, classification_function, move = True, tables = False):\n",
    "    \"\"\"\n",
    "    General function that classifies the documents.\n",
    "    \n",
    "    \"\"\"\n",
    "    data = test_data.copy()\n",
    "    print(\"############################################################\")\n",
    "    print(\"Starting document´s classification...\")\n",
    "    data = classify_documents(data, classification_function)\n",
    "    sleep(1)\n",
    "    print(\"Document´s classification done...\")\n",
    "    if move:\n",
    "        print(\"-----------------------------------------------------------\")\n",
    "        sleep(1)\n",
    "        print(\"Moving files to the correct directories...\")\n",
    "        move_files(data)\n",
    "        sleep(1)\n",
    "        print(\"Files moved.\")\n",
    "    print(\"############################################################\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:44.311443Z",
     "start_time": "2020-12-15T21:13:34.692873Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "Starting document´s classification...\n",
      "Document´s classification done...\n",
      "-----------------------------------------------------------\n",
      "Moving files to the correct directories...\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " health\\_16.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      " health\\_43.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      "  health\\_2.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      "  health\\_3.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      " health\\_17.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      " health\\_48.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      "  health\\_1.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      "  health\\_7.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      " health\\_28.txt &  health &      0.94 &      0.06 &        0.00 &          health \\\\\n",
      " health\\_14.txt &  health &      0.94 &      0.06 &        0.00 &          health \\\\\n",
      " health\\_13.txt &  health &      0.93 &      0.00 &        0.07 &          health \\\\\n",
      " health\\_24.txt &  health &      0.90 &      0.07 &        0.03 &          health \\\\\n",
      " health\\_47.txt &  health &      0.88 &      0.12 &        0.00 &          health \\\\\n",
      " health\\_49.txt &  health &      0.88 &      0.00 &        0.12 &          health \\\\\n",
      "  health\\_6.txt &  health &      0.88 &      0.12 &        0.00 &          health \\\\\n",
      " health\\_35.txt &  health &      0.87 &      0.13 &        0.00 &          health \\\\\n",
      " health\\_45.txt &  health &      0.85 &      0.15 &        0.00 &          health \\\\\n",
      " health\\_23.txt &  health &      0.85 &      0.15 &        0.00 &          health \\\\\n",
      " health\\_34.txt &  health &      0.84 &      0.16 &        0.00 &          health \\\\\n",
      " health\\_46.txt &  health &      0.82 &      0.00 &        0.18 &          health \\\\\n",
      " health\\_25.txt &  health &      0.78 &      0.11 &        0.11 &          health \\\\\n",
      " health\\_10.txt &  health &      0.78 &      0.13 &        0.09 &          health \\\\\n",
      " health\\_39.txt &  health &      0.77 &      0.23 &        0.00 &          health \\\\\n",
      "  health\\_9.txt &  health &      0.72 &      0.28 &        0.00 &          health \\\\\n",
      " health\\_42.txt &  health &      0.70 &      0.30 &        0.00 &          health \\\\\n",
      " health\\_31.txt &  health &      0.69 &      0.10 &        0.21 &          health \\\\\n",
      " health\\_26.txt &  health &      0.67 &      0.00 &        0.33 &          health \\\\\n",
      " health\\_44.txt &  health &      0.67 &      0.33 &        0.00 &          health \\\\\n",
      " health\\_29.txt &  health &      0.57 &      0.25 &        0.18 &          health \\\\\n",
      " health\\_40.txt &  health &      0.50 &      0.00 &        0.50 &          health \\\\\n",
      " health\\_27.txt &  health &      0.47 &      0.53 &        0.00 &          sports \\\\\n",
      "  health\\_4.txt &  health &      0.25 &      0.50 &        0.25 &          sports \\\\\n",
      " health\\_38.txt &  health &      0.22 &      0.56 &        0.22 &          sports \\\\\n",
      " health\\_37.txt &  health &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " health\\_33.txt &  health &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      "  sports\\_1.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "  sports\\_7.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_14.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "  sports\\_5.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_28.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_34.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_41.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_26.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_11.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_24.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "  sports\\_6.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_49.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      "  sports\\_8.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_15.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_19.txt &  sports &      0.00 &      1.00 &        0.00 &          sports \\\\\n",
      " sports\\_12.txt &  sports &      0.04 &      0.96 &        0.00 &          sports \\\\\n",
      " sports\\_16.txt &  sports &      0.04 &      0.96 &        0.00 &          sports \\\\\n",
      " sports\\_22.txt &  sports &      0.07 &      0.93 &        0.00 &          sports \\\\\n",
      " sports\\_13.txt &  sports &      0.00 &      0.92 &        0.08 &          sports \\\\\n",
      "  sports\\_9.txt &  sports &      0.08 &      0.92 &        0.00 &          sports \\\\\n",
      " sports\\_42.txt &  sports &      0.04 &      0.88 &        0.08 &          sports \\\\\n",
      " sports\\_44.txt &  sports &      0.17 &      0.83 &        0.00 &          sports \\\\\n",
      " sports\\_10.txt &  sports &      0.06 &      0.81 &        0.13 &          sports \\\\\n",
      "  sports\\_4.txt &  sports &      0.20 &      0.80 &        0.00 &          sports \\\\\n",
      " sports\\_29.txt &  sports &      0.20 &      0.80 &        0.00 &          sports \\\\\n",
      " sports\\_45.txt &  sports &      0.25 &      0.75 &        0.00 &          sports \\\\\n",
      " sports\\_50.txt &  sports &      0.36 &      0.64 &        0.00 &          sports \\\\\n",
      " sports\\_17.txt &  sports &      0.31 &      0.56 &        0.13 &          sports \\\\\n",
      " sports\\_36.txt &  sports &      0.50 &      0.50 &        0.00 &          health \\\\\n",
      " sports\\_48.txt &  sports &      0.53 &      0.47 &        0.00 &          health \\\\\n",
      " sports\\_31.txt &  sports &      0.53 &      0.47 &        0.00 &          health \\\\\n",
      " sports\\_39.txt &  sports &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " sports\\_27.txt &  sports &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " sports\\_32.txt &  sports &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " sports\\_25.txt &  sports &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "        doc\\_name &     class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      "  politics\\_8.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      "  politics\\_7.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      " politics\\_30.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      " politics\\_43.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      " politics\\_46.txt &  politics &      0.00 &      0.00 &        1.00 &        politics \\\\\n",
      " politics\\_19.txt &  politics &      0.03 &      0.00 &        0.97 &        politics \\\\\n",
      " politics\\_27.txt &  politics &      0.05 &      0.00 &        0.95 &        politics \\\\\n",
      " politics\\_15.txt &  politics &      0.00 &      0.09 &        0.91 &        politics \\\\\n",
      " politics\\_18.txt &  politics &      0.09 &      0.00 &        0.91 &        politics \\\\\n",
      "  politics\\_4.txt &  politics &      0.00 &      0.10 &        0.90 &        politics \\\\\n",
      " politics\\_28.txt &  politics &      0.00 &      0.11 &        0.89 &        politics \\\\\n",
      " politics\\_32.txt &  politics &      0.13 &      0.00 &        0.87 &        politics \\\\\n",
      " politics\\_14.txt &  politics &      0.14 &      0.00 &        0.86 &        politics \\\\\n",
      " politics\\_10.txt &  politics &      0.15 &      0.00 &        0.85 &        politics \\\\\n",
      " politics\\_26.txt &  politics &      0.08 &      0.08 &        0.84 &        politics \\\\\n",
      " politics\\_33.txt &  politics &      0.03 &      0.22 &        0.75 &        politics \\\\\n",
      " politics\\_34.txt &  politics &      0.17 &      0.14 &        0.69 &        politics \\\\\n",
      " politics\\_17.txt &  politics &      0.24 &      0.08 &        0.68 &        politics \\\\\n",
      " politics\\_47.txt &  politics &      0.17 &      0.17 &        0.67 &        politics \\\\\n",
      " politics\\_25.txt &  politics &      0.17 &      0.17 &        0.67 &        politics \\\\\n",
      " politics\\_37.txt &  politics &      0.00 &      0.35 &        0.65 &        politics \\\\\n",
      "  politics\\_9.txt &  politics &      0.27 &      0.09 &        0.64 &        politics \\\\\n",
      " politics\\_40.txt &  politics &      0.06 &      0.30 &        0.64 &        politics \\\\\n",
      " politics\\_42.txt &  politics &      0.00 &      0.43 &        0.57 &        politics \\\\\n",
      " politics\\_11.txt &  politics &      0.44 &      0.00 &        0.56 &        politics \\\\\n",
      " politics\\_38.txt &  politics &      0.29 &      0.21 &        0.51 &        politics \\\\\n",
      " politics\\_44.txt &  politics &      0.36 &      0.17 &        0.48 &        politics \\\\\n",
      " politics\\_50.txt &  politics &      0.53 &      0.00 &        0.47 &          health \\\\\n",
      "  politics\\_1.txt &  politics &      0.54 &      0.00 &        0.46 &          health \\\\\n",
      "  politics\\_3.txt &  politics &      0.56 &      0.00 &        0.44 &          health \\\\\n",
      "  politics\\_2.txt &  politics &      0.51 &      0.07 &        0.42 &          health \\\\\n",
      " politics\\_49.txt &  politics &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " politics\\_31.txt &  politics &      0.71 &      0.00 &        0.29 &          health \\\\\n",
      "  politics\\_6.txt &  politics &      0.70 &      0.05 &        0.25 &          health \\\\\n",
      " politics\\_21.txt &  politics &      0.81 &      0.00 &        0.19 &          health \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved.\n",
      "############################################################\n",
      "############################################################\n",
      "Starting document´s classification...\n",
      "Document´s classification done...\n",
      "-----------------------------------------------------------\n",
      "Moving files to the correct directories...\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " health\\_40.txt &  health &      1.00 &      0.00 &        0.00 &          health \\\\\n",
      " health\\_25.txt &  health &      0.94 &      0.00 &        0.06 &          health \\\\\n",
      " health\\_10.txt &  health &      0.94 &      0.06 &        0.00 &          health \\\\\n",
      " health\\_34.txt &  health &      0.93 &      0.00 &        0.07 &          health \\\\\n",
      " health\\_39.txt &  health &      0.92 &      0.08 &        0.00 &          health \\\\\n",
      "  health\\_4.txt &  health &      0.89 &      0.11 &        0.00 &          health \\\\\n",
      "  health\\_2.txt &  health &      0.88 &      0.12 &        0.00 &          health \\\\\n",
      " health\\_28.txt &  health &      0.87 &      0.00 &        0.13 &          health \\\\\n",
      " health\\_17.txt &  health &      0.85 &      0.00 &        0.15 &          health \\\\\n",
      " health\\_49.txt &  health &      0.84 &      0.00 &        0.16 &          health \\\\\n",
      "  health\\_3.txt &  health &      0.83 &      0.00 &        0.17 &          health \\\\\n",
      "  health\\_1.txt &  health &      0.81 &      0.00 &        0.19 &          health \\\\\n",
      " health\\_13.txt &  health &      0.80 &      0.20 &        0.00 &          health \\\\\n",
      "  health\\_9.txt &  health &      0.74 &      0.00 &        0.26 &          health \\\\\n",
      " health\\_16.txt &  health &      0.73 &      0.00 &        0.27 &          health \\\\\n",
      " health\\_47.txt &  health &      0.70 &      0.30 &        0.00 &          health \\\\\n",
      " health\\_24.txt &  health &      0.68 &      0.00 &        0.32 &          health \\\\\n",
      " health\\_14.txt &  health &      0.68 &      0.00 &        0.32 &          health \\\\\n",
      " health\\_27.txt &  health &      0.64 &      0.36 &        0.00 &          health \\\\\n",
      " health\\_43.txt &  health &      0.62 &      0.00 &        0.38 &          health \\\\\n",
      " health\\_33.txt &  health &      0.62 &      0.00 &        0.38 &          health \\\\\n",
      " health\\_45.txt &  health &      0.61 &      0.39 &        0.00 &          health \\\\\n",
      " health\\_35.txt &  health &      0.60 &      0.40 &        0.00 &          health \\\\\n",
      " health\\_23.txt &  health &      0.59 &      0.00 &        0.41 &          health \\\\\n",
      "  health\\_6.txt &  health &      0.58 &      0.42 &        0.00 &          health \\\\\n",
      " health\\_48.txt &  health &      0.58 &      0.42 &        0.00 &          health \\\\\n",
      " health\\_42.txt &  health &      0.57 &      0.00 &        0.43 &          health \\\\\n",
      " health\\_31.txt &  health &      0.54 &      0.00 &        0.46 &          health \\\\\n",
      " health\\_44.txt &  health &      0.53 &      0.00 &        0.47 &          health \\\\\n",
      " health\\_29.txt &  health &      0.50 &      0.00 &        0.50 &        politics \\\\\n",
      " health\\_26.txt &  health &      0.47 &      0.00 &        0.53 &        politics \\\\\n",
      " health\\_38.txt &  health &      0.14 &      0.00 &        0.86 &        politics \\\\\n",
      " health\\_46.txt &  health &      0.00 &      0.30 &        0.70 &        politics \\\\\n",
      " health\\_37.txt &  health &      0.00 &      0.48 &        0.52 &        politics \\\\\n",
      "  health\\_7.txt &  health &      0.00 &      0.20 &        0.80 &        politics \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " sports\\_42.txt &  sports &      0.00 &      0.93 &        0.07 &          sports \\\\\n",
      "  sports\\_7.txt &  sports &      0.00 &      0.93 &        0.07 &          sports \\\\\n",
      " sports\\_50.txt &  sports &      0.11 &      0.89 &        0.00 &          sports \\\\\n",
      " sports\\_44.txt &  sports &      0.15 &      0.85 &        0.00 &          sports \\\\\n",
      " sports\\_17.txt &  sports &      0.00 &      0.84 &        0.16 &          sports \\\\\n",
      " sports\\_16.txt &  sports &      0.16 &      0.84 &        0.00 &          sports \\\\\n",
      " sports\\_19.txt &  sports &      0.19 &      0.81 &        0.00 &          sports \\\\\n",
      " sports\\_12.txt &  sports &      0.19 &      0.81 &        0.00 &          sports \\\\\n",
      "  sports\\_8.txt &  sports &      0.20 &      0.80 &        0.00 &          sports \\\\\n",
      " sports\\_15.txt &  sports &      0.00 &      0.80 &        0.20 &          sports \\\\\n",
      " sports\\_28.txt &  sports &      0.20 &      0.80 &        0.00 &          sports \\\\\n",
      "  sports\\_6.txt &  sports &      0.24 &      0.76 &        0.00 &          sports \\\\\n",
      "  sports\\_1.txt &  sports &      0.25 &      0.75 &        0.00 &          sports \\\\\n",
      " sports\\_31.txt &  sports &      0.27 &      0.73 &        0.00 &          sports \\\\\n",
      " sports\\_49.txt &  sports &      0.28 &      0.72 &        0.00 &          sports \\\\\n",
      " sports\\_45.txt &  sports &      0.00 &      0.72 &        0.28 &          sports \\\\\n",
      " sports\\_22.txt &  sports &      0.00 &      0.70 &        0.30 &          sports \\\\\n",
      " sports\\_34.txt &  sports &      0.32 &      0.68 &        0.00 &          sports \\\\\n",
      " sports\\_41.txt &  sports &      0.00 &      0.68 &        0.32 &          sports \\\\\n",
      " sports\\_14.txt &  sports &      0.00 &      0.66 &        0.34 &          sports \\\\\n",
      " sports\\_48.txt &  sports &      0.37 &      0.63 &        0.00 &          sports \\\\\n",
      " sports\\_13.txt &  sports &      0.00 &      0.60 &        0.40 &          sports \\\\\n",
      " sports\\_11.txt &  sports &      0.42 &      0.58 &        0.00 &          sports \\\\\n",
      " sports\\_36.txt &  sports &      0.00 &      0.58 &        0.42 &          sports \\\\\n",
      " sports\\_10.txt &  sports &      0.00 &      0.57 &        0.43 &          sports \\\\\n",
      " sports\\_39.txt &  sports &      0.00 &      0.56 &        0.44 &          sports \\\\\n",
      "  sports\\_5.txt &  sports &      0.46 &      0.54 &        0.00 &          sports \\\\\n",
      "  sports\\_9.txt &  sports &      0.48 &      0.52 &        0.00 &          sports \\\\\n",
      " sports\\_29.txt &  sports &      0.58 &      0.42 &        0.00 &          health \\\\\n",
      " sports\\_27.txt &  sports &      0.00 &      0.40 &        0.60 &        politics \\\\\n",
      " sports\\_24.txt &  sports &      0.62 &      0.38 &        0.00 &          health \\\\\n",
      "  sports\\_4.txt &  sports &      0.77 &      0.23 &        0.00 &          health \\\\\n",
      " sports\\_25.txt &  sports &      0.51 &      0.00 &        0.49 &          health \\\\\n",
      " sports\\_26.txt &  sports &      0.56 &      0.00 &        0.44 &          health \\\\\n",
      " sports\\_32.txt &  sports &      0.54 &      0.00 &        0.46 &          health \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "        doc\\_name &     class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " politics\\_19.txt &  politics &      0.01 &      0.00 &        0.99 &        politics \\\\\n",
      " politics\\_18.txt &  politics &      0.00 &      0.05 &        0.95 &        politics \\\\\n",
      "  politics\\_2.txt &  politics &      0.00 &      0.10 &        0.90 &        politics \\\\\n",
      " politics\\_28.txt &  politics &      0.12 &      0.00 &        0.88 &        politics \\\\\n",
      "  politics\\_4.txt &  politics &      0.00 &      0.15 &        0.85 &        politics \\\\\n",
      " politics\\_32.txt &  politics &      0.18 &      0.00 &        0.82 &        politics \\\\\n",
      " politics\\_42.txt &  politics &      0.00 &      0.18 &        0.82 &        politics \\\\\n",
      " politics\\_11.txt &  politics &      0.00 &      0.21 &        0.79 &        politics \\\\\n",
      "  politics\\_8.txt &  politics &      0.00 &      0.25 &        0.75 &        politics \\\\\n",
      " politics\\_10.txt &  politics &      0.00 &      0.26 &        0.74 &        politics \\\\\n",
      " politics\\_17.txt &  politics &      0.00 &      0.26 &        0.74 &        politics \\\\\n",
      "  politics\\_9.txt &  politics &      0.27 &      0.00 &        0.73 &        politics \\\\\n",
      " politics\\_46.txt &  politics &      0.00 &      0.28 &        0.72 &        politics \\\\\n",
      " politics\\_27.txt &  politics &      0.31 &      0.00 &        0.69 &        politics \\\\\n",
      " politics\\_34.txt &  politics &      0.32 &      0.00 &        0.68 &        politics \\\\\n",
      " politics\\_33.txt &  politics &      0.32 &      0.00 &        0.68 &        politics \\\\\n",
      " politics\\_43.txt &  politics &      0.00 &      0.35 &        0.65 &        politics \\\\\n",
      " politics\\_14.txt &  politics &      0.00 &      0.38 &        0.62 &        politics \\\\\n",
      " politics\\_30.txt &  politics &      0.40 &      0.00 &        0.60 &        politics \\\\\n",
      " politics\\_38.txt &  politics &      0.42 &      0.00 &        0.58 &        politics \\\\\n",
      " politics\\_15.txt &  politics &      0.00 &      0.45 &        0.55 &        politics \\\\\n",
      " politics\\_26.txt &  politics &      0.47 &      0.00 &        0.53 &        politics \\\\\n",
      "  politics\\_3.txt &  politics &      0.50 &      0.00 &        0.50 &          health \\\\\n",
      "  politics\\_1.txt &  politics &      0.67 &      0.00 &        0.33 &          health \\\\\n",
      " politics\\_40.txt &  politics &      0.00 &      0.70 &        0.30 &          sports \\\\\n",
      " politics\\_47.txt &  politics &      0.71 &      0.00 &        0.29 &          health \\\\\n",
      "  politics\\_7.txt &  politics &      0.93 &      0.00 &        0.07 &          health \\\\\n",
      " politics\\_31.txt &  politics &      0.97 &      0.03 &        0.00 &          health \\\\\n",
      "  politics\\_6.txt &  politics &      0.30 &      0.70 &        0.00 &          sports \\\\\n",
      " politics\\_37.txt &  politics &      0.37 &      0.63 &        0.00 &          sports \\\\\n",
      " politics\\_44.txt &  politics &      0.26 &      0.74 &        0.00 &          sports \\\\\n",
      " politics\\_25.txt &  politics &      0.41 &      0.59 &        0.00 &          sports \\\\\n",
      " politics\\_21.txt &  politics &      0.77 &      0.23 &        0.00 &          health \\\\\n",
      " politics\\_50.txt &  politics &      0.93 &      0.07 &        0.00 &          health \\\\\n",
      " politics\\_49.txt &  politics &      0.88 &      0.12 &        0.00 &          health \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved.\n",
      "############################################################\n",
      "############################################################\n",
      "Starting document´s classification...\n",
      "Document´s classification done...\n",
      "-----------------------------------------------------------\n",
      "Moving files to the correct directories...\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " health\\_14.txt &  health &      0.81 &      0.10 &        0.09 &          health \\\\\n",
      " health\\_28.txt &  health &      0.79 &      0.11 &        0.10 &          health \\\\\n",
      " health\\_24.txt &  health &      0.77 &      0.11 &        0.12 &          health \\\\\n",
      "  health\\_2.txt &  health &      0.73 &      0.13 &        0.13 &          health \\\\\n",
      " health\\_17.txt &  health &      0.72 &      0.14 &        0.14 &          health \\\\\n",
      " health\\_45.txt &  health &      0.72 &      0.16 &        0.12 &          health \\\\\n",
      " health\\_10.txt &  health &      0.71 &      0.14 &        0.15 &          health \\\\\n",
      " health\\_23.txt &  health &      0.71 &      0.15 &        0.14 &          health \\\\\n",
      "  health\\_3.txt &  health &      0.71 &      0.15 &        0.15 &          health \\\\\n",
      " health\\_16.txt &  health &      0.71 &      0.14 &        0.16 &          health \\\\\n",
      "  health\\_7.txt &  health &      0.70 &      0.13 &        0.16 &          health \\\\\n",
      "  health\\_6.txt &  health &      0.70 &      0.17 &        0.13 &          health \\\\\n",
      " health\\_49.txt &  health &      0.70 &      0.12 &        0.19 &          health \\\\\n",
      " health\\_43.txt &  health &      0.70 &      0.15 &        0.16 &          health \\\\\n",
      "  health\\_1.txt &  health &      0.69 &      0.15 &        0.15 &          health \\\\\n",
      " health\\_35.txt &  health &      0.69 &      0.17 &        0.14 &          health \\\\\n",
      " health\\_13.txt &  health &      0.68 &      0.16 &        0.16 &          health \\\\\n",
      " health\\_34.txt &  health &      0.62 &      0.21 &        0.17 &          health \\\\\n",
      " health\\_46.txt &  health &      0.59 &      0.18 &        0.23 &          health \\\\\n",
      " health\\_31.txt &  health &      0.58 &      0.19 &        0.23 &          health \\\\\n",
      " health\\_47.txt &  health &      0.57 &      0.22 &        0.20 &          health \\\\\n",
      " health\\_25.txt &  health &      0.57 &      0.18 &        0.25 &          health \\\\\n",
      " health\\_48.txt &  health &      0.57 &      0.15 &        0.28 &          health \\\\\n",
      "  health\\_9.txt &  health &      0.54 &      0.27 &        0.19 &          health \\\\\n",
      " health\\_42.txt &  health &      0.54 &      0.25 &        0.21 &          health \\\\\n",
      " health\\_44.txt &  health &      0.50 &      0.29 &        0.21 &          health \\\\\n",
      " health\\_39.txt &  health &      0.49 &      0.26 &        0.25 &          health \\\\\n",
      " health\\_29.txt &  health &      0.44 &      0.27 &        0.29 &          health \\\\\n",
      " health\\_27.txt &  health &      0.37 &      0.46 &        0.17 &          sports \\\\\n",
      " health\\_26.txt &  health &      0.31 &      0.20 &        0.49 &        politics \\\\\n",
      " health\\_40.txt &  health &      0.28 &      0.20 &        0.52 &        politics \\\\\n",
      " health\\_38.txt &  health &      0.27 &      0.46 &        0.27 &          sports \\\\\n",
      "  health\\_4.txt &  health &      0.24 &      0.33 &        0.42 &        politics \\\\\n",
      " health\\_33.txt &  health &      0.23 &      0.54 &        0.23 &          sports \\\\\n",
      " health\\_37.txt &  health &      0.16 &      0.68 &        0.16 &          sports \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "      doc\\_name &   class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " sports\\_15.txt &  sports &      0.08 &      0.84 &        0.08 &          sports \\\\\n",
      " sports\\_12.txt &  sports &      0.09 &      0.83 &        0.08 &          sports \\\\\n",
      " sports\\_14.txt &  sports &      0.09 &      0.82 &        0.09 &          sports \\\\\n",
      "  sports\\_1.txt &  sports &      0.10 &      0.81 &        0.10 &          sports \\\\\n",
      " sports\\_16.txt &  sports &      0.10 &      0.79 &        0.11 &          sports \\\\\n",
      "  sports\\_9.txt &  sports &      0.12 &      0.78 &        0.10 &          sports \\\\\n",
      "  sports\\_6.txt &  sports &      0.12 &      0.77 &        0.11 &          sports \\\\\n",
      " sports\\_41.txt &  sports &      0.13 &      0.75 &        0.13 &          sports \\\\\n",
      "  sports\\_8.txt &  sports &      0.13 &      0.75 &        0.13 &          sports \\\\\n",
      " sports\\_24.txt &  sports &      0.13 &      0.75 &        0.13 &          sports \\\\\n",
      " sports\\_34.txt &  sports &      0.12 &      0.74 &        0.14 &          sports \\\\\n",
      " sports\\_11.txt &  sports &      0.13 &      0.74 &        0.13 &          sports \\\\\n",
      " sports\\_42.txt &  sports &      0.13 &      0.73 &        0.13 &          sports \\\\\n",
      " sports\\_13.txt &  sports &      0.13 &      0.73 &        0.14 &          sports \\\\\n",
      "  sports\\_5.txt &  sports &      0.11 &      0.72 &        0.17 &          sports \\\\\n",
      " sports\\_22.txt &  sports &      0.15 &      0.70 &        0.14 &          sports \\\\\n",
      " sports\\_10.txt &  sports &      0.14 &      0.67 &        0.19 &          sports \\\\\n",
      "  sports\\_7.txt &  sports &      0.17 &      0.66 &        0.17 &          sports \\\\\n",
      " sports\\_49.txt &  sports &      0.16 &      0.66 &        0.18 &          sports \\\\\n",
      " sports\\_19.txt &  sports &      0.17 &      0.65 &        0.18 &          sports \\\\\n",
      " sports\\_29.txt &  sports &      0.21 &      0.65 &        0.14 &          sports \\\\\n",
      " sports\\_44.txt &  sports &      0.19 &      0.65 &        0.17 &          sports \\\\\n",
      " sports\\_28.txt &  sports &      0.19 &      0.62 &        0.19 &          sports \\\\\n",
      " sports\\_26.txt &  sports &      0.19 &      0.62 &        0.19 &          sports \\\\\n",
      " sports\\_45.txt &  sports &      0.25 &      0.59 &        0.16 &          sports \\\\\n",
      "  sports\\_4.txt &  sports &      0.25 &      0.55 &        0.20 &          sports \\\\\n",
      " sports\\_17.txt &  sports &      0.26 &      0.51 &        0.24 &          sports \\\\\n",
      " sports\\_50.txt &  sports &      0.31 &      0.50 &        0.19 &          sports \\\\\n",
      " sports\\_36.txt &  sports &      0.39 &      0.39 &        0.22 &          sports \\\\\n",
      " sports\\_31.txt &  sports &      0.45 &      0.34 &        0.21 &          health \\\\\n",
      " sports\\_48.txt &  sports &      0.46 &      0.34 &        0.21 &          health \\\\\n",
      " sports\\_39.txt &  sports &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " sports\\_27.txt &  sports &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " sports\\_32.txt &  sports &      0.33 &      0.33 &        0.33 &         unknown \\\\\n",
      " sports\\_25.txt &  sports &      0.31 &      0.20 &        0.49 &        politics \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "        doc\\_name &     class &  p\\_health &  p\\_sports &  p\\_politics & predicted\\_class \\\\\n",
      "\\midrule\n",
      " politics\\_15.txt &  politics &      0.05 &      0.05 &        0.90 &        politics \\\\\n",
      " politics\\_19.txt &  politics &      0.06 &      0.06 &        0.88 &        politics \\\\\n",
      " politics\\_33.txt &  politics &      0.06 &      0.10 &        0.84 &        politics \\\\\n",
      " politics\\_18.txt &  politics &      0.09 &      0.07 &        0.84 &        politics \\\\\n",
      " politics\\_28.txt &  politics &      0.07 &      0.09 &        0.84 &        politics \\\\\n",
      " politics\\_43.txt &  politics &      0.09 &      0.09 &        0.82 &        politics \\\\\n",
      "  politics\\_4.txt &  politics &      0.09 &      0.10 &        0.81 &        politics \\\\\n",
      " politics\\_14.txt &  politics &      0.11 &      0.08 &        0.81 &        politics \\\\\n",
      " politics\\_27.txt &  politics &      0.11 &      0.10 &        0.79 &        politics \\\\\n",
      " politics\\_32.txt &  politics &      0.11 &      0.10 &        0.79 &        politics \\\\\n",
      " politics\\_30.txt &  politics &      0.11 &      0.11 &        0.78 &        politics \\\\\n",
      " politics\\_46.txt &  politics &      0.11 &      0.11 &        0.78 &        politics \\\\\n",
      " politics\\_26.txt &  politics &      0.12 &      0.12 &        0.75 &        politics \\\\\n",
      "  politics\\_8.txt &  politics &      0.14 &      0.14 &        0.71 &        politics \\\\\n",
      " politics\\_10.txt &  politics &      0.16 &      0.15 &        0.69 &        politics \\\\\n",
      " politics\\_34.txt &  politics &      0.17 &      0.15 &        0.69 &        politics \\\\\n",
      " politics\\_47.txt &  politics &      0.16 &      0.16 &        0.68 &        politics \\\\\n",
      " politics\\_17.txt &  politics &      0.19 &      0.15 &        0.66 &        politics \\\\\n",
      "  politics\\_9.txt &  politics &      0.20 &      0.14 &        0.66 &        politics \\\\\n",
      "  politics\\_1.txt &  politics &      0.23 &      0.12 &        0.66 &        politics \\\\\n",
      " politics\\_44.txt &  politics &      0.22 &      0.16 &        0.62 &        politics \\\\\n",
      " politics\\_40.txt &  politics &      0.15 &      0.23 &        0.62 &        politics \\\\\n",
      "  politics\\_7.txt &  politics &      0.20 &      0.20 &        0.60 &        politics \\\\\n",
      " politics\\_25.txt &  politics &      0.21 &      0.21 &        0.59 &        politics \\\\\n",
      "  politics\\_2.txt &  politics &      0.30 &      0.15 &        0.56 &        politics \\\\\n",
      " politics\\_31.txt &  politics &      0.30 &      0.15 &        0.55 &        politics \\\\\n",
      " politics\\_38.txt &  politics &      0.24 &      0.21 &        0.55 &        politics \\\\\n",
      " politics\\_49.txt &  politics &      0.24 &      0.24 &        0.52 &        politics \\\\\n",
      " politics\\_37.txt &  politics &      0.17 &      0.33 &        0.50 &        politics \\\\\n",
      "  politics\\_3.txt &  politics &      0.36 &      0.15 &        0.49 &        politics \\\\\n",
      " politics\\_50.txt &  politics &      0.34 &      0.17 &        0.49 &        politics \\\\\n",
      " politics\\_11.txt &  politics &      0.38 &      0.16 &        0.46 &        politics \\\\\n",
      " politics\\_42.txt &  politics &      0.21 &      0.42 &        0.37 &          sports \\\\\n",
      " politics\\_21.txt &  politics &      0.65 &      0.14 &        0.21 &          health \\\\\n",
      "  politics\\_6.txt &  politics &      0.68 &      0.11 &        0.20 &          health \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved.\n",
      "############################################################\n"
     ]
    }
   ],
   "source": [
    "data = execute(test_data, classify_tfidf(classify_document_tfidf, model_tfidf, dictionary, bow, index, test_data))\n",
    "data = execute(test_data, classify_w2v(classify_doc_w2v, glossaries_vector, model_w2v, test_data))\n",
    "data = execute(test_data, classify_bayes(classify_doc_bayes, clf, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:44.317443Z",
     "start_time": "2020-12-15T21:13:44.312436Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_single_model(data, model, classify_function):\n",
    "    \"\"\"\n",
    "    Function that evaluates the performance of a specific model.\n",
    "    \n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    print(\"#######################################################\")\n",
    "    print(\"Evaluating \"+ model + \"...\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    data = classify_documents(data, classify_function)\n",
    "    \n",
    "    y_true = data[\"current_class\"]\n",
    "    y_pred = data[\"predicted_class\"]\n",
    "    original = len(y_pred)\n",
    "    y_pred = data[data[\"predicted_class\"] != -1][\"predicted_class\"]\n",
    "    unknown = original - len(y_pred)\n",
    "    y_true = y_true.loc[y_pred.index]\n",
    "        \n",
    "    print(classification_report(y_true, y_pred, target_names=[\"health\", \"sports\", \"politics\"]))\n",
    "    print(\"Confusion matrix ==>\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    print(f\"{unknown} documents couldn´t been classified.\")\n",
    "\n",
    "    #precisions = []\n",
    "    #recalls = []\n",
    "\n",
    "    #for i in range(len(cm[0])):\n",
    "     #   name = keys_dic[i]\n",
    "      #  print(f\"Computing statistics about {name}:\")\n",
    "       # recall = cm[i,i] / np.sum(cm[i,:])\n",
    "      #  precision = cm[i,i] / np.sum(cm[:,i])\n",
    "      #  print(f\"\\tPrecision ==> {precision}\")\n",
    "      #  print(f\"\\tRecall ==> {recall}\")\n",
    "\n",
    "      #  precisions.append(precision)\n",
    "      #  recalls.append(recall)\n",
    "\n",
    "    #precisions = np.array(precisions)\n",
    "    #recalls = np.array(recalls)\n",
    "    #f1 = f1_score(y_true, y_pred, average = \"macro\")\n",
    "    #accuracy = accuracy_score(y_true, y_pred)\n",
    "    #print(f\"Average precision ==> {precisions.mean()}\")\n",
    "    #print(f\"Average recall ==> {recalls.mean()}\")\n",
    "    #print(f\"F1-Score ==> {f1}\")\n",
    "    #print(f\"Overall accuracy score ==> {accuracy}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Model evaluated\")\n",
    "    print(\"#######################################################\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:44.362437Z",
     "start_time": "2020-12-15T21:13:44.318436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "Evaluating tf-idf...\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      health       0.73      0.86      0.79        35\n",
      "      sports       0.85      0.88      0.86        32\n",
      "    politics       1.00      0.79      0.89        34\n",
      "\n",
      "    accuracy                           0.84       101\n",
      "   macro avg       0.86      0.84      0.85       101\n",
      "weighted avg       0.86      0.84      0.84       101\n",
      "\n",
      "Confusion matrix ==>\n",
      "[[30  5  0]\n",
      " [ 4 28  0]\n",
      " [ 7  0 27]]\n",
      "4 documents couldn´t been classified.\n",
      "-------------------------------------------------------\n",
      "Model evaluated\n",
      "#######################################################\n"
     ]
    }
   ],
   "source": [
    "data_tfidf = evaluate_single_model(test_data, \"tf-idf\", classify_tfidf(classify_document_tfidf, model_tfidf, dictionary, bow, index, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:44.630436Z",
     "start_time": "2020-12-15T21:13:44.363436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "Evaluating Word2Vec...\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      health       0.65      0.69      0.67        35\n",
      "      sports       0.59      0.57      0.58        35\n",
      "    politics       0.62      0.60      0.61        35\n",
      "\n",
      "    accuracy                           0.62       105\n",
      "   macro avg       0.62      0.62      0.62       105\n",
      "weighted avg       0.62      0.62      0.62       105\n",
      "\n",
      "Confusion matrix ==>\n",
      "[[24  6  5]\n",
      " [ 7 20  8]\n",
      " [ 6  8 21]]\n",
      "0 documents couldn´t been classified.\n",
      "-------------------------------------------------------\n",
      "Model evaluated\n",
      "#######################################################\n"
     ]
    }
   ],
   "source": [
    "data_w2v = evaluate_single_model(test_data, \"Word2Vec\", classify_w2v(classify_doc_w2v, glossaries_vector, model_w2v, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:13:44.787436Z",
     "start_time": "2020-12-15T21:13:44.631436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "Evaluating Multinomial NB (tfidf)...\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      health       0.88      0.80      0.84        35\n",
      "      sports       0.85      0.91      0.88        32\n",
      "    politics       0.89      0.91      0.90        35\n",
      "\n",
      "    accuracy                           0.87       102\n",
      "   macro avg       0.87      0.87      0.87       102\n",
      "weighted avg       0.87      0.87      0.87       102\n",
      "\n",
      "Confusion matrix ==>\n",
      "[[28  4  3]\n",
      " [ 2 29  1]\n",
      " [ 2  1 32]]\n",
      "3 documents couldn´t been classified.\n",
      "-------------------------------------------------------\n",
      "Model evaluated\n",
      "#######################################################\n"
     ]
    }
   ],
   "source": [
    "data_bayes = evaluate_single_model(test_data, \"Multinomial NB (tfidf)\", classify_bayes(classify_doc_bayes, clf, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Índice",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
